<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Improving the DQN algorithm using Double Q-Learning | Stochastic Expatriate Descent</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Improving the DQN algorithm using Double Q-Learning" />
<meta name="author" content="David R. Pugh" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes on improving the DQN algorithm using Double Q-learning." />
<meta property="og:description" content="Notes on improving the DQN algorithm using Double Q-learning." />
<link rel="canonical" href="https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html" />
<meta property="og:url" content="https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html" />
<meta property="og:site_name" content="Stochastic Expatriate Descent" />
<meta property="og:image" content="https://davidrpugh.github.io/stochastic-expatriate-descent/images/double-dqn-figure-2.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-11T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"David R. Pugh"},"datePublished":"2020-04-11T00:00:00-05:00","headline":"Improving the DQN algorithm using Double Q-Learning","image":"https://davidrpugh.github.io/stochastic-expatriate-descent/images/double-dqn-figure-2.png","description":"Notes on improving the DQN algorithm using Double Q-learning.","mainEntityOfPage":{"@type":"WebPage","@id":"https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html"},"@type":"BlogPosting","url":"https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html","dateModified":"2020-04-11T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/stochastic-expatriate-descent/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://davidrpugh.github.io/stochastic-expatriate-descent/feed.xml" title="Stochastic Expatriate Descent" /><link rel="shortcut icon" type="image/x-icon" href="/stochastic-expatriate-descent/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Improving the DQN algorithm using Double Q-Learning | Stochastic Expatriate Descent</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Improving the DQN algorithm using Double Q-Learning" />
<meta name="author" content="David R. Pugh" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes on improving the DQN algorithm using Double Q-learning." />
<meta property="og:description" content="Notes on improving the DQN algorithm using Double Q-learning." />
<link rel="canonical" href="https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html" />
<meta property="og:url" content="https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html" />
<meta property="og:site_name" content="Stochastic Expatriate Descent" />
<meta property="og:image" content="https://davidrpugh.github.io/stochastic-expatriate-descent/images/double-dqn-figure-2.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-11T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"David R. Pugh"},"datePublished":"2020-04-11T00:00:00-05:00","headline":"Improving the DQN algorithm using Double Q-Learning","image":"https://davidrpugh.github.io/stochastic-expatriate-descent/images/double-dqn-figure-2.png","description":"Notes on improving the DQN algorithm using Double Q-learning.","mainEntityOfPage":{"@type":"WebPage","@id":"https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html"},"@type":"BlogPosting","url":"https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html","dateModified":"2020-04-11T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://davidrpugh.github.io/stochastic-expatriate-descent/feed.xml" title="Stochastic Expatriate Descent" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/stochastic-expatriate-descent/">Stochastic Expatriate Descent</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/stochastic-expatriate-descent/about/">About Me</a><a class="page-link" href="/stochastic-expatriate-descent/search/">Search</a><a class="page-link" href="/stochastic-expatriate-descent/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Improving the DQN algorithm using Double Q-Learning</h1><p class="page-description">Notes on improving the DQN algorithm using Double Q-learning.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-11T00:00:00-05:00" itemprop="datePublished">
        Apr 11, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">David R. Pugh</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      21 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/stochastic-expatriate-descent/categories/#pytorch">pytorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/stochastic-expatriate-descent/categories/#deep-reinforcement-learning">deep-reinforcement-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/stochastic-expatriate-descent/categories/#deep-q-networks">deep-q-networks</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/davidrpugh/stochastic-expatriate-descent/tree/2020-04-11-double-dqn/_notebooks/2020-04-11-double-dqn.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/stochastic-expatriate-descent/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/davidrpugh/stochastic-expatriate-descent/2020-04-11-double-dqn?filepath=_notebooks%2F2020-04-11-double-dqn.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/stochastic-expatriate-descent/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/davidrpugh/stochastic-expatriate-descent/blob/2020-04-11-double-dqn/_notebooks/2020-04-11-double-dqn.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/stochastic-expatriate-descent/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-11-double-dqn.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I am continuing to work my way through the <a href="https://www.udacity.com/">Udacity</a> <a href="https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893"><em>Deep Reinforcement Learning Nanodegree</em></a>. In this blog post I discuss and implement the Double DQN algorithm from <a href="https://arxiv.org/abs/1509.06461"><em>Deep Reinforcement Learning with Double Q-Learning</em></a> (Van Hasselt et al 2015). The Double DQN algorithm is a minor, but important, modification of the original DQN algorithm that I covered in a <a href="https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/03/deep-q-networks.html">previous post</a>.</p>
<p>The Van Hasselt et al 2015 paper makes several important contributions.</p>
<ol>
<li>Demonstration of how Q-learning can be overly optimistic in large-scale, even 
deterministic, problems due to the inherent estimation errors of learning. </li>
<li>Demonstration that overestimations are more common and severe in practice than previously 
acknowledged. </li>
<li>Implementation of Double Q-learning called Double DQN that extends, with minor 
modifications, the popular DQN algorithm and that can be used at scale to successfully 
reduce overestimations with the result being more stable and reliable learning.</li>
<li>Demonstation that Double DQN finds better policies by obtaining new state-of-the-art 
results on the Atari 2600 dataset.</li>
</ol>
<h2 id="Why-does-Q-learning-overestimate-Q-values?">Why does Q-learning overestimate Q-values?<a class="anchor-link" href="#Why-does-Q-learning-overestimate-Q-values?"> </a></h2><p>No matter what type of function approximation scheme used to approximate the action-value function $Q$ there will always be approximation error. The presence of the max operator in the Bellman equation used to compute the $Q$-values means that the approximate $Q$-values will almost always be strictly greater than the corresponding $Q$ values from the true action-value function (i.e., the approximation errors will almost always be positive). This potentially significant source of bias can impede learning and is often exacerbated by the use of flexible, non-linear function approximators such as neural networks.</p>
<p>Double Q-learning addresses these issues by explicitly separating action selection from action evaluation which allows each step to use a different function approximator resulting in a better overall approximation of the action-value function. Figure 2 (with caption) below, which is taken from Van Hasselt et al 2015, summarizes these ideas. See the <a href="https://arxiv.org/pdf/1509.06461.pdf">paper</a> for more details.</p>
<p><img src="/stochastic-expatriate-descent/images/copied_from_nb/my_icons/double-dqn-figure-2.png" alt="" /></p>
<h2 id="Implementing-the-Double-DQN-algorithm">Implementing the Double DQN algorithm<a class="anchor-link" href="#Implementing-the-Double-DQN-algorithm"> </a></h2><p>The key idea behind Double Q-learning is to reduce over-estimations of Q-values by separating the selection of actions from the evaluation of those actions so that a different Q-network can be used in each step. When applying Double Q-learning to extend the DQN algorithm one can use the online Q-network, $Q(S, a; \theta)$, to select the actions and then the target Q-network, $Q(S, a; \theta^{-})$, to evaluate the selected actions.</p>
<p>Before implement the Double DQN algorithm, I am going to re-implement the Q-learning update from the DQN algorithm in a way that explicitly separates action selection from action evaluation. Once I have implemented this new version of Q-learning, implementing the Double DQN algorithm will be much easier. Formally separating action selection from action evaluation involves re-writing the Q-learning Bellman equation as follows.</p>
<p>
$$ Y_t^{DQN} = R_{t+1} + \gamma Q\big(S_{t+1}, \underset{a}{\mathrm{argmax}}\ Q(S_{t+1}, a; \theta_t); \theta_t\big) $$
</p>
<p>In Python this can be implemented as three separate functions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">def</span> <span class="nf">select_greedy_actions</span><span class="p">(</span><span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">q_network</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Select the greedy action for the current state given some Q-network.&quot;&quot;&quot;</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">actions</span> <span class="o">=</span> <span class="n">q_network</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">actions</span>


<span class="k">def</span> <span class="nf">evaluate_selected_actions</span><span class="p">(</span><span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                              <span class="n">actions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                              <span class="n">rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                              <span class="n">dones</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                              <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                              <span class="n">q_network</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Compute the Q-values by evaluating the actions given the current states and Q-network.&quot;&quot;&quot;</span>
    <span class="n">next_q_values</span> <span class="o">=</span> <span class="n">q_network</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">actions</span><span class="p">)</span>        
    <span class="n">q_values</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gamma</span> <span class="o">*</span> <span class="n">next_q_values</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">q_values</span>


<span class="k">def</span> <span class="nf">q_learning_update</span><span class="p">(</span><span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                      <span class="n">rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                      <span class="n">dones</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                      <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                      <span class="n">q_network</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Q-Learning update with explicitly decoupled action selection and evaluation steps.&quot;&quot;&quot;</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="n">select_greedy_actions</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">q_network</span><span class="p">)</span>
    <span class="n">q_values</span> <span class="o">=</span> <span class="n">evaluate_selected_actions</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">q_network</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">q_values</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>From here it is straight forward to implement the Double DQN algorithm. All I need is a second action-value function. The target network in the DQN architecture provides a natural candidate for the second action-value function. Hasselt et al 2015 suggest using the online Q-network to select the greedy policy actions before using the target Q-network to estimate the value of the selected actions. Once again here are the maths...</p>
<p>
$$ Y_t^{DoubleDQN} = R_{t+1} + \gamma Q\big(S_{t+1}, \underset{a}{\mathrm{argmax}}\ Q(S_{t+1}, a; \theta_t), \theta_t^{-}\big) $$
</p>
<p>...and here is the the Python implementation.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">double_q_learning_update</span><span class="p">(</span><span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                             <span class="n">rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                             <span class="n">dones</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                             <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                             <span class="n">q_network_1</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                             <span class="n">q_network_2</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Double Q-Learning uses Q-network 1 to select actions and Q-network 2 to evaluate the selected actions.&quot;&quot;&quot;</span>
    <span class="n">actions</span> <span class="o">=</span> <span class="n">select_greedy_actions</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">q_network_1</span><span class="p">)</span>
    <span class="n">q_values</span> <span class="o">=</span> <span class="n">evaluate_selected_actions</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">q_network_2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">q_values</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that the function <code>double_q_learning_update</code> is almost identical to the <code>q_learning_update</code> function above: all that is needed is to introduce a second Q-network parameter, <code>q_network_2</code>, to the function. This second Q-network will be use to evaluate the actions chosen using the original Q-network parameter, now called <code>q_network_1</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Refactoring-the-DeepQAgent-class">Refactoring the <code>DeepQAgent</code> class<a class="anchor-link" href="#Refactoring-the-DeepQAgent-class"> </a></h3><p>Now that I have an implementation of the Double Q-learning algorithm I can refactor the <code>DeepQAgent</code> class from my <a href="https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/03/deep-q-networks.html">previous post</a> to incorporate the functionality above.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">typing</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">_field_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;state&quot;</span><span class="p">,</span>
    <span class="s2">&quot;action&quot;</span><span class="p">,</span>
    <span class="s2">&quot;reward&quot;</span><span class="p">,</span>
    <span class="s2">&quot;next_state&quot;</span><span class="p">,</span>
    <span class="s2">&quot;done&quot;</span>
<span class="p">]</span>
<span class="n">Experience</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;Experience&quot;</span><span class="p">,</span> <span class="n">field_names</span><span class="o">=</span><span class="n">_field_names</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ExperienceReplayBuffer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Fixed-size buffer to store Experience tuples.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize an ExperienceReplayBuffer object.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        buffer_size (int): maximum size of buffer</span>
<span class="sd">        batch_size (int): size of each training batch</span>
<span class="sd">        random_state (np.random.RandomState): random number generator.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()</span> <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">random_state</span>
        
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">)</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Number of experience samples per training batch.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">buffer_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Total number of experience samples stored in memory.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer_size</span>
    
    <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experience</span><span class="p">:</span> <span class="n">Experience</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Add a new experience to memory.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="n">Experience</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Randomly sample a batch of experiences from memory.&quot;&quot;&quot;</span>
        <span class="n">idxs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">)</span>
        <span class="n">experiences</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idxs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">experiences</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The functions defined above can be added to the <code>DeepQAgent</code> as static methods or simply included as module level functions, depending.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">typing</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>


<span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">choose_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Rule for choosing an action given the current state of the environment.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        
    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiences</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="n">Experience</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Update the agent&#39;s state based on a collection of recent experiences.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Save any important agent state to a file.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
        
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
             <span class="n">action</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
             <span class="n">reward</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
             <span class="n">next_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
             <span class="n">done</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Update agent&#39;s state after observing the effect of its action on the environment.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="n">NotImplmentedError</span>


<span class="k">class</span> <span class="nc">DeepQAgent</span><span class="p">(</span><span class="n">Agent</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">state_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">action_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">number_hidden_units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">optimizer_fn</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Callable</span><span class="p">[[</span><span class="n">typing</span><span class="o">.</span><span class="n">Iterable</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]],</span> <span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">],</span>
                 <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">buffer_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">epsilon_decay_schedule</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
                 <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                 <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                 <span class="n">update_frequency</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">double_dqn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a DeepQAgent.</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state_size (int): the size of the state space.</span>
<span class="sd">        action_size (int): the size of the action space.</span>
<span class="sd">        number_hidden_units (int): number of units in the hidden layers.</span>
<span class="sd">        optimizer_fn (callable): function that takes Q-network parameters and returns an optimizer.</span>
<span class="sd">        batch_size (int): number of experience tuples in each mini-batch.</span>
<span class="sd">        buffer_size (int): maximum number of experience tuples stored in the replay buffer.</span>
<span class="sd">        epsilon_decay_schdule (callable): function that takes episode number and returns epsilon.</span>
<span class="sd">        alpha (float): rate at which the target q-network parameters are updated.</span>
<span class="sd">        gamma (float): Controls how much that agent discounts future rewards (0 &lt; gamma &lt;= 1).</span>
<span class="sd">        update_frequency (int): frequency (measured in time steps) with which q-network parameters are updated.</span>
<span class="sd">        double_dqn (bool): whether to use vanilla DQN algorithm or use the Double DQN algorithm.</span>
<span class="sd">        seed (int): random seed</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_state_size</span> <span class="o">=</span> <span class="n">state_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_action_size</span> <span class="o">=</span> <span class="n">action_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        
        <span class="c1"># set seeds for reproducibility</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
        
        <span class="c1"># initialize agent hyperparameters</span>
        <span class="n">_replay_buffer_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
            <span class="s2">&quot;buffer_size&quot;</span><span class="p">:</span> <span class="n">buffer_size</span><span class="p">,</span>
            <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_memory</span> <span class="o">=</span> <span class="n">ExperienceReplayBuffer</span><span class="p">(</span><span class="o">**</span><span class="n">_replay_buffer_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon_decay_schedule</span> <span class="o">=</span> <span class="n">epsilon_decay_schedule</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_double_dqn</span> <span class="o">=</span> <span class="n">double_dqn</span>
        
        <span class="c1"># initialize Q-Networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_frequency</span> <span class="o">=</span> <span class="n">update_frequency</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_q_network</span><span class="p">(</span><span class="n">number_hidden_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_q_network</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_q_network</span><span class="p">(</span><span class="n">number_hidden_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_q_networks</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_target_q_network</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="p">)</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target_q_network</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
        
        <span class="c1"># initialize the optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

        <span class="c1"># initialize some counters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_number_episodes</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_number_timesteps</span> <span class="o">=</span> <span class="mi">0</span>
        
    <span class="k">def</span> <span class="nf">_initialize_q_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">number_hidden_units</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create a neural network for approximating the action-value function.&quot;&quot;&quot;</span>
        <span class="n">q_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_size</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">number_hidden_units</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">number_hidden_units</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">number_hidden_units</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">number_hidden_units</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_action_size</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">q_network</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_select_greedy_action</span><span class="p">(</span><span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">q_network</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Greedy action selection step of Q-learning.&quot;&quot;&quot;</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">actions</span> <span class="o">=</span> <span class="n">q_network</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">actions</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_evaluate_selected_action</span><span class="p">(</span><span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                  <span class="n">actions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                  <span class="n">rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                  <span class="n">dones</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                  <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                                  <span class="n">q_network</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Action evaluation step of Q-learning.&quot;&quot;&quot;</span>
        <span class="n">next_q_values</span> <span class="o">=</span> <span class="n">q_network</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">actions</span><span class="p">)</span>        
        <span class="n">q_values</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="p">(</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">next_q_values</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">q_values</span>
        
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_q_learning_update</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                           <span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                           <span class="n">rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                           <span class="n">dones</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                           <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                           <span class="n">q_network</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Q-learning update rule.&quot;&quot;&quot;</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_select_greedy_action</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">q_network</span><span class="p">)</span>
        <span class="n">q_values</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_evaluate_selected_action</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">q_network</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q_values</span>
    
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_double_q_learning_update</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                  <span class="n">rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                  <span class="n">dones</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                                  <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                                  <span class="n">q_network_1</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                                  <span class="n">q_network_2</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Double Q-learning update rule.&quot;&quot;&quot;</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_select_greedy_action</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">q_network_1</span><span class="p">)</span>
        <span class="n">q_values</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_evaluate_selected_action</span><span class="p">(</span><span class="n">states</span><span class="p">,</span>
                                                 <span class="n">actions</span><span class="p">,</span>
                                                 <span class="n">rewards</span><span class="p">,</span>
                                                 <span class="n">dones</span><span class="p">,</span>
                                                 <span class="n">gamma</span><span class="p">,</span>
                                                 <span class="n">q_network_2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q_values</span>
                 
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_soft_update_q_network_parameters</span><span class="p">(</span><span class="n">q_network_1</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                                          <span class="n">q_network_2</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                                          <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;In-place, soft-update of q_network_1 parameters with parameters from q_network_2.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">q_network_1</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q_network_2</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">p1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">p2</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">p1</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_synchronize_q_networks</span><span class="p">(</span><span class="n">q_network_1</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">q_network_2</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;In place, synchronization of q_network_1 and q_network_2.&quot;&quot;&quot;</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">q_network_1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">q_network_2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
           
    <span class="k">def</span> <span class="nf">_uniform_random_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Choose an action uniformly at random.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_action_size</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">_greedy_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Choose an action that maximizes the action_values given the current state.&quot;&quot;&quot;</span>
        <span class="n">action</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                      <span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">cpu</span><span class="p">()</span>  <span class="c1"># action_values might reside on the GPU!</span>
                      <span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">_epsilon_greedy_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;With probability epsilon explore randomly; otherwise exploit knowledge optimally.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_random_state</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uniform_random_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_greedy_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span>

    <span class="k">def</span> <span class="nf">choose_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the action for given state as per current policy.</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state (np.array): current state of the environment.</span>
<span class="sd">        </span>
<span class="sd">        Return:</span>
<span class="sd">        --------</span>
<span class="sd">        action (int): an integer representing the chosen action.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># need to reshape state array and convert to tensor</span>
        <span class="n">state_tensor</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                             <span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                             <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">))</span>
            
        <span class="c1"># choose uniform at random if agent has insufficient experience</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_sufficient_experience</span><span class="p">():</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uniform_random_policy</span><span class="p">(</span><span class="n">state_tensor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon_decay_schedule</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_number_episodes</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_epsilon_greedy_policy</span><span class="p">(</span><span class="n">state_tensor</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiences</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="n">Experience</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Update the agent&#39;s state based on a collection of recent experiences.&quot;&quot;&quot;</span>
        <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span><span class="p">,</span> <span class="n">dones</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">vs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">vs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">experiences</span><span class="p">))</span>
        
        <span class="c1"># need to add second dimension to some tensors</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                          <span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">dones</span> <span class="o">=</span> <span class="n">dones</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_double_dqn</span><span class="p">:</span>
            <span class="n">target_q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_double_q_learning_update</span><span class="p">(</span><span class="n">next_states</span><span class="p">,</span>
                                                             <span class="n">rewards</span><span class="p">,</span>
                                                             <span class="n">dones</span><span class="p">,</span>
                                                             <span class="bp">self</span><span class="o">.</span><span class="n">_gamma</span><span class="p">,</span>
                                                             <span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="p">,</span>
                                                             <span class="bp">self</span><span class="o">.</span><span class="n">_target_q_network</span>
                                                            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">target_q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_q_learning_update</span><span class="p">(</span><span class="n">next_states</span><span class="p">,</span>
                                                      <span class="n">rewards</span><span class="p">,</span>
                                                      <span class="n">dones</span><span class="p">,</span>
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">_gamma</span><span class="p">,</span>
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">_target_q_network</span>
                                                      <span class="p">)</span>

        <span class="n">online_q_values</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
                               <span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">actions</span><span class="p">))</span>
        
        <span class="c1"># compute the mean squared loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">online_q_values</span><span class="p">,</span> <span class="n">target_q_values</span><span class="p">)</span>
        
        <span class="c1"># updates the parameters of the online network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">_soft_update_q_network_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_target_q_network</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">_alpha</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">has_sufficient_experience</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;True if agent has enough experience to train on a batch of samples; False otherwise.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_memory</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory</span><span class="o">.</span><span class="n">batch_size</span>
    
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves the state of the DeepQAgent.</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        filepath (str): filepath where the serialized state should be saved.</span>
<span class="sd">        </span>
<span class="sd">        Notes:</span>
<span class="sd">        ------</span>
<span class="sd">        The method uses `torch.save` to serialize the state of the q-network, </span>
<span class="sd">        the optimizer, as well as the dictionary of agent hyperparameters.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;q-network-state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_online_q_network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;optimizer-state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;agent-hyperparameters&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_alpha</span><span class="p">,</span>
                <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="s2">&quot;buffer_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">,</span>
                <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gamma</span><span class="p">,</span>
                <span class="s2">&quot;update_frequency&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_frequency</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">filepath</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
             <span class="n">action</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
             <span class="n">reward</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
             <span class="n">next_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
             <span class="n">done</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates the agent&#39;s state based on feedback received from the environment.</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state (np.array): the previous state of the environment.</span>
<span class="sd">        action (int): the action taken by the agent in the previous state.</span>
<span class="sd">        reward (float): the reward received from the environment.</span>
<span class="sd">        next_state (np.array): the resulting state of the environment following the action.</span>
<span class="sd">        done (bool): True is the training episode is finised; false otherwise.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">experience</span> <span class="o">=</span> <span class="n">Experience</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_memory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_number_episodes</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_number_timesteps</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># every so often the agent should learn from experiences</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_number_timesteps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_frequency</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_sufficient_experience</span><span class="p">():</span>
                <span class="n">experiences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The code for the training loop remains unchanged from the previous post.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">typing</span>

<span class="kn">import</span> <span class="nn">gym</span>


<span class="k">def</span> <span class="nf">_train_for_at_most</span><span class="p">(</span><span class="n">agent</span><span class="p">:</span> <span class="n">Agent</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">max_timesteps</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Train agent for a maximum number of timesteps.&quot;&quot;&quot;</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_timesteps</span><span class="p">):</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">choose_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">score</span>

                
<span class="k">def</span> <span class="nf">_train_until_done</span><span class="p">(</span><span class="n">agent</span><span class="p">:</span> <span class="n">Agent</span><span class="p">,</span> <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Train the agent until the current episode is complete.&quot;&quot;&quot;</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">choose_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span>
    <span class="k">return</span> <span class="n">score</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">agent</span><span class="p">:</span> <span class="n">Agent</span><span class="p">,</span>
          <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span>
          <span class="n">checkpoint_filepath</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
          <span class="n">target_score</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
          <span class="n">number_episodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
          <span class="n">maximum_timesteps</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reinforcement learning training loop.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    agent (Agent): an agent to train.</span>
<span class="sd">    env (gym.Env): an environment in which to train the agent.</span>
<span class="sd">    checkpoint_filepath (str): filepath used to save the state of the trained agent.</span>
<span class="sd">    number_episodes (int): maximum number of training episodes.</span>
<span class="sd">    maximum_timsteps (int): maximum number of timesteps per episode.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    scores (list): collection of episode scores from training.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">most_recent_scores</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_episodes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">maximum_timesteps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">_train_until_done</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">_train_for_at_most</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">maximum_timesteps</span><span class="p">)</span>         
        <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        <span class="n">most_recent_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        
        <span class="n">average_score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">most_recent_scores</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">most_recent_scores</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">average_score</span> <span class="o">&gt;=</span> <span class="n">target_score</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Environment solved in </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2"> episodes!</span><span class="se">\t</span><span class="s2">Average Score: </span><span class="si">{</span><span class="n">average_score</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint_filepath</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">Episode </span><span class="si">{</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="se">\t</span><span class="s2">Average Score: </span><span class="si">{</span><span class="n">average_score</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">scores</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Solving-the-LunarLander-v2-environment">Solving the <code>LunarLander-v2</code> environment<a class="anchor-link" href="#Solving-the-LunarLander-v2-environment"> </a></h2><p>In the rest of this blog post I will use the Double DQN algorithm to train an agent to solve the <a href="https://gym.openai.com/envs/LunarLander-v2/">LunarLander-v2</a> environment from <a href="https://openai.com/">OpenAI</a> and the compare it to the the results obtained using the vanilla DQN algorithm.</p>
<p>In this environment the landing pad is always at coordinates (0,0). The reward for moving the lander from the top of the screen to landing pad and arriving at zero speed is typically between 100 and 140 points. Firing the main engine is -0.3 points each frame (so the lander is incentivized to fire the engine as few times possible). If the lander moves away from landing pad it loses reward (so the lander is incentived to land in the designated landing area). The lander is also incentived to land "gracefully" (and not crash in the landing area!).</p>
<p>A training episode finishes if the lander crashes (-100 points) or comes to rest (+100 points). Each leg with ground contact receives and additional +10 points. The task is considered "solved" if the lander is able to achieve 200 points (I will actually be more stringent and define "solved" as achieving over 200 points on average in the most recent 100 training episodes).</p>
<h3 id="Action-Space">Action Space<a class="anchor-link" href="#Action-Space"> </a></h3><p>There are four discrete actions available:</p>
<ol>
<li>Do nothing.</li>
<li>Fire the left orientation engine.</li>
<li>Fire main engine.</li>
<li>Fire the right orientation engine.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Colab-specific-environment-setup">Colab specific environment setup<a class="anchor-link" href="#Colab-specific-environment-setup"> </a></h3><p>If you are playing around with this notebook on Google Colab, then you will need to run the following cell in order to install the required OpenAI dependencies into the environment.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install gym<span class="o">[</span>box2d<span class="o">]==</span><span class="m">0</span>.17.*
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Making-my-code-more-maintainable">Making my code more maintainable<a class="anchor-link" href="#Making-my-code-more-maintainable"> </a></h3><p>In order to make the code used in this and in my previous blog post more maintainable for future posts, I have moved the various class definitions and training functions in my previous post out of Jupyter notebooks and into scripts. The <code>agents.py</code> scripts contains the various agent classes, in particular the <code>DeepQAgent</code> class which implements both the DQN and Double DQN algorithms; the <code>experience_replay.py</code> script containing the <code>Experience</code> and <code>ExperienceReplayBuffer</code> classes; and the <code>training.py</code> script contains the functions that train an <code>agents.Agent</code> to solve some <code>gym.Env</code> environment.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gym</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;LunarLander-v2&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pughdr/Research/stochastic-expatriate-descent/env/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: <span class="ansi-yellow-fg">WARN: Box bound precision lowered by casting to float32</span>
  warnings.warn(colorize(&#39;%s: %s&#39;%(&#39;WARN&#39;, msg % args), &#39;yellow&#39;))
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-a-DeepQAgent">Creating a <code>DeepQAgent</code><a class="anchor-link" href="#Creating-a-DeepQAgent"> </a></h3><h4 id="Epsilon-decay-schedule">Epsilon decay schedule<a class="anchor-link" href="#Epsilon-decay-schedule"> </a></h4><p>As was the case with the DQN algorithm, when using the Double DQN algorithm the agent chooses its action using an $\epsilon$-greedy policy. When using an $\epsilon$-greedy policy, with probability $\epsilon$, the agent explores the state space by choosing an action uniformly at random from the set of feasible actions; with probability $1-\epsilon$, the agent exploits its current knowledge by choosing the optimal action given that current state.</p>
<p>As the agent learns and acquires additional knowledge about it environment it makes sense to <em>decrease</em> exploration and <em>increase</em> exploitation by decreasing $\epsilon$. In practice, it isn't a good idea to decrease $\epsilon$ to zero; instead one typically decreases $\epsilon$ over time according to some schedule until it reaches some minimum value.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">power_decay_schedule</span><span class="p">(</span><span class="n">episode_number</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                         <span class="n">decay_factor</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                         <span class="n">minimum_epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Power decay schedule found in other practical applications.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">decay_factor</span><span class="o">**</span><span class="n">episode_number</span><span class="p">,</span> <span class="n">minimum_epsilon</span><span class="p">)</span>

<span class="n">_epsilon_decay_schedule_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;decay_factor&quot;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
    <span class="s2">&quot;minimum_epsilon&quot;</span><span class="p">:</span> <span class="mf">1e-2</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">epsilon_decay_schedule</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">power_decay_schedule</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="o">**</span><span class="n">_epsilon_decay_schedule_kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Choosing-an-optimizer">Choosing an optimizer<a class="anchor-link" href="#Choosing-an-optimizer"> </a></h4><p>As is the case in training any neural network, the choice of optimizer and the tuning of its hyper-parameters (in particular the learning rate) is important. Here I am going to use the <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam">Adam</a> optimizer. In my previous post on the DQN algorithm I used <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.RMSProp">RMSProp</a>. In my experiments I found that the Adam optimizer significantly improves the efficiency and stability of both the Double DQN and DQN algorithms compared with RMSProp (on this task at least!). In fact it seemed that the improvements in terms of efficiency and stability from using the Adam optimizer instead of RMSProp optimzer were more important than any gains from using Double DQN instead of DQN.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>


<span class="n">_optimizer_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
    <span class="s2">&quot;eps&quot;</span><span class="p">:</span> <span class="mf">1e-08</span><span class="p">,</span>
    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;amsgrad&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">optimizer_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">parameters</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">_optimizer_kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-the-DeepQAgent-using-Double-DQN">Training the <code>DeepQAgent</code> using Double DQN<a class="anchor-link" href="#Training-the-DeepQAgent-using-Double-DQN"> </a></h3><p>Now I am finally ready to train the <code>deep_q_agent</code>. The target score for the <code>LunarLander-v2</code> environment is 200 points on average for at least 100 consecutive episodes. If the <code>deep_q_agent</code> is able to "solve" the environment, then training will terminate early.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_agent_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;state_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;action_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> 
    <span class="s2">&quot;number_hidden_units&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;optimizer_fn&quot;</span><span class="p">:</span> <span class="n">optimizer_fn</span><span class="p">,</span>
    <span class="s2">&quot;epsilon_decay_schedule&quot;</span><span class="p">:</span> <span class="n">epsilon_decay_schedule</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;buffer_size&quot;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
    <span class="s2">&quot;update_frequency&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;double_dqn&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># True uses Double DQN; False uses DQN </span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">double_dqn_agent</span> <span class="o">=</span> <span class="n">DeepQAgent</span><span class="p">(</span><span class="o">**</span><span class="n">_agent_kwargs</span><span class="p">)</span>

<span class="n">double_dqn_scores</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">double_dqn_agent</span><span class="p">,</span>
                          <span class="n">env</span><span class="p">,</span>
                          <span class="s2">&quot;double-dqn-checkpoint.pth&quot;</span><span class="p">,</span>
                          <span class="n">number_episodes</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                          <span class="n">target_score</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Episode 100	Average Score: -182.66
Episode 200	Average Score: -76.17
Episode 300	Average Score: -54.74
Episode 400	Average Score: 13.89
Episode 500	Average Score: 119.59
Episode 600	Average Score: 184.22

Environment solved in 698 episodes!	Average Score: 200.20
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-the-DeepQAgent-using-DQN">Training the <code>DeepQAgent</code> using DQN<a class="anchor-link" href="#Training-the-DeepQAgent-using-DQN"> </a></h3><p>Next I will create another <code>DeepQAgent</code> and train it using the original DQN algorithm for comparison.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_agent_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;state_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;action_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> 
    <span class="s2">&quot;number_hidden_units&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;optimizer_fn&quot;</span><span class="p">:</span> <span class="n">optimizer_fn</span><span class="p">,</span>
    <span class="s2">&quot;epsilon_decay_schedule&quot;</span><span class="p">:</span> <span class="n">epsilon_decay_schedule</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;buffer_size&quot;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
    <span class="s2">&quot;update_frequency&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;double_dqn&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># True uses Double DQN; False uses DQN </span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">dqn_agent</span> <span class="o">=</span> <span class="n">DeepQAgent</span><span class="p">(</span><span class="o">**</span><span class="n">_agent_kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dqn_scores</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">dqn_agent</span><span class="p">,</span>
                   <span class="n">env</span><span class="p">,</span>
                   <span class="s2">&quot;dqn-checkpoint.pth&quot;</span><span class="p">,</span>
                   <span class="n">number_episodes</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                   <span class="n">target_score</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Episode 100	Average Score: -180.70
Episode 200	Average Score: -129.81
Episode 300	Average Score: -82.39
Episode 400	Average Score: -29.52
Episode 500	Average Score: -19.16
Episode 600	Average Score: 14.74
Episode 700	Average Score: 129.72
Episode 800	Average Score: 200.00

Environment solved in 801 episodes!	Average Score: 200.34
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Comparing-DQN-and-Double-DQN">Comparing DQN and Double DQN<a class="anchor-link" href="#Comparing-DQN-and-Double-DQN"> </a></h3><p>To make it a bit easier to compare the overall performance of the two algorithms I will now re-train both agents for the same number of episodes (rather than training for the minimum number of episodes required to achieve a target score).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_agent_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;state_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;action_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> 
    <span class="s2">&quot;number_hidden_units&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;optimizer_fn&quot;</span><span class="p">:</span> <span class="n">optimizer_fn</span><span class="p">,</span>
    <span class="s2">&quot;epsilon_decay_schedule&quot;</span><span class="p">:</span> <span class="n">epsilon_decay_schedule</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;buffer_size&quot;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
    <span class="s2">&quot;update_frequency&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;double_dqn&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">double_dqn_agent</span> <span class="o">=</span> <span class="n">DeepQAgent</span><span class="p">(</span><span class="o">**</span><span class="n">_agent_kwargs</span><span class="p">)</span>

<span class="n">double_dqn_scores</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">double_dqn_agent</span><span class="p">,</span>
                          <span class="n">env</span><span class="p">,</span>
                          <span class="s2">&quot;double-dqn-checkpoint.pth&quot;</span><span class="p">,</span>
                          <span class="n">number_episodes</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                          <span class="n">target_score</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">),</span> <span class="c1"># hack to insure that training never terminates early</span>
                         <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Episode 100	Average Score: -167.21
Episode 200	Average Score: -126.37
Episode 300	Average Score: -40.27
Episode 400	Average Score: 62.17
Episode 500	Average Score: 198.44
Episode 600	Average Score: 220.72
Episode 700	Average Score: 235.76
Episode 800	Average Score: 239.27
Episode 900	Average Score: 227.32
Episode 1000	Average Score: 238.04
Episode 1100	Average Score: 230.81
Episode 1200	Average Score: 241.14
Episode 1300	Average Score: 241.82
Episode 1400	Average Score: 240.67
Episode 1500	Average Score: 248.40
Episode 1600	Average Score: 255.64
Episode 1700	Average Score: 257.87
Episode 1800	Average Score: 262.54
Episode 1900	Average Score: 252.53
Episode 2000	Average Score: 251.59
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_agent_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;state_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;action_size&quot;</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> 
    <span class="s2">&quot;number_hidden_units&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;optimizer_fn&quot;</span><span class="p">:</span> <span class="n">optimizer_fn</span><span class="p">,</span>
    <span class="s2">&quot;epsilon_decay_schedule&quot;</span><span class="p">:</span> <span class="n">epsilon_decay_schedule</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;buffer_size&quot;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span>
    <span class="s2">&quot;update_frequency&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;double_dqn&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">dqn_agent</span> <span class="o">=</span> <span class="n">DeepQAgent</span><span class="p">(</span><span class="o">**</span><span class="n">_agent_kwargs</span><span class="p">)</span>

<span class="n">dqn_scores</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">dqn_agent</span><span class="p">,</span>
                   <span class="n">env</span><span class="p">,</span>
                   <span class="s2">&quot;dqn-checkpoint.pth&quot;</span><span class="p">,</span>
                   <span class="n">number_episodes</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                   <span class="n">target_score</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Episode 100	Average Score: -168.37
Episode 200	Average Score: -87.11
Episode 300	Average Score: -19.44
Episode 400	Average Score: 20.67
Episode 500	Average Score: 128.34
Episode 600	Average Score: 173.04
Episode 700	Average Score: 146.70
Episode 800	Average Score: 144.91
Episode 900	Average Score: 217.99
Episode 1000	Average Score: 209.41
Episode 1100	Average Score: 214.15
Episode 1200	Average Score: 219.80
Episode 1300	Average Score: 217.97
Episode 1400	Average Score: 242.82
Episode 1500	Average Score: 239.33
Episode 1600	Average Score: 234.26
Episode 1700	Average Score: 221.27
Episode 1800	Average Score: 239.80
Episode 1900	Average Score: 256.01
Episode 2000	Average Score: 266.62
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Plotting-the-time-series-of-scores">Plotting the time series of scores<a class="anchor-link" href="#Plotting-the-time-series-of-scores"> </a></h4><p>I can use <a href="https://pandas.pydata.org/">Pandas</a> to quickly plot the time series of scores along with a 100 episode moving average. Note that training stops as soon as the rolling average crosses the target score.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dqn_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">dqn_scores</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;scores&quot;</span><span class="p">)</span>
<span class="n">double_dqn_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">double_dqn_scores</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;scores&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">dqn_scores</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;DQN Scores&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="p">(</span><span class="n">dqn_scores</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
               <span class="o">.</span><span class="n">mean</span><span class="p">()</span>
               <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Rolling Average&quot;</span><span class="p">)</span>
               <span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Score&quot;</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">double_dqn_scores</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Double DQN Scores&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="p">(</span><span class="n">double_dqn_scores</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
                      <span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Rolling Average&quot;</span><span class="p">)</span>
                      <span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Score&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Episode Number&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Kernel-density-plot-of-the-scores">Kernel density plot of the scores<a class="anchor-link" href="#Kernel-density-plot-of-the-scores"> </a></h4><p>Kernel density plot of scores is bimodal with one mode less than -100 and a second mode greater than 200. The negative mode corresponds to those training episodes where the agent crash landed and thus scored at most -100; the positive mode corresponds to those training episodes where the agent "solved" the task. The kernel density or scores typically exhibits negative skewness (i.e., a fat left tail): there are lots of ways in which landing the lander can go horribly wrong (resulting in the agent getting a very low score) and only relatively few paths to a gentle landing (and a high score).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">dqn_scores</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;DQN&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">double_dqn_scores</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Double DQN&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Score&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Where-to-go-from-here?">Where to go from here?<a class="anchor-link" href="#Where-to-go-from-here?"> </a></h2><p>In a future post I plan to cover <a href="https://arxiv.org/abs/1509.06461">Prioritized Experience Replay</a> which improves the sampling scheme used by the <code>ExperienceReplayBuffer</code> so as to replay important transitions more frequently which should lead to more efficient learning.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="davidrpugh/stochastic-expatriate-descent"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/stochastic-expatriate-descent/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/stochastic-expatriate-descent/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/stochastic-expatriate-descent/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An expat scientist&#39;s musings about machine learning, deep learning, and living abroad.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/davidrpugh" title="davidrpugh"><svg class="svg-icon grey"><use xlink:href="/stochastic-expatriate-descent/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/TheSandyCoder" title="TheSandyCoder"><svg class="svg-icon grey"><use xlink:href="/stochastic-expatriate-descent/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
