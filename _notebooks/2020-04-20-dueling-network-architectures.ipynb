{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dueling Network Architectures\n",
    "> ???\n",
    "\n",
    "- branch: 2020-04-20-dueling-network-architectures\n",
    "- badges: true\n",
    "- image: images/dueling-network-architectures.jpeg\n",
    "- comments: true\n",
    "- author: David R. Pugh\n",
    "- categories: [pytorch, deep-reinforcement-learning, deep-q-networks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am continuing to work my way through the [Udacity](https://www.udacity.com/) [*Deep Reinforcement Learning Nanodegree*](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893). In this blog post I discuss and implement an the dueling network architecture from [*Dueling Network Architectures for Deep Reinforcement Learning*](https://arxiv.org/abs/1511.06581) (Wang et al 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The overall setup in [Wang et al 2016](https://arxiv.org/pdf/1511.06581.pdf) is similar to \n",
    "previous work in the deep RL literature. The agent seeks maximize the expected discounted \n",
    "return, where we define the discounted return as \n",
    "\n",
    "$$ R_t = \\sum_{s=0}^{\\infty} \\gamma^s r_{t+s} $$\n",
    "\n",
    "where $\\gamma \\in [0, 1]$ is a discount factor that determines how the RL agent should value \n",
    "immediate versus long-term rewards. For an RL agent behaving according to a stochastic policy \n",
    "$\\pi$, the values of the state-action pair $(s, a)$ and the state $s$ are defined as follows.\n",
    "\n",
    "\\begin{align}\n",
    "Q^{\\pi}(s, a) =& \\mathbb{E} \\big[R_t \\big| s_t = s, a_t = a, \\pi\\big] \\\\\n",
    "V^{\\pi}(s) =& \\mathbb{E}_{a\\sim \\pi(s)}\\big[Q^{\\pi}(s, a)\\big]\n",
    "\\end{align}\n",
    "\n",
    "The preceding state-action value function, or Q function, can be computed recursively with \n",
    "dynamic programming.\n",
    "\n",
    "$$ Q^{\\pi}(s, a) = \\mathbb{E}_{s'}\\bigg[r + \\gamma \\mathbb{E}_{a'\\sim \\pi(s')}\\big[Q^{\\pi}(s', a')\\big] \\bigg| s, a, \\pi \\bigg] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantage Function\n",
    "\n",
    "At this point, [Wang et al 2016](https://arxiv.org/pdf/1511.06581.pdf), begin to deviate \n",
    "a bit previous work from previous work by defining an *advantage function* which relates \n",
    "the $V$ and $Q$ functions as follows.\n",
    "\n",
    "$$ A^{\\pi}(s, a) = Q^{\\pi}(s, a) − V^{\\pi}(s) $$\n",
    "\n",
    "Note that assuming that the agent chooses its actions using policy $\\pi$ it follows that \n",
    "\n",
    "$$ \\mathbb{E}_{a\\sim\\pi(s)}\\big[A^{\\pi}(s, a)\\big] = 0. $$\n",
    "\n",
    "Intuitively, the value function $V$ measures how \"good\" it is to be in a particular state $s$. The \n",
    "$Q$ function measures the the value of choosing a particular action when in state $s$. The \n",
    "advantage function, $A$, subtracts the value of being in state $s$ from the $Q$ function to obtain \n",
    "a relative measure of the importance of each action in state $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-Networks\n",
    "\n",
    "[Minh et al 2015](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf) approximate the value functions defined above using deep neural networks which they refere to as deep Q-networks. In particular Minh et al 2015 parameterize the Q-function using $Q(s, a; \\theta)$ and then seek to find parameters $\\theta$ of some neural network that minimize the follwing sequence of loss functions at iteration $i$:\n",
    "\n",
    "$$ L_i(\\theta_i) = \\mathbb{E}_{s,a,r,s'} \\bigg[y_i^{DQN} − Q(s, a; \\theta_i)\\bigg]^2 $$\n",
    "\n",
    "with\n",
    "\n",
    "$$ y_i^{DQN} = r + \\gamma \\underset{a'}{max}\\ Q(s', a'; \\theta^{-}) $$\n",
    "\n",
    "where $\\theta^{-}$ represents the parameters of a separate, target network whose parameters, because of convergence issues, are only occasionally updated. If you are interested in more details about deep Q-networks check out my [previous post](https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/03/deep-q-networks.html) (or even better read the original paper).\n",
    "\n",
    "In the cell below I implement several useful type annotations and functions that come from Minh et al 2015 that will be used later in this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "States = torch.Tensor\n",
    "Actions = torch.Tensor\n",
    "Rewards = torch.Tensor\n",
    "Dones = torch.Tensor\n",
    "QNetwork = nn.Module\n",
    "QValues = torch.Tensor\n",
    "\n",
    "\n",
    "def synchronize_q_networks(q1: QNetwork, q2: QNetwork) -> None:\n",
    "    \"\"\"In place, synchronization of q1 and q2.\"\"\"\n",
    "    _ = q1.load_state_dict(q2.state_dict())\n",
    "\n",
    "\n",
    "def select_greedy_actions(states: torch.Tensor, q_network: QNetwork) -> Actions:\n",
    "    \"\"\"Select the greedy action for the current state given some Q-network.\"\"\"\n",
    "    _, actions = q_network(states).max(dim=1, keepdim=True)\n",
    "    return actions\n",
    "\n",
    "\n",
    "def evaluate_selected_actions(states: States,\n",
    "                              actions: Actions,\n",
    "                              rewards: Rewards,\n",
    "                              dones: Dones,\n",
    "                              gamma: float,\n",
    "                              q_network: QNetwork) -> QValues:\n",
    "    \"\"\"Compute the Q-values by evaluating the actions given the current states and Q-network.\"\"\"\n",
    "    next_q_values = q_network(states).gather(dim=1, index=actions)        \n",
    "    q_values = rewards + (gamma * next_q_values * (1 - dones))\n",
    "    return q_values\n",
    "\n",
    "\n",
    "def q_learning_update(states: States,\n",
    "                      rewards: Rewards,\n",
    "                      dones: Dones,\n",
    "                      gamma: float,\n",
    "                      q_network: QNetwork) -> QValues:\n",
    "    \"\"\"Q-Learning uses a q-network to select and evaluate actions.\"\"\"\n",
    "    actions = select_greedy_actions(states, q_network)\n",
    "    q_values = evaluate_selected_actions(states, actions, rewards, dones, gamma, q_network)\n",
    "    return q_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Deep Q-Networks\n",
    "\n",
    "[Van Hasselt et al (2015)](https://arxiv.org/abs/1509.06461) combined double Q-learning and deep \n",
    "Q-networks to obtain a much improved algorithm called double deep Q-networks (DDQN). For more \n",
    "detailed discussion of the DDQN algorithm see either my \n",
    "[previous blog post](https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/11/double-dqn.html) \n",
    "(or better yet read the [original paper](https://arxiv.org/pdf/1509.06461.pdf)).\n",
    "\n",
    "The DDQN algorithm uses the online Q-network parameterized by $\\theta$ to choose actions but uses \n",
    "the target Q-network parameterized by $\\theta^{-}$ to evaluated the chosen actions and compute the \n",
    "q-values. DDQN uses the following rule for computing the target.\n",
    "\n",
    "$$ y_i^{DDQN} = r + \\gamma Q\\big(s', \\underset{a'}{\\mathrm{argmax}}Q(s', a'; \\theta_i); \\theta^{-}\\big) $$\n",
    "\n",
    "In the cell below I provide my Python implementation of this update rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_q_learning_update(states: States,\n",
    "                             rewards: Rewards,\n",
    "                             dones: Dones,\n",
    "                             gamma: float,\n",
    "                             q1: QNetwork,\n",
    "                             q2: QNetwork) -> torch.Tensor:\n",
    "    \"\"\"Double Q-Learning uses q1 to select actions and q2 to evaluate the selected actions.\"\"\"\n",
    "    actions = select_greedy_actions(states, q1)\n",
    "    q_values = evaluate_selected_actions(states, actions, rewards, dones, gamma, q2)\n",
    "    return q_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prioritized Experience Replay\n",
    "\n",
    "[Schaul et al (2016)](https://arxiv.org/abs/1511.05952) introduced prioritized experience replay \n",
    "which increased the replay probability of experience tuples that have a high expected learning \n",
    "progress (as measured via the proxy of absolute temporal difference (TD) error). For more details \n",
    "see my \n",
    "[previous blog post](https://davidrpugh.github.io/stochastic-expatriate-descent/pytorch/deep-reinforcement-learning/deep-q-networks/2020/04/14/prioritized-experience-replay.html) \n",
    "(or better yet read the [original paper](https://arxiv.org/pdf/1511.05952.pdf)).\n",
    "\n",
    "In the cells below I provide and implementation of the TD errors for both Q and double Q-learning \n",
    "as well a an implementation of a `PrioritizedExperienceReplayBuffer` that encapsulates the key \n",
    "ideas from Schaul et al (2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDErrors = torch.Tensor\n",
    "\n",
    "\n",
    "def q_learning_error(states: States,\n",
    "                     actions: Actions,\n",
    "                     rewards: Rewards,\n",
    "                     next_states: States,\n",
    "                     dones: Dones,\n",
    "                     gamma: float,\n",
    "                     q_network: QNetwork) -> TDErrors:\n",
    "    \"\"\"Q-learning temporal-difference (TD) error.\"\"\"\n",
    "    expected_q_values = q_learning_update(next_states, rewards, dones, gamma, q_network)\n",
    "    q_values = q_network(states).gather(dim=1, index=actions)\n",
    "    delta = expected_q_values - q_values\n",
    "    return delta\n",
    "\n",
    "\n",
    "def double_q_learning_error(states: States,\n",
    "                            actions: Actions,\n",
    "                            rewards: Rewards,\n",
    "                            next_states: States,\n",
    "                            dones: Dones,\n",
    "                            gamma: float,\n",
    "                            q1: QNetwork,\n",
    "                            q2: QNetwork) -> torch.Tensor:\n",
    "    \"\"\"Double Q-learning temporal-difference (TD) error.\"\"\"\n",
    "    expected_q_values = double_q_learning_update(next_states, rewards, dones, gamma, q1, q2)\n",
    "    q_values = q1(states).gather(dim=1, index=actions)\n",
    "    delta = expected_q_values - q_values\n",
    "    return delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Experiences = np.ndarray\n",
    "SamplingWeights = np.array\n",
    "\n",
    "\n",
    "_field_names = [\n",
    "    \"state\",\n",
    "    \"action\",\n",
    "    \"reward\",\n",
    "    \"next_state\",\n",
    "    \"done\"\n",
    "]\n",
    "Experience = collections.namedtuple(\"Experience\", field_names=_field_names)\n",
    "\n",
    "\n",
    "class PrioritizedExperienceReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store priority, Experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size: int,\n",
    "                 buffer_size: int,\n",
    "                 alpha: float = 0.0,\n",
    "                 beta: float = 0.0,\n",
    "                 beta_annealing_schedule: typing.Callable[[int], float] = None,\n",
    "                 random_state: np.random.RandomState = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize an ExperienceReplayBuffer object.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        buffer_size (int): maximum size of buffer\n",
    "        batch_size (int): size of each training batch\n",
    "        alpha (float): Strength of prioritized sampling. Default to 0.0 (i.e., uniform sampling).\n",
    "        beta (float): Strength of the sampling correction. Default to 0.0 (i.e., no correction).\n",
    "        random_state (np.random.RandomState): random number generator.\n",
    "        \n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._buffer_size = buffer_size\n",
    "        self._buffer_length = 0 # current number of prioritized experience tuples in buffer\n",
    "        self._buffer = np.empty(self._buffer_size, dtype=[(\"priority\", np.float32), (\"experience\", Experience)])\n",
    "        self._alpha = alpha\n",
    "        self._beta = beta\n",
    "        \n",
    "        # if not provided, assume constant beta annealing schedule\n",
    "        if beta_annealing_schedule is None:\n",
    "            self._beta_annealing_schedule = lambda n: self._beta\n",
    "        else:\n",
    "            self._beta_annealing_schedule = beta_annealing_schedule\n",
    "        \n",
    "        self._random_state = np.random.RandomState() if random_state is None else random_state\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Current number of prioritized experience tuple stored in buffer.\"\"\"\n",
    "        return self._buffer_length\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        \"\"\"Strength of prioritized sampling.\"\"\"\n",
    "        return self._alpha\n",
    "\n",
    "    @property\n",
    "    def batch_size(self) -> int:\n",
    "        \"\"\"Number of experience samples per training batch.\"\"\"\n",
    "        return self._batch_size\n",
    "    \n",
    "    @property\n",
    "    def buffer_size(self) -> int:\n",
    "        \"\"\"Maximum number of prioritized experience tuples stored in buffer.\"\"\"\n",
    "        return self._buffer_size\n",
    "\n",
    "    def add(self, experience: Experience) -> None:\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        priority = 1.0 if self.is_empty() else self._buffer[\"priority\"].max()\n",
    "        if self.is_full():\n",
    "            if priority > self._buffer[\"priority\"].min():\n",
    "                idx = self._buffer[\"priority\"].argmin()\n",
    "                self._buffer[idx] = (priority, experience)\n",
    "            else:\n",
    "                pass # low priority experiences should not be included in buffer\n",
    "        else:\n",
    "            self._buffer[self._buffer_length] = (priority, experience)\n",
    "            self._buffer_length += 1\n",
    "\n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\"True if the buffer is empty; False otherwise.\"\"\"\n",
    "        return self._buffer_length == 0\n",
    "    \n",
    "    def is_full(self) -> bool:\n",
    "        \"\"\"True if the buffer is full; False otherwise.\"\"\"\n",
    "        return self._buffer_length == self._buffer_size\n",
    "    \n",
    "    def sample(self, episode_number: int) -> typing.Tuple[np.array, Experiences, SamplingWeights]:\n",
    "        \"\"\"Sample a batch of experiences from memory.\"\"\"\n",
    "        # use sampling scheme to determine which experiences to use for learning\n",
    "        ps = self._buffer[:self._buffer_length][\"priority\"]\n",
    "        sampling_probs = ps**self._alpha / np.sum(ps**self._alpha)\n",
    "        idxs = self._random_state.choice(np.arange(ps.size),\n",
    "                                         size=self._batch_size,\n",
    "                                         replace=True,\n",
    "                                         p=sampling_probs)\n",
    "        \n",
    "        # select the experiences and compute sampling weights\n",
    "        experiences = self._buffer[\"experience\"][idxs]\n",
    "        \n",
    "        # compute the sampling weights\n",
    "        beta = self._beta_annealing_schedule(episode_number)\n",
    "        weights = (self._buffer_length * sampling_probs[idxs])**-beta\n",
    "        normalized_weights = weights / weights.max()\n",
    "        \n",
    "        return idxs, experiences, normalized_weights\n",
    "\n",
    "    def update_priorities(self, idxs: np.array, priorities: np.array) -> None:\n",
    "        \"\"\"Update the priorities associated with particular experiences.\"\"\"\n",
    "        self._buffer[\"priority\"][idxs] = priorities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling Network Architecture\n",
    "\n",
    "The motivation for the new Q-network architecture developed by Wang et al (2016) is the observation that in many practical applications it is unnecessary to estimate the value of each action choice in every state. In some states, it is obviously critical to know which action to take (think of an autonomous vehicle about to hit a pedistrian!), but in many other states the choice of action has no real, observable impact. Bootstrapping-based RL algorithms, however, estimate the value of each action for every state.\n",
    "\n",
    "![](my_icons/dueling-network-architectures.jpeg)\n",
    "\n",
    "The lower layers of the network are shared and can be though of as a kind of feature extractor. Instead of following these layers with a single sequence of fully-connected, dense layers, the dueling network architecture splits into two streams of fully-connected, dense layers. One stream of fully connected layers is used to estimate the value function directly, while the second stream of layers is used to estimate the advantage function. The two streams are then re-combined using equation ??? above to estimate the Q-function.\n",
    "\n",
    "There are some technical issues given any Q-function it is not possible to recover both V and A functions uniquely (technically, this means that the parameters $\\theta^{F}, \\theta^{A}, \\theta^{V}$ are not identifiable from the data). In order to solve this issue Wang et al (2016) force the advantage function estimator to have zero advantage for the chosen action. That is, we let the last module of the network implement the forward mapping\n",
    "\n",
    "$$ Q(s, a; \\theta^{F}, \\theta^{A}, \\theta^{V}) = V (s; \\theta^{F}, \\theta^{V}) + \\bigg(A(s, a; \\theta^{F}, \\theta^{A}) − \\underset{a'}{\\max} A(s, a'; \\theta^{F}, \\theta^{A})\\bigg) $$ \n",
    "\n",
    "trying to An alternative module replaces the max operator with an\n",
    "average:\n",
    "\n",
    "$$ Q(s, a; \\theta^{F}, \\theta^{A}, \\theta^{V}) = V (s; \\theta^{F}, \\theta^{V}) + \\bigg(A(s, a; \\theta^{F}, \\theta^{A}) − \\frac{1}{|A|}\\sum_{a'}A(s, a'; \\theta^{F}, \\theta^{A})\\bigg) $$ \n",
    "\n",
    "Since the output of the dueling network architecture is a Q-function, it can be trained with either the DQN or DDQN training algorithms and can also take advantage\n",
    "of other advances such as better replay memories, better exploration policies, etc.\n",
    "\n",
    "In the cell below I wrap up these ideas into a PyTorch `nn.Module`. All the action is in the implementation of the `forward` method of the `DuelingDeepQNetwork` module which will be used to compute the forward pass during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class DuelingDeepQNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 advantage_q_network_fn: typing.Callable[[], QNetwork],\n",
    "                 feature_extractor_q_network_fn: typing.Callable[[], QNetwork],\n",
    "                 value_q_network_fn: typing.Callable[[], QNetwork]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._advantage_q_network_fn = advantage_q_network_fn\n",
    "        self._feature_extractor_q_network_fn = feature_extractor_q_network_fn\n",
    "        self._value_q_network_fn = value_q_network_fn\n",
    "        self._initialize()\n",
    "        \n",
    "    def _initialize(self):\n",
    "        \"\"\"Create the various Q-network instances.\"\"\"\n",
    "        self._feature_extractor_q_network = self._feature_extractor_q_network_fn()\n",
    "        self._advantage_q_network = self._advantage_q_network_fn()\n",
    "        self._value_q_network = self._value_q_network_fn()\n",
    "        \n",
    "        \n",
    "    def clone(self) -> \"DuelingDeepQNetwork\":\n",
    "        \"\"\"Return a DuelingDeepQNetwork with the same network architecture as self.\"\"\"\n",
    "        q_network = DuelingDeepQNetwork(self._advantage_q_network_fn,\n",
    "                                        self._feature_extractor_q_network_fn,\n",
    "                                        self._value_q_network_fn)\n",
    "        return q_network\n",
    "        \n",
    "    def forward(self, X: torch.Tensor):\n",
    "        \"\"\"Forward pass combines the three Q-networks.\"\"\"\n",
    "        Z = self._feature_extractor_q_network(X)\n",
    "        advantage = self._advantage_q_network(Z)\n",
    "        value = self._value_q_network(Z)\n",
    "        return value + advantage - advantage.mean()\n",
    "        \n",
    "    def synchronize_with(self, other: \"DuelingDeepQNetwork\") -> None:\n",
    "        \"\"\"Synchronize the weights of self with those of other.\"\"\"\n",
    "        synchronize_q_networks(self, other)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring the `DeepQAgent` class\n",
    "\n",
    "Other than continuing to clean up internal implementation details, nothing really changed from the \n",
    "implementation of the `DeepQAgent` from my previous posts.  I added two additional parameters to \n",
    "the constructor: `alpha` which controls the strength of the prioritization sampling and \n",
    "`beta_annealing_schedule` (discussed in detail below) which allows the strength of the sampling \n",
    "bias correction (i.e., the importance sampling weights) to increase as training progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GymState` is represented by an `np.ndarray` with shape `(210, 160, 3)` and dtype `np.uint8`. Need to convert the `GymState` into a `DeepQAgent` internal representation of state which is a `torch.Tensor` with shape `(1, 3, 210, 160)` and dtype `torch.float32`. We can accomplish this by defining a pre-processing function that takes an `ndarray` input and returns a `torch.Tensor`. This function can encapsulate what ever pre-processing steps that need to be included to convert a raw `GymState` to a suitable `torch.Tensor`.  Here I make use of the `torchvision.transforms` module which contains exactly the transformation that I need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "GymState = np.ndarray\n",
    "\n",
    "\n",
    "def preprocessing_fn(state: GymState) -> torch.Tensor:\n",
    "    \"\"\"Converts a Gym state with shape (H, W, C) to a torch.Tensor with shape (1, C, H, W).\"\"\"\n",
    "    state_tensor = (transforms.ToTensor()(state)\n",
    "                              .unsqueeze(dim=0))\n",
    "    return state_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "Action = int\n",
    "Reward = float\n",
    "Done = bool\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __call__(self, state: GymState) -> Action:\n",
    "        \"\"\"Rule for choosing an action given the current state of the environment.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def load(self, filepath) -> None:\n",
    "        \"\"\"Load an Agent state from a saved checkpoint.\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def save(self, filepath) -> None:\n",
    "        \"\"\"Save any important agent state to a file.\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def step(self,\n",
    "             state: GymState,\n",
    "             action: Action,\n",
    "             reward: Reward,\n",
    "             next_state: GymState,\n",
    "             done: Done) -> None:\n",
    "        \"\"\"Update internal state after observing effect of action on the environment.\"\"\"\n",
    "        raise NotImplmentedError\n",
    "\n",
    "\n",
    "class DeepQAgent(Agent):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dueling_dqn: DuelingDeepQNetwork,\n",
    "                 replay_buffer: PrioritizedExperienceReplayBuffer,\n",
    "                 preprocessing_fn: typing.Callable[[GymState], torch.Tensor],\n",
    "                 optimizer_fn: typing.Callable[[typing.Iterable[nn.Parameter]], optim.Optimizer],\n",
    "                 number_actions: int,\n",
    "                 epsilon_decay_schedule: typing.Callable[[int], float],\n",
    "                 gamma: float,\n",
    "                 update_frequency: int,\n",
    "                 seed: int = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize a DeepQAgent.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        dueling_dqn (DuelingDeepQNetwork):\n",
    "        optimizer_fn (callable): function that takes Q-network parameters and returns an optimizer.\n",
    "        epsilon_decay_schdule (callable): function that takes episode number and returns 0 <= epsilon < 1.\n",
    "        alpha (float): rate at which the target q-network parameters are updated.\n",
    "        gamma (float): Controls how much that agent discounts future rewards (0 < gamma <= 1).\n",
    "        update_frequency (int): frequency (measured in time steps) with which q-network parameters are updated.\n",
    "        seed (int): random seed\n",
    "        \n",
    "        \"\"\"\n",
    "        self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # set seeds for reproducibility\n",
    "        self._random_state = np.random.RandomState() if seed is None else np.random.RandomState(seed)\n",
    "        \n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.backends.cudnn.deterministic = True\n",
    "                torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "        # initialize agent hyperparameters\n",
    "        self._memory = replay_buffer\n",
    "        self._number_actions = number_actions\n",
    "        self._epsilon_decay_schedule = epsilon_decay_schedule\n",
    "        self._gamma = gamma\n",
    "        self._update_frequency = update_frequency\n",
    "        \n",
    "        # initialize Q-Networks\n",
    "        self._preprocessing_fn = preprocessing_fn\n",
    "        self._online_q_network = dueling_dqn\n",
    "        self._target_q_network = (self._online_q_network\n",
    "                                      .clone())\n",
    "        self._target_q_network.synchronize_with(self._online_q_network)        \n",
    "        self._online_q_network.to(self._device)\n",
    "        self._target_q_network.to(self._device)\n",
    "        \n",
    "        # initialize the optimizer\n",
    "        self._optimizer = optimizer_fn(self._online_q_network.parameters())\n",
    "\n",
    "        # initialize some counters\n",
    "        self._number_episodes = 0\n",
    "        self._number_timesteps = 0\n",
    "        \n",
    "    def __call__(self, state: GymState) -> Action:\n",
    "        \"\"\"Epsilon-greedy action given the current state of the environment.\"\"\"\n",
    "        _state = (self._preprocessing_fn(state)\n",
    "                      .to(self._device))\n",
    "            \n",
    "        # choose uniform at random if agent has insufficient experience\n",
    "        if not self.has_sufficient_experience():\n",
    "            action = self._uniform_random_policy(_state)\n",
    "        else:\n",
    "            epsilon = self._epsilon_decay_schedule(self._number_episodes)\n",
    "            action = self._epsilon_greedy_policy(_state, epsilon)\n",
    "        return action\n",
    "           \n",
    "    def _uniform_random_policy(self, state: torch.Tensor) -> Action:\n",
    "        \"\"\"Choose an action uniformly at random.\"\"\"\n",
    "        return self._random_state.randint(self._number_actions)\n",
    "        \n",
    "    def _greedy_policy(self, state: torch.Tensor) -> Action:\n",
    "        \"\"\"Choose action that maximizes the Q-values given the current state.\"\"\"\n",
    "        actions = select_greedy_actions(state, self._online_q_network)\n",
    "        action = (actions.cpu()  # actions might reside on the GPU!\n",
    "                         .item())\n",
    "        return action\n",
    "    \n",
    "    def _epsilon_greedy_policy(self, state: torch.Tensor, epsilon: float) -> Action:\n",
    "        \"\"\"With probability epsilon explore randomly; otherwise exploit knowledge optimally.\"\"\"\n",
    "        if self._random_state.random() < epsilon:\n",
    "            action = self._uniform_random_policy(state)\n",
    "        else:\n",
    "            action = self._greedy_policy(state)\n",
    "        return action\n",
    "    \n",
    "    def _ddqn_algorithm(self,\n",
    "                        idxs: np.ndarray,\n",
    "                        states: torch.Tensor,\n",
    "                        actions: torch.Tensor,\n",
    "                        rewards: torch.Tensor,\n",
    "                        next_states: torch.Tensor,\n",
    "                        dones: torch.Tensor,\n",
    "                        sampling_weights: torch.Tensor) -> None:\n",
    "        \"\"\"Double deep Q-network (DDQN) algorithm with prioritized experience replay.\"\"\"\n",
    "\n",
    "        # compute the temporal difference errors\n",
    "        deltas = double_q_learning_error(states,\n",
    "                                         actions,\n",
    "                                         rewards,\n",
    "                                         next_states,\n",
    "                                         dones,\n",
    "                                         self._gamma,\n",
    "                                         self._online_q_network,\n",
    "                                         self._target_q_network)\n",
    "        \n",
    "        # update experience priorities\n",
    "        priorities = (deltas.abs()\n",
    "                            .cpu()\n",
    "                            .detach()\n",
    "                            .numpy()\n",
    "                            .flatten())\n",
    "        self._memory.update_priorities(idxs, priorities + 1e-6) # priorities must be positive!\n",
    "        \n",
    "        # compute the mean squared loss\n",
    "        loss = torch.mean((deltas * sampling_weights)**2)\n",
    "        \n",
    "        # updates the parameters of the online network\n",
    "        self._optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "\n",
    "        # don't forget to synchronize the target and online networks\n",
    "        self._target_q_network.synchronize_with(self._online_q_network) \n",
    "    \n",
    "    def has_sufficient_experience(self) -> bool:\n",
    "        \"\"\"True if agent has enough experience to train on a batch of samples; False otherwise.\"\"\"\n",
    "        return len(self._memory) >= self._memory.batch_size\n",
    "    \n",
    "    def load(self, filepath: str) -> None:\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self._online_q_network.load_state_dict(checkpoint[\"q-network-state\"])\n",
    "        self._target_q_network.synchronize_with(self._online_q_network)\n",
    "        self._optimizer.load_state_dict(checkpoint[\"optimizer-state\"])\n",
    "    \n",
    "    def save(self, filepath: str) -> None:\n",
    "        \"\"\"\n",
    "        Saves the state of the DeepQAgent.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filepath (str): filepath where the serialized state should be saved.\n",
    "        \n",
    "        Notes:\n",
    "        ------\n",
    "        The method uses `torch.save` to serialize the state of the q-network, \n",
    "        the optimizer, as well as the dictionary of agent hyperparameters.\n",
    "        \n",
    "        \"\"\"\n",
    "        checkpoint = {\n",
    "            \"q-network-state\": self._online_q_network.state_dict(),\n",
    "            \"optimizer-state\": self._optimizer.state_dict(),\n",
    "            \"experience_replay_buffer\": {\n",
    "                \"alpha\": self._memory.alpha,\n",
    "                \"batch_size\": self._memory.batch_size,\n",
    "                \"beta_annealing_schedule\": self._beta_annealing_schedule,\n",
    "                \"buffer_size\": self._memory.buffer_size,\n",
    "            },\n",
    "            \"agent-hyperparameters\": {\n",
    "                \"epsilon_decay_schedule\": self._epsilon_decay_schedule,\n",
    "                \"gamma\": self._gamma,\n",
    "                \"update_frequency\": self._update_frequency\n",
    "            }\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        \n",
    "    def step(self,\n",
    "             state: GymState,\n",
    "             action: Action,\n",
    "             reward: Reward,\n",
    "             next_state: GymState,\n",
    "             done: Done) -> None:\n",
    "        \"\"\"Update internal state after observing effect of action on the environment.\"\"\"\n",
    "        state_tensor = self._preprocessing_fn(state)\n",
    "        next_state_tensor = self._preprocessing_fn(next_state)\n",
    "        experience = Experience(state_tensor, action, reward, next_state_tensor, done)\n",
    "        self._memory.add(experience) \n",
    "\n",
    "        if done:\n",
    "            self._number_episodes += 1\n",
    "        else:\n",
    "            self._number_timesteps += 1\n",
    "            \n",
    "            # every so often the agent should learn from experiences\n",
    "            if self._number_timesteps % self._update_frequency == 0 and self.has_sufficient_experience():\n",
    "                idxs, _experiences, _sampling_weights = self._memory.sample(self._number_episodes)\n",
    "                \n",
    "                # unpack the experiences\n",
    "                _states, _actions, _rewards, _next_states, _dones = tuple(zip(*_experiences))  \n",
    "                states = (torch.cat(_states, dim=0)\n",
    "                               .to(self._device))\n",
    "                actions = (torch.Tensor(_actions)\n",
    "                                .long()\n",
    "                                .unsqueeze(dim=1)\n",
    "                                .to(self._device))\n",
    "                rewards = (torch.Tensor(_rewards)\n",
    "                                .unsqueeze(dim=1)\n",
    "                                .to(self._device))\n",
    "                next_states = (torch.cat(_next_states, dim=0)\n",
    "                                    .to(self._device))\n",
    "                dones = (torch.Tensor(_dones)\n",
    "                               .unsqueeze(dim=1)\n",
    "                               .to(self._device))\n",
    "                \n",
    "                # reshape sampling weights\n",
    "                sampling_weights = (torch.Tensor(_sampling_weights)\n",
    "                                         .view((-1, 1))\n",
    "                                         .to(self._device))\n",
    "                \n",
    "                self._ddqn_algorithm(idxs, states, actions, rewards, next_states, dones, sampling_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Training Loop\n",
    "\n",
    "The code for the training loop remains unchanged from previous posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import typing\n",
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "Score = int\n",
    "\n",
    "\n",
    "def _train_for_at_most(agent: Agent, env: gym.Env, max_timesteps: int) -> Score:\n",
    "    \"\"\"Train agent for a maximum number of timesteps.\"\"\"\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    for t in range(max_timesteps):\n",
    "        action = agent(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        if done:\n",
    "            break\n",
    "    return score\n",
    "\n",
    "                \n",
    "def _train_until_done(agent: Agent, env: gym.Env) -> Score:\n",
    "    \"\"\"Train the agent until the current episode is complete.\"\"\"\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "    return score\n",
    "\n",
    "\n",
    "def train(agent: Agent,\n",
    "          env: gym.Env,\n",
    "          checkpoint_filepath: str,\n",
    "          target_score: Score,\n",
    "          number_episodes: int,\n",
    "          maximum_timesteps=None) -> typing.List[Score]:\n",
    "    \"\"\"\n",
    "    Reinforcement learning training loop.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    agent (Agent): an agent to train.\n",
    "    env (gym.Env): an environment in which to train the agent.\n",
    "    checkpoint_filepath (str): filepath used to save the state of the trained agent.\n",
    "    number_episodes (int): maximum number of training episodes.\n",
    "    maximum_timesteps (int): maximum number of timesteps per episode.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    scores (list): collection of episode scores from training.\n",
    "    \n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    most_recent_scores = collections.deque(maxlen=100)\n",
    "    for i in range(number_episodes):\n",
    "        if maximum_timesteps is None:\n",
    "            score = _train_until_done(agent, env)\n",
    "        else:\n",
    "            score = _train_for_at_most(agent, env, maximum_timesteps)         \n",
    "        scores.append(score)\n",
    "        most_recent_scores.append(score)\n",
    "        \n",
    "        average_score = sum(most_recent_scores) / len(most_recent_scores)\n",
    "        if average_score >= target_score:\n",
    "            print(f\"\\nEnvironment solved in {i:d} episodes!\\tAverage Score: {average_score:.2f}\")\n",
    "            agent.save(checkpoint_filepath)\n",
    "            break\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"\\rEpisode {i + 1}\\tAverage Score: {average_score:.2f}\")\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving `atari` environments\n",
    "\n",
    "In the rest of this blog post I will use the Double DQN algorithm with prioritized experience \n",
    "replay to train an agent to solve the \n",
    "[LunarLander-v2](https://gym.openai.com/envs/LunarLander-v2/) environment from \n",
    "[OpenAI](https://openai.com/).\n",
    "\n",
    "https://gym.openai.com/envs/#atari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab Preamble\n",
    "\n",
    "If you are playing around with this notebook on Google Colab, then you will need to run the following cell in order to install the required OpenAI dependencies into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# install required system dependencies\n",
    "apt-get install -y xvfb x11-utils\n",
    "\n",
    "# install required python dependencies (might need to install additional gym extras depending)\n",
    "pip install gym[atari]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below creates a virtual display in the background that your Gym Envs can connect to for rendering. You can adjust the size of the virtual buffer as you like but you must set `visible=False`.\n",
    "\n",
    "**This code only needs to be run once per session to start the display.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "\n",
    "\n",
    "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                    size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binder Preamble\n",
    "\n",
    "The code in the cell below creates a virtual display in the background that your Gym Envs can connect to for rendering. You can adjust the size of the virtual buffer as you like but you must set `visible=False`.\n",
    "\n",
    "*This code only needs to be run once per session to start the display.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "\n",
    "\n",
    "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                    size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('Atlantis-v0')\n",
    "_ = env.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `DeepQAgent`\n",
    "\n",
    "Before creating an instance of the `DeepQAgent` with prioritized experience replay I need to \n",
    "define a $\\beta$-annealing schedule, an $\\epsilon$-decay schedule, and choose an optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\beta$-annealing schedule\n",
    "\n",
    "Due to the inherent non-stationarity of the RL training process, Schaul et al 2016 hypothesize \n",
    "that a small sampling bias can be ignored during early training episodes. Instead of fixing \n",
    "$\\beta=1$ (and fully correcting for the bias throughout training) they increase the amount of \n",
    "importance sampling correction as the number of training episodes increase by defining a schedule \n",
    "for $\\beta$ that reaches 1 (i.e., full bias correction) only near the end of training.  \n",
    "\n",
    "Note that the choice of $\\beta$ interacts with choice of prioritization exponent $\\alpha$: \n",
    "increasing both simultaneously prioritizes sampling more aggressively while at the same time as \n",
    "correcting for it more strongly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some annealing schedue for beta\n",
    "rate = 1e-2\n",
    "_beta_annealing_schedule = lambda n: 1 - np.exp(-rate * n)\n",
    "\n",
    "_replay_buffer_kwargs = {\n",
    "    \"alpha\": 0.5,\n",
    "    \"beta_annealing_schedule\": _beta_annealing_schedule,\n",
    "    \"batch_size\": 64,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"random_state\": None\n",
    "}\n",
    "replay_buffer = PrioritizedExperienceReplayBuffer(**_replay_buffer_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\epsilon$-decay schedule\n",
    "\n",
    "As was the case with the DQN and Double DQN algorithms, the agent chooses its action using an \n",
    "$\\epsilon$-greedy policy. When using an $\\epsilon$-greedy policy, with probability $\\epsilon$, the \n",
    "agent explores the state space by choosing an action uniformly at random from the set of feasible \n",
    "actions; with probability $1-\\epsilon$, the agent exploits its current knowledge by choosing the \n",
    "optimal action given that current state. \n",
    "\n",
    "As the agent learns and acquires additional knowledge about it environment it makes sense to \n",
    "*decrease* exploration and *increase* exploitation by decreasing $\\epsilon$. In practice, it isn't \n",
    "a good idea to decrease $\\epsilon$ to zero; instead one typically decreases $\\epsilon$ over time \n",
    "according to some schedule until it reaches some minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_decay_schedule(episode_number: int,\n",
    "                         decay_factor: float,\n",
    "                         minimum_epsilon: float) -> float:\n",
    "    \"\"\"Power decay schedule found in other practical applications.\"\"\"\n",
    "    return max(decay_factor**episode_number, minimum_epsilon)\n",
    "\n",
    "_epsilon_decay_schedule_kwargs = {\n",
    "    \"decay_factor\": 0.99,\n",
    "    \"minimum_epsilon\": 1e-2,\n",
    "}\n",
    "epsilon_decay_schedule = lambda n: power_decay_schedule(n, **_epsilon_decay_schedule_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing an optimizer\n",
    "\n",
    "Given the good results I achieved in my previous post using the [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) optimizer I decided to continue to use that optimizer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "_optimizer_kwargs = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"betas\":(0.9, 0.999),\n",
    "    \"eps\": 1e-08,\n",
    "    \"weight_decay\": 0,\n",
    "    \"amsgrad\": False,\n",
    "}\n",
    "optimizer_fn = lambda parameters: optim.Adam(parameters, **_optimizer_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dueling Q-network architecture\n",
    "\n",
    "Now I am ready to create an instance of the `DuelingQNetwork` class. I need to define three, no-arg functions that return the `feature_extractor_q_network`, `value_q_network` and `advantage_q_network`, respectively. I am going to use the same network structure from the paper.\n",
    "\n",
    "* `feature_extractor_q_network` consists of three convolutional layers with ReLU activations. First convolutional layer has 32 filters each using a kernel size of 8 and a stride of 4. Second convolutional layer has 64 filters each using a kernel of size 4 and a stride of 2. The final convolutional layer also has 64 filters but uses a kernel of size 2 and a stride of 1.\n",
    "* `value_q_network` consists of two layers. The first layer simply flattens the inputs from the `feature_extractor_q_network`. The second layer is just a dense, fully-connected layer followed by a ReLU activation function. The final layer of the `value_q_network` outputs a single number representing the value of a particular state.\n",
    "* `advantage_q_network` also consists of two layers. The first layer flattens the inputs from the `feature_extractor_q_network`. The second layer is just a dense, fully-connected layer followed by a ReLU activation function. The final layer of the `value_q_network` has the same number of outputs as there are valid actions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, f):\n",
    "        super().__init__()\n",
    "        self._f = f\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self._f(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atari_feature_extractor_q_network_fn() -> QNetwork:\n",
    "    \"\"\"Defines the feature extractor Q-network.\"\"\"\n",
    "    q_network = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=8, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, stride=1),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return q_network\n",
    "\n",
    "\n",
    "def atari_value_q_network_fn() -> QNetwork:\n",
    "    \"\"\"Defines the value Q-network (computes the value of each state).\"\"\"\n",
    "    q_network = nn.Sequential(\n",
    "        LambdaLayer(lambda tensor: tensor.view(tensor.size(0), -1)),\n",
    "        nn.Linear(in_features=25024, out_features=512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=512, out_features=1)\n",
    "    )\n",
    "    return q_network\n",
    "\n",
    "\n",
    "def make_atari_advantage_q_network_fn(number_actions: int) -> typing.Callable[[], QNetwork]:\n",
    "    \"\"\"Return a function representing the advantage Q-network.\"\"\"\n",
    "    \n",
    "    def atari_advantage_q_network_fn() -> QNetwork:\n",
    "        \"\"\"Defines the advantage Q-network (computes the benefit of taking each action a given the state).\"\"\"\n",
    "        q_network = nn.Sequential(\n",
    "            LambdaLayer(lambda tensor: tensor.view(tensor.size(0), -1)),\n",
    "            nn.Linear(in_features=25024, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=number_actions)\n",
    "        )\n",
    "        return q_network\n",
    "    \n",
    "    return atari_advantage_q_network_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_ACTIONS = (env.action_space\n",
    "                     .n)\n",
    "\n",
    "dueling_dqn = DuelingDeepQNetwork(\n",
    "    make_atari_advantage_q_network_fn(NUMBER_ACTIONS),\n",
    "    atari_feature_extractor_q_network_fn,\n",
    "    atari_value_q_network_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the `DeepQAgent`\n",
    "\n",
    "Now I am finally ready to train the `deep_q_agent`. The target score for the `LunarLander-v2` environment is 200 points on average for at least 100 consecutive episodes. First, I will train an RL agent with $\\alpha=0.0$ and $\\beta=0$ (throught training) which will recover the uniform random sampling baseline. Then I will re-train the RL agent using prioritized sampling for comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 27s, sys: 2min 18s, total: 13min 45s\n",
      "Wall time: 10min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_agent_kwargs = {\n",
    "    \"dueling_dqn\": dueling_dqn,\n",
    "    \"replay_buffer\": replay_buffer,\n",
    "    \"preprocessing_fn\": preprocessing_fn,\n",
    "    \"number_actions\": NUMBER_ACTIONS,\n",
    "    \"optimizer_fn\": optimizer_fn,\n",
    "    \"epsilon_decay_schedule\": epsilon_decay_schedule,\n",
    "    \"gamma\": 0.99,\n",
    "    \"update_frequency\": 4,\n",
    "    \"seed\": None,\n",
    "}\n",
    "double_dqn_agent = DeepQAgent(**_agent_kwargs)\n",
    "\n",
    "uniform_sampling_scores = train(double_dqn_agent,\n",
    "                                env,\n",
    "                                checkpoint_filepath=\"uniform-sampling-checkpoint.pth\",\n",
    "                                number_episodes=1,\n",
    "                                target_score=float(\"inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the behavior of the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "def simulate(agent: Agent, env: gym.Env, ax: plt.Axes) -> None:\n",
    "    state = env.reset()\n",
    "    img = ax.imshow(env.render(mode='rgb_array'))\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent(state)\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, _ = env.step(action)       \n",
    "    env.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "simulate(double_dqn_agent, env, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the time series of scores\n",
    "\n",
    "I can use [Pandas](https://pandas.pydata.org/) to quickly plot the time series of scores along with a 100 episode moving average. Most obvious difference between the two different sampling strategies is that prioritized sampling reduces, perhaps even eliminates, the significant number of large negative scores. Perhaps this is because prioritized sampling replays exactly those experiences that generate, at least initially, large losses (in magnitude). Over time the RL agent using prioritized sampling learns how to handle those awkward state transitions that led to *really* poor scores much better than an RL agent that uses uniform random sampling throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15000.0,\n",
       " 25700.0,\n",
       " 12900.0,\n",
       " 20100.0,\n",
       " 15100.0,\n",
       " 14500.0,\n",
       " 21300.0,\n",
       " 40900.0,\n",
       " 27800.0,\n",
       " 20300.0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_sampling_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-7dd3504c366f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_sampling_scores = pd.Series(uniform_sampling_scores, name=\"scores\")\n",
    "prioritized_sampling_scores = pd.Series(prioritized_sampling_scores, name=\"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAFzCAYAAABVWI+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3xV5f3A8c9zR272DgmBkEUCIYwgYU8FQcFdFbW4xVX3qquuWqtd1q2o/Wm1RVutrVWKCqg4QNmyd4AwAiFkkXXH8/vjjtyb3CQ3ISEJfN+vFy9yzz3jOeee8T3PVFprhBBCCCFE92To7AQIIYQQQoi2k2BOCCGEEKIbk2BOCCGEEKIbk2BOCCGEEKIbk2BOCCGEEKIbk2BOCCGEEKIbM3V2AjpLfHy8TktL6+xkCCGEEEK0aMWKFcVa6wR/3520wVxaWhrLly/v7GQIIYQQQrRIKbWrqe+kmFUIIYQQohuTYE4IIYQQohuTYE4IIYQQohuTYE4IIQCtNTJWtegsZdVWiitrOzsZopuSYE60mtXu4MjRukbTy6qsHCyv6YQUNVZrs7Pr8FHu/sca6myODtlGcWWt3+MAsLe0mucXbm234KDO5uD77cUBzetwaN5ZUkCN1d7ivF9vOURZtbXF+Wx2B1uLKnw+u9f//bZiymuc69BaU1ReQ2WtDZv92I/7il0lHKqopdZm57GP13OoovmH3f6yaqyu7Vqb2X6dzcEv/r6SNXtKsdkdlFVbSX9gHq8t3oHd0fRvtnpPKQ6v7wuPVHHvP9dwtNZGRY3/47inpIq//eBbb1lrTcnROl79ejtfbCji/WW7m92v299bxe/mb2p0PpXXWCmtqvPs+8rdRxoteyxB6t7Saj5ff8Dz2e7QPsenzuZgbWEZz8zf1Oy1v3THYQY99hnvLCkAnPeKLzcdDCgNWmuemb+JWW/8wE+Fpc3O5309/t93O/l2q/OaqbHaeWfpLs+94PvtxXy1uX77K3cfYf2+MqrrnOd0VZ2Nqc9+zVebD3LHe6tYt7fMM++mA+W8vngHAEXlNXy0qpCD5TUUV9ZSeKQKcB631XtKWbL9MG98s4O7/7GGUU8txO7QfLetmB93lnjWV11n53BlLUMe/5z8Jxd4zi+HQ7OnpAqtnce8pd9Rax3QNd+UGqvd59x2K6+x8t6Pu1leUML2Q5UAHKyo4U9fbMFqd1Bnc/CXb3dyoKyGu/+xht2Hq9qcBoBtByv5/WeNz/WG5q87QFmV/2uu1mb3/JbethRVcMVffvTsq8OhKa2qa/La9afO5mj2HtFZ1Mn6Jpqfn69P9NasVruDrzcfYsqAxBbnrbM5KDh8lOzEiBbnveO9Vfx79T52/nY6SinP9EGPfUZFjY2Cp2c0WmbNnlKW7zrCtePS/a6zqLyGJdsPc97QXo2+e2reRj5YUcjKX53uM939AJw5vI/P9F2HjzLx91/5TFv1q9OJCQtqcp/qbA4OVdbSKzrE7/daa/aV1fh8n3b/pygFO3/ru7/e23/l56dw5qCeHCyv4Y1vd3LN2HR6RFjYXFRBenwYFpOBH3aW8NXmQ2iteWB6js+6Co9UcbiyjnNf+g6Az+6YQL+kCA6W17CmsIzhaTEUHqnmsteXkp4QTnpcKMPSYvnVv9dx86RM3l26ixHpcbx+xTCUUtz/4U/MW7ufJQ9M5oKXv2dzUQWnD0jkoek5LCsoYeP+Cj5du4+Y0CCSooIZkR7LeXm9+Mu3O3nj2508dvYApg/qyf3/WsuiTQdZ/vAU8p9cwJScRF6/Yhj9Hp5PnVcQ9ceLhhATZub3n22hrKqOO6Zkc9+HP/Hr8wZy+ahUyqqs3PvBGi4fncr4rAQcDs3yXUeIDw9i04EKbv7bSjLiw7h9Sha3v7eaabmJ3HdGfzITwlmwoYiXv9rGwYpashMjeOmyU8h5ZD5BRgMf3jSGs1/8llP7JTBzeB/Kq63M+WYH10/IYOqARF5YtI03v93Z5PkwMTuBH3eWMHt8OgaD4o4p2Xy3rZifv/EDvaJD+NVZObz1fQFLd5T4LFfw9AxW7CrhZ68sAeCb+07l6reWse1gJcsfnsIna/YxqHc0320r5k9fbGm03ecuyWNKTiJGgyLYbGRZQQlWu4PLXv8BgKcvGMQlI/pgtTsoPFLNqX9wnmfnDEnm4zX7AHjmZ4P45YdrAchNjmT9vnIAnjg3l3lr9/PEuQMJMhp4b9ke7pvWD4NB8ea3O9l9+CinpMZwbl4vVuwqoarOzv0frmVvaTUxoWaGpcayYV8Z+8pqWPHwFJRSPPrxev7r2i7g+V1f/Xo7b3yzk0fPHkBxZS2P/3eDZ55J/RKoqrXzY0EJC+6ayJIdh/lpTymr95Ty8FkD2FNSxatfb+ejm8fy9ZZDjMqIZdwzX3qW/+LOCZz+7GJmjerDP5cX0r9nJAYFQ3pH89b3Bcy5fBiZPcKZ/MevAdjwxDQGPPKZZ/mrxqTx1vcFAHx+5wT2lFRx7dv1z4JfntGfZ+ZvavTbvDrrFAb0jGLC751p6ZcYwWavFxy35y8dym1zVzWaDjAhO4HFWw4BEBpkZExmHAs2+ga17mP4xjc7ePLTjeSnxrB8l2+Q/tD0HK4Zl87G/eWkxoXyn9X7eOK/G6izO3hoeg4LNxUxPiuBw5V13DAxg1/9ex2fbygC4DfnD6RXdAgvLNqG1e7g1tOy2HawkmfmbyLEbKTaaifCYsJgUFwyIgWL0cDzi7Z5th0WZOSon0DJ24K7JvD99sOckZtEfLiFw0frCA0ycqC8hlv/voqnLhhEXko0hytriQu3sLe0ml7RIdTa7Ix9+kuKK2u5aVImNVY7D7nuiU9+upFrx6VzoLyG5OgQxj69CIC/XjOC7MQIVu0+wjfbivnNeQMZ+usvKK2ycuXoVM4ekkx+WiwA57/8Hat2l3LfGf14fuFWaqz196qU2BAW3DWRkqN12B2a3jGhOByavaXVhAYZWbTpINMH9ST3Uee5dG5eMqMz4iirtnJxfkqzz5f2opRaobXO9/udBHMnrj99vpnnF23jnWtHMD7Lb9c0Hr/69zreWbqLJQ+cRs8o/wGNW9r9nwKw9TdnYjYaWLn7CLPfXs5h11txwdMzOFprY97a/Vw4rDdKKTIe+BSHhi/vmcSWogqm5SZ51vf3H3bz4EdrPZ9fvGwoUwckMWfxdi4Z0Yf8Jxd41nuoopZb567kaK2dta635Qen9yc1Loxf/XsdBytqGZYaw4oGN7+5s0cRFWJm/b4ylmw/zL9W7eXW0/py9pBkFmwsYk9JFXN/3MPKX51OrNdFabM7mP3X5Vjtmm+3FXPjxEx+eUY/lFKe47DhiWnUWB08v3Arn68/wL4y3xyKX5+by6o9pfxr5V7AeRP4z+p9ZCSEUWt1sLe02jPvsNQYshPDeer8Qcz9cY/PcQFIiLAwPives65J/RL4avOhZn8v72XdOVvXT8hgjit34Vh4PxhP69+DRQHmtriZjQqrveV70Ij0WJ/cDH8+unkM57/8PQBXjE7lr0uabMXfaleMTmXTgYoW0/DQ9Bx+M2+j53O4xURlrc1rDo0BjQEHRhyYsGPGhgkHZmwEqzo0kJTUiycvGcOUZ79ttI2L83vzj+WFbd6XvJRoVu9x5nBFWEwMSYnm2231ub4PnNmf3/6vcTATqDevzPcJjo7VpSNSmPvjnnZbnzcjdoKpI4Q6glUtUVShAQMOgqkjWFkJxnlfs2KiDhO12kw5oWzTvTskTacPSGTqgETu/eCnDll/V+EOHK8bl84b3+7k8lGpfL7hAEXljXPfP75lLOe8+F2bt/XW1cN56cttLCtonHPdlB8fnMyIpxYGNO+Fw3rzh4uGtDV5AZNgzo+TIZi78/3VfLRqL8/OHML5Q+tvPFprFm8tZkJWvCdnbeqzX7OlqJL5d4ynf1Jkk+t0ODQZD84DYOMTZxBsNpD+wDyfeQqensE9/1zDBysK+dfNY8hOjGDgo5/5zPOvm8fw1eZD3HJqX8Y8vZDiSv/Fld5WP3I6eU98EfD+e5uYncDXWxoHPe4AJy4syBOMrnl0KmFBRm5/bzW9Y0J4rUHQ8+aV+bz1fQHfbPUt9gw0MDl2mjBqiFGVWKjzBAeh1BKEDStGLMpKijqIxvn7KjRm14PLQh0W10PKgpUwarAoK3+zTcGBQgNByoYFKybsXoGHw/O3QTn/d/6zO6d5PtcHK0blnF6pQ7jY+BVxqpxSHc5u3QPAtZTCgcKdx+tMAdgwEoSNMFVNEDY0oHyOAuzXcWx0pGJQDixGRZ3dQa0O4hBRRFKFDaNrC8712jFgw8gunUilDsGKkTrMWDFhwIFGUYeZWm1yTdMMMuykpzrs2qYzdTFU0s+wx3XMncfJiAOTcuZYGHGQpg4QQq3vsVGtOz+OagsVhFKoE9Dg+Q3cv4vJ6/gbXb9JqQ7jkI5mo+5DpQ7BpBzU6CAKdTwVhGLHQDB1hFJDuKrBipFljv5EU0mRjmEfcQ2OdNMiOUq160wxYSOeMo4QQS0dn0vROpoYKuilirnMuIhEdYQsVUgfQ2AvQv58bR/MAscp1GHGgAMbRo7oCEp1GEY0IaqGBFVGtbYAYEBTg5nvHbkYcRBONeGqmnIdRiUh2DBgwkGUqqRch5KuDjDT+CVWnOdi/fXmPAfsGLBiwoaRKiwU6gRqtZlwVcMww2bM2KnDTJ02EaGqsGDFihEbJo7ocCoIxYzzOk9RBwml1nMOARzREYRSQwkRFOgkgrAShI0gbM6XEGXjqA7mKMGee4kG7BixYSRGVRBBNQU6iSIdzQpHNrt1IjYMVGOhBkvAx3ru7FFc+vrSNv9WreO8V1pb2Q3v/Wf258aJmR2UJqfmgrmTttPgk4G7BLRh1aF5aw/wi7+vZMagnjx6zgBMBgNbipx1IX4qLKN/UiRWu4OHPlrL7PEZZCVGYLU72LS/gote+96znp+/sZSpXjlsbntKqlhb6Mw1q7HaedZPcdIFrhyU5xduDXh/pj/3TcDzNuQvkIP6R9Zhr7o2n68/QEZCOJ+u3e93maZyHdoSyIVRTawqJ4kjJKojGHAQpJwPxVRVRG91iGKiiKOcJFVCtDpKNBUEqbbXjXGr1kHUYiZaHQXgHOOSY16nPw6tMLiCmG/tuTgwEK6qXQGWwxWMajR4gk8AM3Z6xESyqcRMJSEonAFcVGgQZVV1hKtqTjOs4kzjsvptGeu31dFKdRhFOoZazK4HmAGbdt5S7RhYqnPYr+NcYZeh/n/tDmANnmDSjoFbpuTw2y8KMKCJVRVEqCrCqCFBldJTlWDVRqpdwagdg2eb47MT2VhURWFZHVpDb1VMP8MeJqi1LeyBf4d1BKU6nCBsKKWxawNVWCjVEdRixoqRSFVFhtpHgnIW4dZpo+ecdGjFQaIp0ZFUYSGYOg7oGK6z3gMojNidgQzVVGOhCgu1mNHHWIX7euN/GWdYR7wqx0IdwarOmbtGHSHKioH6G+EWRy8OEMtHtnGU61DuOGMwj/1vJwblfBmowkINQdRoMzUEEWQ0gL2OIGUjhFoeNP2dicafmGjs+Nwzm3YGPw6U63d3nkdGHESaNVZrHWHKNzfLYQqh3JxAZZUziLNhpFSHe3KCexmKUWhPoHhEh1NEDHZtxIqRcFVNinLmso9QmzDioA4TdZixKRPhoWEcqLQRbagkCBs2gwVLSCglR+tc27C7AjsDk5X/IudiHYkGVjmyMLkCz5WOvhToJEp1OAU6iYPEAPDil4E/J5pjxE62KqSPOkgwtUxPLCXj8NdEqwosWLFgw6Kc9ec2O3rzgyOHMsKI4ihFOoYywqjFTDzlVBDCfh3rSXuYPbld0thWEsydwAyuaM7RIPfV3WLq07X7WbLjMHdOyfJ8d98HP3Fxfgpr95bxj+WFfL/9MAvumsjMOUtZs8e38vHK3aWs3N24QvL439XXb3lx0Ta+3364XfanYfFlezjop0L9vR/8RP+klusONmdc33gmZMfz1LxNKBwMVAUkqRLO61WO4cAaYlUFg427CNHVTa6jWEeyX8eSRhGVBLNDJ3PEEU4p4ZToCIb0y2BnqZ2NB46iUVQTRC1BmLHhwMBBHc1RHewJkC4cmcFNk3O59YMNLNhSSn0oqzlFbSUpFMqqa1HA1RP7MTm3D5sPVREZEszfl+9l3vqD2DEw/45TuXDODxQftWH3BBb1AYtv8KIwGRRhjkqsmKgi2Gcfzx6S7Klztf2p6VjtDvr/ar7n+xdOG8qtDeof/fPS0Vz9qjPwNOBgcO9oNhVVUGN1nuc9OUy8KnMFUu5w0bmvvaKCqCg/QqoqwowdE3aCsHqOmUJjUVZmj+nN3uIyFm05zFEdTHXP4azaW0WI2UCtq5L5fmI5rX8SQ/tEc2r/Hvzi7eXsK6shyGTgshF9WLX7CGsKy7h3Wj9iQoMaFZmnxYUya1QqT366kbF940icNJL/fOabyx0daqbUVcn7hokZTMlJ5CLXvv/tupHsLa0mKj+FrMpaLnFVR3D/pkHYsGFkck4S327cTao6yO/O6Uu/xFC2HLZx67+2clQHE6/KGaB2UYWFeFXGQFVAcqidYZlJ/G/dAQw4CKOGaFVJNDWYsVNDEEscudSF9GDnUQvhqppLxvbnhW8PEEEVvVQxMaqSUGrIN25hIAWsNNzAIR1NijpEaIPgo0abKSGCb+yDWaGz2OJIYY9OoBYztQRhx0CQKyixYSSEWqb2tnF4305CqeHR6X1J+uI9jEqzI2Y864ut1DiCqCEIU3AYl47JhtA4fvHxPrbqXmzRKYCz+O5orZ2IzDieGeOg70P/80nXsoem8NzCLYzrm8CN764gJsTM9RMyOX3+UIKpdeZqY+Xft07gghe/JpoK5s7qR0SIhQtfX85hojg1K4bvtpXwi9Oy+N+iRWSo/VRh4ZGfjeTuf28lwl6KyVXUrtCUEUYIdUSqo3xhH8Z6nc6nt43j3aW7GhU3Fzw+gwVr93PP374nhgosysotE9O44PRJRBlM5DUoNfE+P5rKfb13Wj9+/9lmz2eFwxNov3jZUM4anIzDoZnwYP2637wyn8k5iYx0VT1puK00dYChahthqgYjDiKoIt2wn2DqGKB2kaxKOEI4Z3i9mNm1YrXuy3ZHMrUFZk4zmRmQksAp6QnsKqlh0bpdmLBToUOxKCuJ6gjB1BJLJUZlR6Ep12FYMWGhjoGGAiI5ikV5VXs4oviBfvxo708tZhxGC0dtRqKpYIBhFxcbv8KMLaAc9VX7qoChLc7XUSSYO4EZ6p/VPkKCjJ6/S47WscpPQLanxNkiqfBINXe8t7pRIBeoQAO5CIuJCp+6RfUs1JGkSijSMa6seU0virEoK0U6BgOaiYY12DCS37cXa7btIstQSC9VTF+1j2RV7Mn63+VIpIYgSglHoanTJioJoUjHsEsn4nDlfBwqiiZNWQihjiy1l1zDTuwYyTdsplAnsNSRg0aRog5SoiPRKGedJ+oIVbXMsESQuvcIkyJ2klK3nRDlyvk7BJWGYPbrOFTeZfz2xyoOE0mxjqRQJ3hya8p1GGWENzoWN07M5NWvtwPw3OA8bs2rbzDy2foD3PDOCgCenTmEO99f47Ps1BGDCYmM4qUrRtPvYWfAdNvkLJ5fuJWVOpt7x/Xjzwu2YLVrHho8HnpG0s9VOn93/+G8+ch8qursBCdm8smvnMUJe0qqiA41E2QyeNY5Mj2WH3aW8PEtY0mLD+Os579ldwm8c+0INh+o4MlP6+uUnTkwiTumZLFhXzlGg8JoMLLgrolM+ZOz8vr0QT3ZX1bNrFGpzFm8g+SoEPJTY/jDRUO4559rcGDgspFp3PdhfQ7JfuLYr+O4caKzAvXUAYmU19i48d0VJIdEUFhmptBVzJsaF8quBq3vjAbF72dMx3Cwknc2fs3frhvJ7+Zv4gBlvHPFCPolRvDV5kNclN/bpwHQ9w9M9lnPM/M3saawDK01ceGNix2/uvdUAH4+MhWTUfmsy+3swcm8s9RZ9+/eqf0wGZ0P1bOHJDO2b7xnvrhwC3+/biRPz9/ET4Vl4CouLnh6Bn/8fDNfbAxmk+6DNTkfS2oMgzKg5gsbh8prOKRj2KhTfbY7KCKK/84chz1jD7ERFq5+a5nP93dOyWZivwQGJkd6AqArJ0/jL1/7VqcAmB5XzqNH7meP7kGxjqI8bgjzD0ZTQSgh1BFKLb3UIdLUAWaavmImXzVahzdPTm8xeEpzFwAKrq27mzdvf4QdG4qIMCqu+r9lXDU4DU7LBWC4fSefejXGGNw72vO3+9h6S4iw8OR5g/jeVafQZDQwJCUKgBpXUeGUnB6Yo3tRqBMoJIGI3KkA3H7NAHpEBNPP9WL4/fZi/udw5oIvuGsCqkcE8/89nyp7fS57iNnIyIzYRvVgEyIsNFUjKqtHOFUEU0UwO5+qb5TW8GwKMhqoszsYnxXvU0XkszsmkBQVzLdbiymrtjI6M84TzJ3SJ9rnhd3sOkYGg2L2+HRe/2YnV41JY3JOc43sFAW6JwW6pycNANi953BWcchU+wijhkhVxTjDOkYZNjDOuBYLVkIMdkIP2mF/LdlAX4sFm81GkLLj0IpazOzXsdhC4klPjOWnwjKSbYcBjR0jBcE5RPXO4fVNZsqj+vPaNRMhLI6Zj9eXNt0+MYv/+24n5TUNn0WaJEo8VSmKdAwRVJGhDmBz5ZJe3ntMJ4ZyEsyd0Nw5c5+s3c95Q3thdj0wGtaT/NeqvT6fj9baOFpbf6XN9+qaoDk5PSPZuL+8TWmdkJ3AT+tWc0PaIex7lhGuqkmgjGBVx1DjTszaGQzVaDNWZSYC5wPYrhUOZcSM6+LbjecGX6vNrNaZfOMYjAZiqSBCVRNNJf3UHrRWJBlKMAdQZGnXzhyeo4Ywhjh2cIGxccV0N6s2Yt4XCeFJ9E2KZlHpmQwYOo7k7GHUxWQy8NfOirwF587gtSXON9kFd03gv2v289zCrX4roHvXZewTG8qDH60lM8E32JuWm8SHN41m7o97OC+vF9V1Dp/cIHesYDEZPZWPpw5IpMZqZ87iHXjHEmZj48Bi8X2nUt6gG5OU2NBG8825PJ9NB8p9HpTOdRoazW9QkJkQ7rMvfXuEs+juiTi0M7C6foIzcLxjSrZnnguH9eaefzqDVYNB+bTgdLt7arbn4fOd62EcEex7yzP7eYAbXQeib49wT8vskRlxrCksI6dnJPHhFi4entJouYbcR9ChYeqARF67fBijM+P4aU8ZI9JjPfN5v1w11M8rh9gdbGx58kyMhsa/z5i+8aTFhbmCOf8spvr9/d2Fg7niLz/6nc/drYt7P9+7fhSXzFnKS5edQlx4EKMy4hotE2zyvx+9s/MYufhlAG45tS/3TOsHBSWYjQbOe+k7ZgzuySs/Oas0xFrLiVEV9Fd7iFXlBGF11chzFvNZsHLRKT2JiowiokcqRPWCoHAwWdhVaeB6nAGuuwX/N/edSs+o+tzgq8amkxgZzE1/W9nkMfLHO9AzeF0oMwb15I8XD/HbDU7DRmdGr+WCzb7Hyt1CdOHdE4kONfu0vgUwGQyNSlj8pa3hC0Gf2FB6RFi4bnwGA3pGsqO4ki9crVq95wkJMjJjcE+g/kXeH4OfF47k6GA/c/rXKyaEL++Z5Gk85ubO+duue7kn8K1jkOf7NY9OxRxkBKMBtAbt4EB5HWOeXkgPSjlElGcdl+al8NsLBnPn775kd0mVp9Xx5Iwe3DQ+k3+uX0JfUzjE922UvtGZcYRbTD6NmJwUB4jzpA2cwfwhHeOZ4+KIPnQmCeZOAE/N28i/Vu7lu/tP5bP1RaTEhPDlpoOeYsnFWw6R/fD/uO20vtw1tZ9PoOZP7qOf8fCMnGbn8SclJsQnmIukkkpCcWAANE9Miua9r9dQixmA0YYNjDas54iO4NT9RfSyrIP9UGkMpgxnJW4bRqqHXMlDy6Cv2kc0laigEDbXxlFGGOnqAH3jgvh3eTYVtQ5mTx7E898dZGdVMIeJ4n+3j2emV127/kkRbDpQ351AKDWulmtWUtUBgpSNUGoIwsYtE1KYs3gH+3Q8N18+k6FpPbjg5e8pKK4gWRWTEG5hR4URM3YiQoI4VK1dS5ooeNwZBBiAKV7HyNhE/0TJ0SHcMSWLX5zal49WOVsqnj4g0XPj9W6UcumIFCb2S/Dbjcqw1FiGpToDhagQ53Ge3L8HeSnRDOhZv467Ts/mD59vpm+P+iDK+0ZtMjQOcuLDLcSHN11p+S9X5WMyGIgKNTPS62HvXq3ZaPB5oLm+9buujITGuZINTR2QyOcbijAoGJkZ7/NdkMngE6i5+5wKs/je8mptja8FP7vOvdP6ccXo1Gb3v9F6vKo5KKU8LbjHZcU3t5gPfw3Ugkytq1vmfYSDzfXLDkmJbjyzS8N+tEZlxPHTY1OJDDY3uYzBT4A5M9836HX//MNdXUUUPD2DT37ax6euYK6ESEp0JNt1L+LDg3h4xgBSYkOZs3g7n60v4uEZOfQen+F3+6k9ILXBNH8vGwN7RTW5D03xDp699zIpKrhRYBbIOhq+RLx+ZT6FJdUkR4f47Z/RaFD0jmm8LwAmP8fdbfF9p/p87hMXyoKNvsGc9zkBvueXv9ziQLhfFhtqLq1u0aFmMuLDfHIE3fcyV6JAGYkJDQKUp16dm/u6066oy/tlyR34+kvG2semEhFsZlRGnE8wd9fp2X67EWqosxuTSjDXzf1u/iZPFxMHy2ub7N8I4PlF2ygsrSYjPqzF9frrcLEpCgdxVDDd9hOTTUtJUQfprQ7Rx3CICh3CPh1HvCojbmkFVzR4FhbpaIKwERXeF0Y9DlmnM/jZHa4A0KngvBnsPriEf7j69OoRYuGgvb7OzfQeSSypOMwRh5Ub+ozkg8nxnje/9Ab72vB6c9fhqgSKdZTnrSs1LpTcM07lP1851xMaHEJ0aBB2rXFgoFD3wKoslOFMh02ZqaTljiebupcFGQ0opQgyKU+7Tn+5Y+C8wTbVH563abmJ3DY5i2vHpfveDIHZEzK4bny6z83ae2umJrbdnNP6+y9qca8pyGholKMUwL29RQalPH08ufvkarhai+uBldUj3KcIq3d0KOKnRJUAACAASURBVHtKqvndhYNJiwvj4teW+Ak4nQ/fph6mTRmTGceLX25jRFpsyzO7/O/28ew6fJQb33XmHLX348HilXtm8Xlo+14bvzyjf6NlmwvkmvLMhYN5yuvB6O/n9pfbA84Axt3vZK/o1h375vjLjW15Ga/rpInzoyXewa77OnBPSY4KYYzrhcRfca/JoLh5UiZVdXbOzUvmTK8X1LZcq253nZ7daH8CCbiaEhsWRMnROoLNBr/BnL8c5YbumJzFUwF0jdNUjrZ7G+7zOdQ7mPMc9/p0uIudI5o4v88ekhxgMNfiLB3qhAnmlFJnAM8BRuANrfXTnZykDvfDjsO8/NV2z+eH/72uxWX+tXIv5/vpmLehKteFGEINOWo3DgyEKGeF335qj6elZZCyka0KiVRVsBtKjOHs0Mls1Km8bz2VfoY9RFPJOpVNTPop/GtzLZGqikodzBadwiadAigKbqzveNdBQaP0xDWTI2L0ykppmKvS1hvTBUN9+5Ayux58Nq8Wq94Xb6AXcsMb57TcRD5bX9TEDfzYWveZjAbuOj27ye8bpsV7F9rywGuJ2aQa5d545wy2lVLO/txWPDyFwiPVng6WvY3rG88Llw5lWm4Sr3/j7Cy44OkZ3PSus45hZLCJtDhnwOAvh6ktxvSNZ93j0wi3BH6bzekZ6RM4+OuRv9W8fmeLVy5MUDO/cSAdjR9rWjyTmpj1WM//pjT1ktTQpH71xaTeAYL3LqgG3zfH+yXB3GDfzC3kthoNCpPRwP1nNg6yj+U4NcyVayktLe3l+9eP4sOVexncO4qb/RRlBxJ4mowGQoOMbR65x5Mz57p0QrxyTt0/gfdv+PoV+c2OghPiJ+fVXV/QW1PF4MfLCRHMKaWMwEvA6UAhsEwp9bHWekPzS3ZNpVV1RAabfR4qa/aUktkjnPJqK/9ds4/rxmc0aknaVPcbDX3UoI6cWzQVjDWsp79hNyO2GRll3soow0ZPU21vRTqa/TqWWoL4r300BTqRQePO5ravHfhc8q6Xs6gQM5cl9uGTjdsbrau1Gl4y3gFbw7f8hjdZjW5UAdifhkVZ7puvd/GTdzramsX+wqWneIbCauhY3riP1bG8nTe9zvpi1hFpsbx5VX6Tb8Ot4f7N48ItfjscBWfgevaQxl0H1N+AledcCeTBHKjWBHJu3oF0e48a5J0zZ2hQdOje1LTc1gVyGfFh7Cg+GtC8/o5sUyV5PkWbrj/b43np78WpoYaj2Hj/Jt7JbU0ppPf+uK9t9wuVuYVzrrnr8Viu1WGpMY2mNQw0AXpGBbO/rIbw4ObP56zECE/A+eqsYdzoelly85fr3ZDJoAg1GykNoKTDn4bXr7sYXFN//ng/J4LNxmaLyv1Va3hoxgD2ldb4dF/V2SN8nRDBHDAC2Ka13gGglHoPOBfodsHc/rJqRv92EQ9O7++p+F1dZ+fcl77zGQqmosbWqhuJP1FUMtSwjaGGbUww/MQQtR2D0ti14mhxKAcN0bxjn8JSxwBsGDwdga5xZDbqYgLgmfiBgP++rYwGdUzj2TW3q0Y/xRee5RrmPml459qRvPLVdr9D9rg1CuZMzvXYm3iatHXPgkyGJuthNVX81FG8t9ZSTkGr1utuXae8ck4VxxzIuY+593FqbSCWlxLDZ+uL6B0T4rmhn9a/xzGl61h5n3vt/bZvaeJ3VV7lrBec0rqRDebdPt5nCDe3c/wEz/5Paf+/malBsAn19aCORXM5kk2pP690m++7PnVSG7yotRRgNndet/Wl74Ez+3vq13rzl3P58IwBWO0ORqY3nr81p2ggdfBMRoNPcPW7nw0OfAM0Plbe++NOa2t+w4bXzKNnD3CtxHe+9jg3j8WJEsz1Arw74CkERnZSWo7JtoPOznsXbTrI9RMyWbixyNNJ7WKvnLcXv9zGhOzmh+jyZsROqipiiNpOX8NeBqoCxhjWY1Z27FqxRmfyvP18FtsHs1ZnYMXkM65jc168bCg9IoJJjGy6KNSglE8RZXPGZ8WzZPthbE0Efw2vQ9+cuYA20eIg8I2COWPjnDlvnV1for35eztvDx0RoHr/5u5nYqA/xw0TMpiS04Ms15jE39x3KomRgbfO6wjexWY/O6W3T1cubeF9xJsK5sC3wU1r+MvZeHXWKZwxsKeftPgpZj3OOXOBFrP6LOP1mzQVkAxLjWH6oMb77ObTAKLB9dUwIHtoeg7ZSRFc6Wpt3HCbKbEhhAU5H99trRIR2kKdM595LUZO7df0vvnT3KXub7xZN5NB+Zy0Q/s03VDHH/c9psZVVSjUK3fcfV9vzTXesJj16rHpQOPnkL9z+3g6UYI5f0ex0WWvlLoeuB6gT5/ObUbsrcZqp87uIMho4I73VgOwdEcJj3283jPupT+LWyxW1Yw2bOBy4xeMN6wlQjk7qLVpA7t0Im/ap/OlPY8NOpX/3H0mhp/2s9Kromdz9dS8jc6I88z74U2jufsfayho0HeXv6IAf/UOAN66egQOrcny6sCzuTc6o6G+j66WggX3SeGvK4Hm0uu3mNWnztyJEc1lxIezuaiiXYsaI12NLwIpYmkL73OjtcGiwaA8gRz4b/14vLkPfUyouV0G73Y/wO72U9ndPe6pon0CpfFZ8QzqFeU3kAP/D/imfjHv39L98A30ntQc97ntr75Yk8sYverMeU33Pp4f3jSmhe3W/+0u4o4JM1NZa2t0bcye4L/Frts3953mtd72va78NYryd10lucbwbk0Lb/cp9s61I9lzpIqpzy5uNI/JqNpc1GFQcOEwZ51wd527JK/ArV9SBM/8bJDP2OAtrrOJ4+tucf/CpUP5YedhLjil5broHelECeYKAe828L2BfQ1n0lrPAeaAc2zW45O0lnn3eO+tuUDO26e3jWPG8/X9ni28pg/FP35A8JaPGWLYQbGO5GP7GFbpviRkjeS1TUGkxIXz9b2ncmTeRm7NSiAjIZzbJmdx/YQMHv/vBub+uJsEr4s0OzHcM+TXBUN78dHqvZ6bv3cu1rDUWD66eSxDf+07huq5ecncPKkvf/muPnh7aMYAXv9mJ1kNKsEbDQpjK95yTM0Us4LzDbSqQetca4MctoKnZ/j0fdRwLZEhzkvFt0K6//pzx8rddcXPR/bhgxVtH1C9Ld69biRr9pS2uvuL5rw2axgfr9lLalwoB8rbfxQPb+39YOsM7npJLT3QA3X12DQOV9Zx7fj0Rt/9fGRqo1EFjuUIvnNt8wUi+X7qaKU10breO364emw6PSKDOauZnK9AKaX49XkDGZ3RuMjwjilZrPbTQbrZJ5ewbUfIX0D09+tG8dXmg426zGmNjqjf2pC/TVw1Jo2kyGCmDwo8MHILCTI22SLfZFBtql5w+oBEXr+iftjSMX3j+Gx9ET0inM8x9wv3zOGtz8hxj8Ty6qxhnmm3ndaXYakxTMxO8Fsf93g7UYK5ZUCWUiod2AtcAlzWuUmCd5fuQmvN5aPTmPbsYjYXVXDHlCyGpcaQnRhBydE6Xv9mR8srakFuchQRVDHT+CXTjMvI/PtWMtEcjcvBOvKPHEk5l4decGbXXxbVBwe7PS1aH5ju259csNnoyX7vFVN/sb119QhPs/Pk6BD+ePEQbn9vNR+v2edTqRogJiyIgqdncPmbP3gaGtw1NRuLycgNEzJ8Bq7/5NZxAeWGNF9nztDsG+TojDgWbnKOM+i+oKcP7MkrXzXdGKNhMOPulqHWK0fvxomZniKw0wck8p/Vjd4f2iQ5OsRTATurRzhntsMDLFAJEZZ2b8mYFBXsqf/ZnvydE8e7nmFHsJiMPhXwrxqT5rdOmj/+dj80yMQj7no+DRzP4PfmSZmM6du4j73sxAi+v/80xjy9yGd6H6/7gtGg/NbBa6vLRzXskc7Ju2Nqb0114dMa/s7NlNhQLh+d1sY1utLTxnO+NeGSv7QbDcrT0bA//lL1gFdr3DCLib9clc81b/mOdW00GHzSFhtA7vTX905qVHT67Mw81uwpo6rO/8hCrZEUGUxplZWU2PpnosloYGIrqjp1tBMimNNa25RStwCf4eya5C9a6/Wdmabthyo9XYUkRgazucjZUe2fF7TPgMHgHOZqqGEbLFrNYsvLxKhK1jnSYNIDkHcpYdHON5Asr2XCXIFacy8+I9NjefPbnUzql8DzC53pTXa9Rbn/V0rxx4uH8NCMnCZzcZqrI+LWUgeeTa37v7eM4+wXnbmRJqPyWxnezXuSe75BvaMa5ca53TM1m9MbBDTurHZ31v2SB06jZ1SIJ5j73YWD+eUZ/Rs9kI7VF3dNbNf1nejcv1P3D+nqPXZObsDztjZDw9PvloL279XOV2RI0w1ekv3k0vzh4iEdmZxW8emOxPvvVqzDfT8MJDhpixF+Gif4E0jdrvT4MM4ZkuwZOaW9XpIajhzi3TflGblJzF9/AEV9w58PbxodUNF6alzj3N3QIBOjM+NYuLH19UAbcgfMXbk2zQkRzAForecBTY0qfNwVHqkfQP36d1Y0M6evc4Ykc+fp2azZU8od769udt5f5tm4ZtOTsBjWkscztRdx5c/OZWB+00MNhXg1027K6QMSPf1j/eWqfJY0Mb6q2WhotiLpmMw4TwetDesdjPJTxNHQorsneh4ADQOyrMT6otkVXhVp2yOn4ZbT6sPfe6Zm+x1f1p1T9+vzBmJUCovJ6PeBJHx5boYddFPsqHp5Jyp38V5ucv1LVVtzetpbWzop7ijul8p+SRFtrujeXv0X+vPd/acRG9p+QeKX90xyrtcTzLXbqhu5blw6GrhmXDoWs4EhKdHEhVnYU1LtqZfXlHPzkgMuEWnLLednrpbdXeOKaN4JE8x1NeP8FCcE4rrx6Y1GLQCYMbinZ8gbcI7l2TfWAjsiofdwBulwXrfamwwoLjilF/9auZeJ/RJ4ftE2JjQzpJBSytM/1mn9E5vs2b8ls8dn8NQ8/91/TOrXcvcPzQ3p5B209YiwUODq58o9+dy8ZE8QNiYzngUbncWsrb2ibzktyye4c3MXRTcsrokKMTfbAWVX1F0bb/hLdSCNcAf2imTd3raNIdzVRYe2LgBKjg7hqfMHkZscyQuL2q/U4EQTGWxm7uxR5PaKZPfhpscubU5bXjQigk1UNBr0vbFARoRpi/pOdo89nJk7e5Tf6Q+fVV8F4LlLnEPVz7l8GJ9vKGpxv/50cR7PtNB1iXvYumvHNa4z2pI/dqHc4ZZIMNdBjAbFmkenMuTxzwNeJi8l2jM4ecML/88z85i/7oCnNWVGfLgzcsmeBkCM619Tfn/hEJ46fxDBZiM7fzv9uLx9+9tGW8MG7zWNTI/1qfT750vyGPNbZ/Gm++3XfVMAZwXw0ZlxnPncN5zVTB2PQFw1Jo23vi9o8vgtfWByk33RCa8c1nY8/bx/ikAemB/dPPaY+jzsyn55Rn9SYkL9DBTetMtGOqtjyGnbvNGZziJCn1OsFedxW3r7+fKeSRw5Wtf6BZsxPD2Wd5buIsdrrOaO0PAe2ZpHTo/IYGY1Ua/Rm9GgMBqaHxs3PtzSqBPo1uoimdXNkmCuA0WFmLGYDNQGOCzJ3VPrK9+mxIZw/5n9iQ+3sP1QJWajgS/vnsSPBSVcOKx1nXqC70nfmcUo7lygtqbg5kmZ3DY5C6UU3/7yVOLDLVhMRs/F5r/OnCKnZyRrH5vq6ZuprR47J7fZOkxNjRcojo9AitnNRgMBjo3e7YRZTMyekNGqYM6tj2s4s5hW5u6dbLyLWVtT5NqWemfx4ZZWdf0RiHOGJDMqI5YeEYH3tdaW3Ht3K1K3nlGd239je+jKLzwSzHWwIGNgwdyWJ8/0qeyvlOLGib4tAPvEhXpuuN1da+9rZw7qyb9X7+OCU3p5Oij1N/B5czkzLY048OjZA9r9Ldifd64d0aXqA51IOrJe0onu/jP7M65vPPlpgVWk7ygv//wUopppLNHZ2vou3JXOzNYEcm01JCWaf9wwmryUaA5W1Pi9X3cXl4zow6/+vc6nh4euRoK5DlZR23J9h+NV7NkZrp+Q0S59pU3LTWLHU9NbfFgfy8AF7p69O9r4rK7TnP14y3Z10Hv1mLQOWb80gGg7i8nI5Jz27ZamLdLjwzq8CPBYNNWy9UTW1ueTu4Vtdw7kwFk3uqnubLoKCeY6wfRBScxbe8Dz+UQN5AAenJ7Dgw36smurQHJdToR+xk5ksa4+CDuK/P7dX1f/Db2LVi8bEXgHtO77fFvGhu1s3bWR1MlEgrnjJMRsxGRQVNTaeOzsXLYWVbLVNQ7ryaSj7wmt7Zrk3WtHdvoAyV1FF3+GNuLvXOpu+yAa6+ol5fUtPFs3/FtMqJnbJ2dxTl7njxYQqM4eb1QErvu9InRT1Va7p8+0yBAz824f38kp6hxjXV2iDPMzrM+xaVtnseOy4k/qYk9v3fXl2/s3t5gMjMmM45VZp3RaesSx6er1Ht2pa+31opTiztOzyWymyyUh2kpy5o6jv103km+3FXsq8J+MTu3Xgw1PTCP0GFuVNqlrPwdEB1NK8fcm+rMS3UOXL2bt4unrCN30Pa/N3r5mBNUNxvPu6iSY62Deg7ynxYc1Oaj0yaTDAjk4+e467egkfEaJLqirN2Lp4skT7aArjbkaKClm7WAf3zK2s5NwUpAb7LHrrsWs3TTZooE8V0/9FnPXfix5+r0+ie45J9GudluSM9fBmitS/eHBydRaA+tQWDQvLyWaLzYUYTGdvEXYQnRnr8w6hfV7y5sd77krkGJW0RVJMNfBQpoJ5rr6Tas7ee6SPLYWVRIlvde32Un4jDphvXTZKYQHd6/be8+oEHq2MLB6V3BSXSYn1c52b93rau+G3Dlz7T0ki/AVGmTyDKgsTi7yvGlsxjGOQSyadjK99AxMjuLHnSXEhQV1dlJECySY62BhFhMPz8hhShfoWV2IE8n0QUks2FjkGVVCiOPB3dq2u9YxbY0HpvfnnLxksuQa6/IkmDsOrhuf0dlJEOKEc8EpvTlrcLLPmMZCiPZjNho8DVNE1yZ3QSFEtyWBnDjeTqZiVtF9yJ1QCCGECNDJ2JpVdH0SzAkhhBABklBOdEUSzAlxkjsZKnIL0V4kY050RRLMCSGEEAFSkjcnuiAJ5oQQQogAGSSWE12QBHNCCCFEoCSYE12QBHNCCCFEgKSYVXRFEswJIYQQAZIGEKIrkmBOCAFIjoMQgZCrRHRFEswJIQDQSB8lQrREOg0WXZEEc0IIIUSApDWr6IokmBNCAFLMKkQg5DoRXZEEc0IIQIpZhQiIxHKiC5JgTgghhAiQVJkTXZEEc0IIQIqPhAiEXCWiK5JgTgghhAiQtGYVXZEEc0Kc5HpGhwCQEGHp5JQI0fVJKCe6ok4J5pRSFyml1iulHEqp/AbfPaCU2qaU2qyUmuY1fZhSaq3ru+eV6/VIKWVRSr3vmv6DUirt+O6NEN3bVWPSeO3yYZybl9zZSRGiyzNIzpzogjorZ24dcAGw2HuiUmoAcAmQC5wBvKyUMrq+fgW4Hshy/TvDNf1a4IjWui/wLPBMh6deiBOI0aCYlpskxUdCBEAuE9EVdUowp7XeqLXe7Oerc4H3tNa1WuudwDZghFKqJxCptV6itdbAX4HzvJZ52/X3B8BkJU8lIYQQQpwkAg7mlFIhSql+HZkYoBewx+tzoWtaL9ffDaf7LKO1tgFlQJy/lSulrldKLVdKLT906FA7J10IIcSJTrIKRFcUUDCnlDobWA3Md33OU0p93MIyC5RS6/z8O7e5xfxM081Mb26ZxhO1nqO1ztda5yckJDSXfCGEEKIR6cJHdEWmAOd7DBgBfAWgtV7dUkMDrfWUNqSnEEjx+twb2Oea3tvPdO9lCpVSJiAKKGnDtoUQQohmSc6c6IoCLWa1aa3LOjQlTh8Dl7haqKbjbOjwo9Z6P1ChlBrlqg93BfAfr2WudP19IbDIVa9OCCFEF3GixEDSmlV0RYHmzK1TSl0GGJVSWcBtwPdt3ahS6nzgBSAB+FQptVprPU1rvV4p9Q9gA2ADfqG1trsWuwl4CwgB/uf6B/Am8I5SahvOHLlL2pouIYQQojkSyomuKNBg7lbgIaAW+DvwGfBkWzeqtf4I+KiJ734D/MbP9OXAQD/Ta4CL2poWIYQQIlCSMSe6ohaDOVc/bx+76sA91PFJEkIIIbomd89XYzL9dpogRKdoMZjTWtuVUlVKqajjVG9OCCGE6LIW3j2RnlHBnZ0MITwCLWatAdYqpb4Ajronaq1v65BUCSGEEF1UZkJ4ZydBCB+BBnOfuv4JIYQQQoguJKBgTmv9tlIqCMh2TdqstbZ2XLKEEEIIIUQgAgrmlFKTcI5/WoCzZXaKUupKrfXijkuaEEIIIYRoSaDFrH8EpmqtNwMopbKBucCwjkqYEEIIIYRoWaAjQJjdgRyA1noLYO6YJAkhhBBCiEAFmjO3XCn1JvCO6/PPgRUdkyQhhBBCCBGoQIO5m4Bf4BzGSwGLgZc7KlFCCCGEECIwgQZzJuA5rfWfwDMqhKXDUiWEEEIIIQISaJ25hTgHuHcLARa0f3KEEEIIIURrBBrMBWutK90fXH+HdkyShBBCCCFEoAIN5o4qpU5xf1BK5QPVHZMkIYQQQggRqEDrzN0B/FMptQ/QQDIws8NSJYQQQgghAtJszpxSarhSKklrvQzoD7wP2ID5wM7jkD4hhBBCCNGMlopZXwPqXH+PBh4EXgKOAHM6MF1CCCGEECIALRWzGrXWJa6/ZwJztNYfAh8qpVZ3bNKEEEIIIURLWsqZMyql3AHfZGCR13eB1rcTQgghhBAdpKWAbC7wtVKqGGfr1W8AlFJ9gbIOTpsQQgghhGhBs8Gc1vo3SqmFQE/gc621dn1lAG7t6MQJIYQQQojmtVhUqrVe6mfalo5JjhBCCCGEaI1AOw0WQgghhBBdkARzQgghhBDdmARzQgghhBDdmARzQgghhBDdmARzQgghhBDdmARzQgghhBDdmARzQgghhBDdmARzQgghhBDdmARzQgghhBDdmARzQgghhBDdmARzQgghhBDdWKcEc0qp3yulNimlflJKfaSUivb67gGl1Dal1Gal1DSv6cOUUmtd3z2vlFKu6Ral1Puu6T8opdKO/x4JIYQQQnSOzsqZ+wIYqLUeDGwBHgBQSg0ALgFygTOAl5VSRtcyrwDXA1muf2e4pl8LHNFa9wWeBZ45XjshhBBCCNHZOiWY01p/rrW2uT4uBXq7/j4XeE9rXau13glsA0YopXoCkVrrJVprDfwVOM9rmbddf38ATHbn2gkhhBBCnOi6Qp25a4D/uf7uBezx+q7QNa2X6++G032WcQWIZUCcvw0ppa5XSi1XSi0/dOhQu+2AEEIIIURnMXXUipVSC4AkP189pLX+j2uehwAb8Df3Yn7m181Mb26ZxhO1ngPMAcjPz/c7jxBCCCFEd9JhwZzWekpz3yulrgTOAia7ik7BmeOW4jVbb2Cfa3pvP9O9lylUSpmAKKDkmHdACCGEEKIb6KzWrGcAvwTO0VpXeX31MXCJq4VqOs6GDj9qrfcDFUqpUa76cFcA//Fa5krX3xcCi7yCQyGEEEKIE1qH5cy14EXAAnzhaquwVGt9o9Z6vVLqH8AGnMWvv9Ba213L3AS8BYTgrGPnrmf3JvCOUmobzhy5S47bXgghhBBCdLJOCeZc3Yg09d1vgN/4mb4cGOhneg1wUbsmUAghhBCim+isnLkuyWq1UlhYSE1NTWcnRRwnwcHB9O7dG7PZ3NlJEUIIIdpEgjkvhYWFREREkJaWhnRVd+LTWnP48GEKCwtJT0/v7OQIIYQQbdIV+pnrMmpqaoiLi5NA7iShlCIuLk5yYoUQQnRrEsw1IIHcyUV+byGEEN2dBHNdSEFBAQMH+rbxeOyxx/jDH/7Q7HLLly/ntttuA6C2tpYpU6aQl5fH+++/32FpBfjNb35Dbm4ugwcPJi8vjx9++KFDtzdp0iSWL18OwPTp0yktLe3Q7QkhhBDdgdSZOwHk5+eTn58PwKpVq7BaraxevTrg5e12O0ajsVXbXLJkCZ988gkrV67EYrFQXFxMXV1dq9ZxLObNm3fctiWEEEJ0ZZIz141MmjSJX/7yl4wYMYLs7Gy++eYbAL766ivOOussDh48yKxZs1i9ejV5eXls376dhQsXMnToUAYNGsQ111xDbW0tAGlpaTzxxBOMGzeOf/7zn6SlpfHggw8yevRo8vPzWblyJdOmTSMzM5NXX321UVr2799PfHw8FosFgPj4eJKTkwF44oknGD58OAMHDuT666/H3YfzpEmTuPPOO5kwYQI5OTksW7aMCy64gKysLB5++GHAmTvZv39/rrzySgYPHsyFF15IVVVVo+2npaVRXFxMQUEBOTk5zJ49m9zcXKZOnUp1dTUAy5YtY/DgwYwePZp77723Ua6nEEIIcSKQnLkmPP7f9WzYV96u6xyQHMmjZ+ce0zpsNhs//vgj8+bN4/HHH2fBggWe73r06MEbb7zBH/7wBz755BNqamqYNGkSCxcuJDs7myuuuIJXXnmFO+64A3B2y/Htt98CcP/995OSksKSJUu48847ueqqq/juu++oqakhNzeXG2+80ScdU6dO5YknniA7O5spU6Ywc+ZMJk6cCMAtt9zCI488AsDll1/OJ598wtlnnw1AUFAQixcv5rnnnuPcc89lxYoVxMbGkpmZyZ133gnA5s2befPNNxk7dizXXHMNL7/8Mvfcc0+Tx2Tr1q3MnTuX119/nYsvvpgPP/yQWbNmcfXVVzNnzhzGjBnD/ffff0zHXQghhOiqJGeuC2mqMr739AsuuACAYcOGUVBQ0Oz6Nm/eTHp6OtnZ2QBceeWVLF682PP9zJkzfeY/55xzABg0aBAjR44kIiKChIQEgoODG9VPCw8PZ8WKFcyZM4eEhARmzpzJW2+9BcCX9i+GcwAAIABJREFUX37JyJEjGTRoEIsWLWL9+vV+t5Gbm0vPnj2xWCxkZGSwZ88eAFJSUhg7diwAs2bN8gScTUlPTycvL8/nuJSWllJRUcGYMWMAuOyyy5pdhxBCCNFdSc5cE441B60t4uLiOHLkiM+0kpISnz7Q3MWaRqMRm83W7PpaGqI2LCzM57N73QaDwfO3+7O/bRmNRiZNmsSkSZMYNGgQb7/9Npdccgk333wzy5cvJyUlhccee8yn649AttEwqG2pxan3eoxGI9XV1S3uuxBCCHGikJy5LiQ8PJyePXuycOFCwBnIzZ8/n3HjxrVpff3796egoIBt27YB8M4773iKQo/V5s2b2bp1q+fz6tWrSU1N9QRu8fHxVFZW8sEHH7R63bt372bJkiUAzJ07t037HxMTQ0REBEuXLgXgvffea/U6hBBCiO5Acua6mL/+9a/84he/4O677wbg0UcfJTMzs03rCg4O5v/+7/+46KKLsNlsDB8+vFHdt7aqrKzk1ltvpbS0FJPJRN++fZkzZw7R0dHMnj2bQYMGkZaWxvDhw1u97pycHN5++21uuOEGsrKyuOmmm9qUxjfffJPZs2cTFhbGpEmTiIqKatN6hBBCiK5MnazFUfn5+drdZ5nbxo0bycnJ6aQUCXC2Zj3rrLNYt27dMa+rsrKS8PBwAJ5++mn279/Pc88912g++d2F6DhPzdvInMU7eODM/twwsW0vpkIIUEqt0Frn+/tOcubECevTTz/lt7/9LTabjdTUVE8DDSGEEOJEIsGc6FLS0tLaJVcOnK11G7bYFUIIIU400gBCCCGEEKIbk2BOCCGEEKIbk2BOCCGEEKIbk2BOCCGEEKIbk2CuizEajeTl5TFw4EDOPvvsRsNoNXTVVVd5OuadNGkS7u5Wpk+f3uKyrfHss88SHBxMWVlZu61TCCGEEMdOgrkuJiQkhNWrV7Nu3TpiY2N56aWX2rSeefPmER0d3W7pmjt3LsOHD+ejjz5ql/XZ7fZ2WY8QQghxspNgrgsbPXo0e/fuBZzDZY0aNYrBgwdz/vnnNxrDtaG0tDSKi4spKCggJyeH2bNnk5uby9SpU6murgZg2bJlDB48mNGjR3PvvfcycOBAv+vavn07lZWVPPnkk8ydOxeAV155hfvuu88zz1tvvcWtt94KwLvvvsuIESPIy8vjhhtu8ARu4eHhPPLII4wcOZIlS5bwxBNPMHz4cAYOHMj111/vGU+1qXTZ7Xbuvfdehg8fzuDBg3nttdfaemiFEEKIE4b0M9eU/90PB9a27zqTBsGZTwc0q91uZ+HChVx77bUAXHHFFbzwwgtMnDiRRx55hMcff5w///nPAa1r69atzJ07l9dff52LL76YDz/8kFmzZnH11VczZ84cxowZw/3339/k8nPnzuXSSy/9f/buO06q6m78+Ofc6ds7yxZ26WVZem8WFAiiKBaIJqKxl5gYnyS/aBLBaDTGGKNRn/jE2BVb7L1jAwUFpYOwwC5tC2wvU87vjynMzs7sDrDLsuz3/XrxYva2OXfmzrnfeypTp05l48aN7Nu3j3POOYeJEydy5513AvDss89y0003sX79ep599lk+//xzLBYLV199NU899RQXXnghtbW1DB06lFtuuQWAIUOG8Mc//hGAn/70p7z++uucfvrpEdP18MMPk5iYyNdff01jYyOTJ09mxowZ9O7dO6rPQQghhDgeScncMaa+vp4RI0aQmppKRUUFp556KpWVlRw4cIATTjgBgIULF7J06dKoj9m7d29GjBgBwOjRoykqKuLAgQNUV1czadIkAM4///yI+y9ZsoQFCxZgGAbz5s3j+eefJz09nT59+rBs2TLKy8vZuHEjkydP5oMPPmDlypWMHTuWESNG8MEHH7B161bA2x7w7LPPDhz3o48+Yvz48RQWFvLhhx+ydu3aVtP17rvv8vjjjzNixAjGjx9PeXk5mzdvjvpzEEIIIY5HUjIXSZQlaO3N32ausrKSOXPmcP/997Nw4cIjOqbNZgu8NplM1NfXE+2cvN999x2bN2/m1FNPBaCpqYk+ffpwzTXXMH/+fJ577jkGDRrEWWedhVIKrTULFy7k9ttvb3Esu92OyWQCoKGhgauvvpoVK1aQm5vLokWLaGhoaDVdWmvuu+8+Zs6ceSinL4QQQhzXpGTuGJWYmMi9997LXXfdRUxMDMnJyXz66acAPPHEE4FSusOVnJxMfHw8y5YtA7ylb+E888wzLFq0iKKiIoqKiti1axclJSVs376defPm8fLLL/PMM88Eps2aPn06L7zwAvv27QOgoqKC7du3tzhuQ0MDAGlpadTU1AR65LaWrpkzZ/Lggw/idDoB2LRpE7W1tUf0OQghhBBdnZTMHcNGjhzJ8OHDWbJkCY899hhXXnkldXV19OnTh0ceeeSIj//www9z2WWXERsby4knnkhiYmKLbZYsWcJbb73VbNlZZ53FkiVL+O1vf8uQIUNYt24d48aNA7zt4G699VZmzJiBx+PBYrFw//33k5eX1+wYSUlJXHbZZRQWFpKfn8/YsWPbTNell15KUVERo0aNQmtNeno6L7/88hF/DkIIIURXpqKtbjvejBkzRvvHZPNbv349gwcP7qQUHX01NTXExcUBcMcdd7B7927+8Y9/dHKqjn66utv3LsTR9Oc31/PQ0q387keDuOKEvp2dHCG6LKXUSq31mHDrpGSuG3vjjTe4/fbbcblc5OXl8eijj3Z2koBjN11CCCHEsUiCuW5s/vz5gbZux5JjNV1CCCHEsUg6QAghhBBCdGESzIXorm0Iuyv5voXoWAvG5pLosDBneFZnJ0WI45YEc0Hsdjvl5eVyg+8mtNaUl5djt9s7OylCHLf6pMex+uYZZCc5OjspQhy3OqXNnFLqT8BcwAPsAy7SWu/yrfsdcAngBq7TWr/jWz4aeBRwAG8Cv9Baa6WUDXgcGA2UA/O11kWHk66cnByKi4spLS09grMTXYndbicnJ6ezkyGEEEIcts7qAPFXrfUfAJRS1wF/BK5USg0BFgAFQBbwvlJqgNbaDTwIXA4swxvMzQLewhv47dda91NKLQD+AhxW63mLxSLzfAohhBCiS+mUalatdVXQn7GAv15zLrBEa92otd4GbAHGKaV6Agla6y+1tw70ceDMoH0e871+AZiulFIdfhJCCCGEEMeAThuaRCl1G3AhUAmc5Fucjbfkza/Yt8zpex263L/PTgCttUspVQmkAmVh3vNyvKV79OrVq71ORQghhBCi03RYyZxS6n2l1Jow/+YCaK1v0lrnAk8B1/p3C3Mo3cry1vZpuVDrh7TWY7TWY9LT0w/thIQQQgghjkEdVjKntT4lyk2fBt4AbsZb4pYbtC4H2OVbnhNmOUH7FCulzEAiUNHWm65cubJMKdVyBvj2lUaYEsJupDuff3c+d+je59+dzx269/l353OH7n3+R+Pc8yKt6KzerP211pt9f54BbPC9fhV4Wil1N94OEP2Br7TWbqVUtVJqArAcb/XsfUH7LAS+BM4BPtRRjC2ite7wojml1IpI86h1B935/LvzuUP3Pv/ufO7Qvc+/O587dO/z7+xz76w2c3copQbiHZpkO3AlgNZ6rVLqOWAd4AKu8fVkBbiKg0OTvOX7B/Aw8IRSagveErkFR+skhBBCCCE6W6cEc1rrs1tZdxtwW5jlK4ChYZY3AOe2awKFEEIIIboImQGiYz3U2QnoZN35/LvzuUP3Pv/ufO7Qvc+/O587dO/z79RzVzJ1lRBCCCFE1yUlc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZgEc0IIIYQQXZi5sxPQWdLS0nR+fn5nJ0MIIYQQok0rV64s01qnh1vXbYO5/Px8VqxY0dnJEEIIIYRok1Jqe6R1Us0qhBBCCNGFSTAnhBBCCNGFSTAnhBBCCNGFSTAnjlsriirYUV7X4e+jtW7xd12T65CP4/ZoKuuc7ZWsdlVR29TiPI8Wt0fj9nTOe4eqrHPi8Wi2l9cC3s/lWP3OhJfHo6ltjO73qLVGa02D043L7englEXvSH97dU0uGl3uVrc5UNdEeU3jEb3PsWxfdQMb91QD4HJ7+HRzaZv7fLNjP/uqGwDvZ1hR29ShaTwSpkWLFnV2GjrFQw89tOjyyy/v7GSIDjTpjg955IsiLpvah017q/lsSxkJDgu1jS6cbo1Ha17+toRBPRMwlMLj0Ryoc+KwmnB7NOt2VdHo8pDosADeDPX5lcVoDRkJ9sCyE+/6mL1VjUzpn4bbo3l19S5O/+fnnDQwg417q3G5NSmxVgC+3bGff32ylVibmddX72JMfgp7qxpwWEz84ZU1XPP0NwzpmcCnm0tRSmG3GLy6ahcF2Ylhz/Hhz7bxx1fWUFHbRE5yDPF2S9jttpfX0ujyYDUZmAwFeDMnt0djNnmf6ZpcHkqrG4mzH+wX9fK3Jcz6x6f8a+lW0uKsDM9NanZcp9vDe+v20Dc9DqVUi/ddUVSB2VDE2lr2tXK6PVz79DfkJseQmWjnyidW8tmWMk4Z0iOwTV2Ti1Pu/oQ/vb6ey6f1wRKUVgXsrmzgxpfWcNLAjMC61uworwMFW0tr0Vo3S9e/P93KbW+uZ/7YXGobXfy//37Hxj3V5KbEYCjFl1vLmXnPUl5eVcI9729mav80pv/tE/73kx/45SkDAKhpdHHBv5fx9PIdnDky23ueHg8mpWhwevhscxm5yQ4MQ1FZ5+SVVSUUZCUEPru6Jhf9b3qLOJuZUXnJge/ObjEFvqdInG4P1z3zLXmpMaTEWjEMxc6KOuwWg7LqJg7UN5HgsLC3qoH9tU2U1TSyrawWj9ac9cDnVNY7Gd8nFYCdFXW43B7Ka5pY/OpahmQlBH4HfmU1jTz79U4e/aKIoVmJOCymwLXldHv4+TPfkJXkoGeio0Vai8pqKd5fzz0fbGbxa+uorHcyLj8l8Dm8t24vz329k6n9w3bci+ijjfvomWinorYJt9Z8tGEfv395DTe+tIbJ/dLweHSL8wDYvLearWW1nHTXJ/xQWsPPn/mWez/cQpPLQ2ainXi7OXBu0XC6PWzaW01pdSONLjcOq4mPNuwjPzU27O8kkn1VDRTc/A4vfVvCE8u2E2M1ceWTK8lOctAvI47Keierdx7gq20V9MuIC6SxvslNTYPL+93XNDHilvf4dHMZswoycVhN1DS6+Pv7m0BDerwNi8lg2KJ3eTDoWgZocLrxaHht9S6a3B5eWVXCjoo6Pt9SxrwHv+Diyb2xW0xorVm5fT9Ws8Gdb2/koke+JivR0Szf0lqzv87Jxr3VJMdaMBve6/mTTaU0uTykxtlYU1LJut1VfLxxH6uLK1m+tRyLyWDDniry02IB2HWgntU7K8lMtLN0UynT//Yx28pqyUpykBxjpdHlZuY9S7ntzfVcMa0vt7y2losf/Zr/+3QbTy7bzsWTenPmA5/z70+3kZcaw7ayWk79+1JsZhNj8pJ5/Mvt2MwGZkNx8t8+4fXvdnPp1D6cdNfH/PWdjazbVUWszcRnW8op6JnAltIaahvdJMaEz3vb0+LFi3cvWrTooXDrVGc9bXe2MWPGaOnNevRs3FPN9yWVnDM6p8W6JpcHj9bYLabAsrKaRsbc+j5XTOvDv5Zu5c6zhzFzaCZ/f28TOckOLp3ahw/W7+WSx7zfYV5qDG9eNzVwc25yeRjw+7cOKY2nDO7B++v38twVE/l44z4e+PgHAFJjrVx5Ql+2V9Ty5LIdAFw+rQ+vr95F7/RYPt9SDsCQngms210VON6f5hbwh1fWAnDG8Cym9Evj/o+3sD1MaWFOsoPi/fUR09YjwUZKrI3b5xVSVt1IWryNEblJ5P+/N5ptt+322Xyz4wBf/lDGSYMyeOO73fx65kB6/+5NAAZlxmMzGwzJSuSZr3aQHm/j89+ezP0fbWHzvmre/H4Pb/9yKrWNbkbnJTPtzo/YUeFN76S+qTx4wWhsFgO7xUTx/jqm/OUjAOJsZi6Y0It/fbIVgF4pMTxwwSjm3PcZAFv/PBvDd6NZvrWcz7aU8cH6fazbXYXVZPDO9dM46a6PAfjhz7Px+G4OCx5a1uz87j5vOGU1jfz5zQ0ATB+UwQcb9gGQmWDnvvNHcufbG5gxJJOnlm/nhasmkRZnw+X28K+lW/nrOxtJsJupavCW1Dz2s3H895tihvRM4Pa3NgTeJ3ibSE4d0oP31u0NvC6tbmTVzgMttouxmphd2JMXVhYDMLJXEr1TY1m+rYKSA/W8/6sT+HjjPm59Yz25KQ52Vnivg6I7TuOLLWWc/+/l9M+I45IpvemdFsuQrATi7RZcbg+1jW6Wbi7lqeXbWba1otX0Arx7/TRm/H1pq9v8ff5wrn92dbNl8XYzH95wIq+u3sWfXl/HS1dP4qwHvmi2zaDMeMbkJ/P8imJOHJjOO2v3tjh2fmoMY/NTeHvtHqojfL6zCzN58/s9APx21iD+8vYG7vvxSJJjrEzqmxq4jt76fjef/1BGgt1CnN3MnW9vbHYch8VEvfNgaVR2koOSA/UsPqOAPVUNrCmp5NPNZQzoEcemvTWtfiYAA3rE8dSlE0iPt/HJplKeXr6dm08voKrByUNLt7J8awU3zh5MvN3MH15ZE/idW80GZ43I5tkVOwFYu3gm28pqUQo+2+x9wJw+KIPXvtvNCQPS6ZcRx4cb9vKzR1u/P93345Hc+NL3gc+xX0Ycfzl7GC9/W8JzK3bS6PLQNz2WH0prm+33l7ML+b6kMpCXAWz40ywG/eFtAK45qS9uD/xkQq/A7zuS7CQHt88rxGo2WvxWAV7/+RTm3PcZVpNBU1BJZ35qDDefUcCtr68LpG/1zTMYvvjdiO+V6jB4+arxTLv7c3QrlYpmQ+HyleS3la9G6+cn9+O+D7dEXJ9FGV/cdj6YOjagU0qt1FqPCbtOgrnuqbS6EY/W9PCVMIXavLea3mmxVDe4SHRYAhkoQFWDk6KyWoblJLG/tomaRhe5KTFhj/Pp5lLG5KUw+I/ejKLojtNabHPyXR+zrbyWbbefxiebStlb2UCCw8yVT37TbLux+cl8XbQfgO8WzWDYopY//HG9UzhvTC7/8/zqFusORbzNTHUbVTN2GlFo6rEBLZ+2Q28m4VhxYqcJG96qunR1ADNuzLhJUjXYcGKgMeEmW3mDxs89BTRgJYZG9ukkqomhDhtuTK291SELvqmGKsxO5PuSykM63pxhPdld2cDK7fvb3DbWaqK2qfXP7nh34cQ8Hv8y/EgEl0zpzcOfbTvKKYrMggsDDy5MWHARSwMO1YQVJxqFB4UbA482vP+jsCknOaoMgAZtpYoYdugMPBiYcaPQNGIh+LdlMxsM6pnAzoq6TqnyiuY3faTOGZ0TCPw7SqHaSqqqxIKbLF++4sagEQvrPHls0z2pw46Bh0RqiMFb/apRGEqTp/YQSwMeDGpw0KS9D9He786FXTmx4kRxML6w4yRO1RNPHcmqmlxVSr7agwV34NgWXFhxYlIezLgx4caCGwdN2JQ3j3RrxR5S8GgDk3JjwZtPl+kkinQPKnQC63UvbL58dbXuy16djBUXFt8/w5cuD8p3fRo0+UZqM+HBhpMY1YidRgzfdehB0VNV0EvtI4Vq8o09gXQPVz9QVHA1g89b3KHfmwRzYXT3YM5fohMuuNpeXssJf/2Yc0fn8PzKYq47uR+/mjGQ37ywmudWHMxktv55Nlc8uZL31u3lu0UzqKp38sxXO/ifGQNRSrHo1bU8+kURc4b15PXvdgPeUheTofho4z4q65w8v3JnoGSr6I7TAuka1zuFr7a1XdJw5DRWXMTQQE9VQQ9VQZaqIIYGynUCmWo/6eoAPVQFsTSSpGpIoYo4VU+K8j7NO7WJahxU6xg0CrtqYoOnFwYe3w3OjBMziarGm3FoAzeKVFXFYGNnu5yFU5toxIIJD24MvvH0p1in04CVIt2DIp1JjXZQTQw12kEF8TRibZf3jsSEm95qN73UPkx4iKGBGhzE0kA9NmpwMFDtZJKxlmpiMPmC2CYsNGkzjVhowoITsy8AMHBrgxRVRZqqpBELjdqKGwONwoQHD4omLNTgADSJ1JKqqqjTdjTgxIzJl4XHqXriqCfe97/35qQC7wVQRQwOmmjEQq22U4cdJyb6ql1UEuu9ueHxBdyewGsXBqU6GRcGTVio0PGU6iTcGDgxs1/HYaCxKBdm382sEQuxNGCnKXCTyVLlpKoqqnUM5cSzU2egfO9lwkMqVTgxsVunUqzTUWiSVA0KTZqqooeqYJMnlwasWHDhxqAOO9XaEVgWQyMxqpEE6hhk7CBblVGqE9ml07DhxK4asdNEvtpLb7Ubmy9Ac2HCiRkXBgNUMTZ16O1EQ3m0N1jwK9fxFOt0KnUsP+gsXJjYq5Mp1wm4MVFJLMU6jb06OXAdaFSLIBA0BhobTTRhaeXBR+OgkRgaSVB1uDGo11bKSCSFalJVFY1YcGoztdipJC6q81J46K9KqMNGsc447M8n1CmDM3h//b6w6yy4GGNsZLTaxJDYalR9Of1VCTac5Bpttxer0g7iaGj2fbSnXTqFIk8m1cQEgj4nJhqx4tYGTky4MZGRFMvWAx7qtPeBNUHVkqaqvCGYyUyty4RDNdFL7SWJWjJVBfHqyEvjInFrRRmJ7NYp1Gk7ZuVmj07BNusWZk4e12HvC60Hc9120ODuqsHpZl9V641c91R6G3w+73s6vPfDLdwbpoi5weUOVDMFl5LNHZHNgB7xPPpFEUAgkAOod7pxWExc/MjXLY63+LW1gdftEchtuvVHWM0G+f/vDWw00UPtJ50DDDJ2MkjtYJCxg6GqCIdq/Qm/Vtuox8Z+Hc9uncI2Mqn32NhrZNDohnhVRzz1JKha781PN5Giqr3BBwYW6rHiZL+ORwGG8mDBgyO5J3rw6ajEHH7/+mbMuCnVSQzKTcdktfPulnryeqaybnctbgwqdSx2mhhrbPSFDYoY1UA8dfRQB1BoPCjy1V6GqO0MNnbgoJE41dDinBq1mbU6nx06gxrtoIpYDuhYKomjSZuZZvqOUp3Eak9f0tUBXJh86ffeLhNUHWONDSRSi0M1EUODNxBR/lulmwSjEYtuu/Rkt07BjYENJ5U6FitOrIYLG96newsub/Diu6k0agulJGLgwez7JMxK47DZcDVUY8YdCCxqtY19Ogm74S0BVWicvmyv2hfc9snOZFlxI1XEYPiCJP//8dRRRiIOGnGoJpKpwUYTtdgDgbkLUyCQcPu+cztNZKkyb1pwkmJUk6AOvTOOWytKdBoxRiNJ1GBWHdso343BPp1EGpVY1MESqAZt4QBx1Gkb3+p+AJh9pSZWnKzx9GaH7oEZF068gU4DVs4d35cnl+1gZE48ZwzLRGk3d769HhMeNIqdOh0XJuw0kaYq6at20YSZBm3Fqlzkqz2kU0kvtY+RxhbsNDVLVyQerXzlLwpvUKd9wbN33wM6FicWmnzXtQsTGUYVqaoKm46+E8ABHeu7Og126nR26nTqtJ29OpnRxiZyVClOzPRQ+0lS3urE5Z5BlOkE9uhUmjCzVyf7Am0TNpy84RnPT04ezX0fbEKhyVX7GJXqZOFQO99//hopeBvxKzSTdQqrYypocrmwmsDp1tRrGxOMddjVwY45HlMqxcpgq86iklj+45zFt57+GHhojMnk5rNGkxZr5uKHPmK4+oE+xm6SqeYA8Ywb0pdv9zjZVl7n+/3Dfh1HiU5H4SFe1fsetzSPLBzNip3VZKencNWSNXhQXDA+j8wEKycNzQNbPBUuO6P/+iUag0cuHssVvnvBKYN7cM1Jfdmwp5o3v9/NojMKiLGayEyws2L7flZu388dQU0hbj59CAsn5tPnxjebfSdWnCRSw9NXncR5Dy5lguG93ob2SsNjWPmiqAo3RiAv8z+IXTgui2e+2oEbgyunF7BydyOvrt2PRmHFiQ0nVcRQWDiSWo+Ft9bs4Z1fTqO8ppEz+qVFfc10FAnmjmNPL9/BO2v38NjPvE8L1Q1OCsNUTQZ7+dsSfvnsqqiOX3IYbRHqmlxs3lsddt0jnxcd8vFaY22sgG9e4jHL44w31jfL3OpUDGvcuXwQM4t1VQ6yMtLY44olNbs/8T3y+Ns7G4lV9bx20wJe+G4/N796sO3bq6t3AXDWyGxe+rYkcMz5Y3KJsZl45PMicpId3Hx6AW6P5sonVwLw4lUTaXJp/u+zrVw6tQ/5vsbmAHU7VvFf37FSs/K4+fQCzq1tIj3extJNpVz4n68C25Z4wjcKP398L1xuD7evCK6i0WRTRg+1/2AJlKqnn9rFKGMzE6zbsLhqSKAuqptkMK1MrHbn0YiVUp3EDmzUe6w4MTF9aDaW5CRqEvrSmDKIrRWN/PbVLcRRTx02bDhJUHX0zUjgyT05+EtRLhjfi+dW7MTp1i3au8we2oOp/VIpzElizj+97bX+78IxZCc56JsRy7c7DgTa7dhpJCs1mdeum8pJN7/TLN1rFs9k895qznrgCwZlxvP2FdMYVdNIvdPdZhuhSMyGondaLJv3NW979dYvpnLiPz4NpOnPZxbwl5e/wqacaODWeaO48cVVNGHmpln9yMtM58ePrsZA0ytesbnaTIzNRnWjCzuNpKnKQFWlRlFBPGbc9FMl9FL76J/Xi/eLmrhpzhAmDh1Awe3LGKCPiTSEAAAgAElEQVSKcWHgwhy4KSWras4b1ZNThuaCNQYssWCNpTqmFxNv+wQDDwnUsupPc8n/wwcEl3J9ddN0xt32QbPzvPXMoTz48ppmywqyEhh3xlTGnXFwWV2TiyVvHPw+7j5vOL96rmWTiDvPGcZvXvguzCetyaSCmQOT+XqT92ElT+0lRVVz1ohMCnrG88q3xRTtLcfiq6pVQL/0WLaWVlOPDbc2SFcHcJg0Dk81dpw4aCRr2HSITeNvS/dgVh5KdSJuDBKoI1HVcta00dz2cRkWXJiVm2xVRjLVmPCQqGopUEWkm6roqcuwKDcNyQOwZ02kvKqGuOR0frMylkK1jRHGFkZYqsj2fBXm/OC3LIHP4fLgFjA1wDLoYzaz1p2DCzMeFCZ3IyOy40AZGIbBmq07GWzsoCR9Kn0LJ/Hrd/fxoXskKxedT9O+aianxmIoxfjqRppcHlLirMT52hnvqWxgu85ku84E3zODv+bmn/9exuf7ynn04rGMzkvmDy+vYV5OEn96fR1o+NWpA7h4cj6G3cK4gd59U76JY+2uKn585inNzi8F+OYPMzGUIjHGwprFM3lv3R7OGJ6NyVCM7JXMj8f1arbP2PwUxuanUJidyAX/Xg7ATybkYRiKBWNzWfL1wRqOJiyUkkz/vGz2k8BbnvH866ejmVmQSXWDk/hVu/jJ+F4opSitbuSVVSXc+sZ6fj5yEhcMdvLksu2MOWkMw9weppXWUJCVyMY91dz7wWb+fEp/+veID/nGQv/uHBLMHcdufOn7Zn9Han+zblcVr6wu4ZnlOyK2fQvn1AgNqSvrnS0a5vsdqHO2aDjdnky4Odn4lgWmj+Bv34PHRS/Vg1fck1mr8xhaMIzzZs9EOXrSs7aJr1aV8MC7m7h6YF9+M2sQ4O3xuPudMtDgiEukR4K3RGVcfgp/nz8iEMzdPq8w0HsV4MJJeazd5e0AoZS3UTzAf6+exLDsxEBvxIl9Uwl15znDGJgZz+1vbSA11obJUKTH2wCYNiCdl6+ZjMWkOO3ez1rsmxprpby2iZxkB1ef2K9ZVTgoSkinRKdDmNqSH4/I5ZmvdgKaWBpIpJZ4VUfB4CEsW1dEgqqjTsVg0k7uObeArKQYXlhZwmXT+mBOyibfbUMp5W3L5GtADfDOidPokRlPHBAH1JbXsVWHlExpOHNyIalvb6Tc1/7ptrMKedaXMd9//iiuenIlu3wlxb84ZSADM5tnnBP7pgZuRsG9WRuw8c8LRhNrM/OTCb2aNfa2mgxG9krm7vOGB76j1Dhbs+NeNCk/ULIc+CQVRGqVsuXPs/njK2uaBXOJDgsx1oPVeQ3YMNnj2EtK4LvwJGRRQgkOi4nTp43HZCi+/EMuJpOiwenmhudWM7BHPP/+bBsNviq64OYIS399EtP++hFrdB/W6D58dt5J/DLJcbB3LHZW+UrSbpo9mNveXB/47C8dPRF6pzQ7D39fZQ8GB4gHi4PQ9qAZ8XbeuG4KL6wsDjyATR+cwe9fbv6Z5KW2zEtirAdvOa9eO5nc5JbbDM1O4LwxuRGCOcUeUql0ZLFOe7/vldobPfz+XG/gMXcKzPz7UjYGPTRe1DufR3cX0S8jji2+7yjeZKbaebBquGied//7Pgqfd501/mTO71vL22v2RMxL547I4s1VO5g+KI3/vWgyAP5f+4n9d3P1U952wOOyUlhd5G13NnVABh9tKkMB8aqemcbXnD0qixe/2YWBh5t+fCok5kBcBkZcD7aureAXS7wP3EWXnNasK8Ac33Wx6cofgdngvLwKrvFd2/0yDv52MhNbtpWOt0cOB3qlxPI55dgtJuLtFu5ZMBLAG8wB103v32KfRy4aG7HnbnLswSYecTYzZ41s2TEunElBeaf/937p1D7NgrlwzL423/F2Cz+dkBdYnh5v49KpfThndA5JMd40nTjQWw1uN0wUZHl74w7MjOf+C0ZFlcbOIsFcN+ByewLDUoQz+95PA6/9PRePxK1vrI+47kA7jsnVk3JON31BjiojXR1ggComT+3FrDzU2zNg9DUwbD5nPFhMtW/ct+vS+0NSLg4gN2hYiuB7tBHyMfkzDY1uNjyB3WKiZ9LBTNFsGIFMQwXdAEf1Sm7zXMwmg0un9iHGZmb+mNwW60fkJlHdEP6zi3akg1evncwZ//y82bKMeH/6FbU4qMXBn+YOZfnWcnaRxi4NeSkxbCuvw5kykPT8FK7qMzywf/OBSg6ymJonymYJf+3ZzCZOHdKDJV/v5PZ5hc3WWc1Gs+8l9Jihy0LXm31/33pmIR+u3xcICv3bzRsV+Qay6IyCFsHc27+YxrVPf9Oi9M3PGWZcMpu5edus0Jub/zc5JCshcG35b3QJdgtPXDKeBz6O3IsuJa55u0dDqaiHvgj3eUarICuRbWW1PPJ5ET8amtlsiJctt/2IDzfsY0KYhxY42LnIYjLCXhfm0B9g2LS3vs1zV06kqt7J1Dubl7RGM3xNJGbDYFLfNJb9UN7qNk7MuFTL9qj+hzO/Rqzef5YkqvBem5U6jofds5kweAwPf+1t033T0ObtmueOyA4Ec5H4r6Wx+Smtbhcs+MEj1B/mDGZkbhLjQ4L/V66ZHHHIlkMZgiVa4Y4Z6b4WrK1hZfyBXFcmgwZ3A79YsoqCm99pNn6YX2jpXXv8/FaHGZ7BL1JAMrlf+IzfS2OnkXT2c5bxKbeYH2Gp9Rd8af85N1qe4ULzexQa29iis/m3+zQub7qe9Qu+gFNvgR4FfHjDiZw40Fs1aTO3fcmH3kwCwVyYUhkjKHMxm1Qg0zicfMxkKH46IQ9rhDRGypAijaf71U3TA68n90sNOwad/wl9cM8EwJsx/nRCXuC9JvVNDZzjoYyzFXrTtAcFNa9dOyXwOty5+k8n9Bjh3t8S9F2Fbm9u55uM3WK0+r1OCxkTTWvd5vV2uMHFPfNH8OuZA1ucY2vfUWjajySwAeiT5m38P6V/WrPzNJsMZhRkkhBhzMPg9w93I470vTXbJmS/a07q2+zvRIclbC1D8PV2qM36owl+rebI2wTnFTro3U1hjmuP8PATrUP4qQa09ruIsZo5b2xui22G5yYxNMIYmEeLpZXP3C+aB4SuTkrmuoE3vt8dcd3Ty3c0+7utsbUOlwUX6RygriZ8e7kBjlqK1R4MND1VOekcwKGamGZ8xzTju2aN+N1a8bFnBM85T+QVzyR26h4tjned5eCTVnq8jfzUWKA04s01ODuIXDLXUnCmaTYOBnNGBzyVRjqmxxdlhgabB0vdvPumhHn6TIuz8eENJ+D26GbV5qagAM7/roeSIYYGacElMIU5iZw4MJ2PN5ZiNRmBdIem32Y+uK5Hgo2spJaDzwYPmdOiZC4ove1RSmANSk84PyrsybxR2fz3m5Jm+wQLHT3gcJPlH5A4dGaMQzlepIeGaA3JSmD5jdPJCClxapMvjVaTEXYg5Gh+O9aQ79rpji40C97vUD/6tgZthtYD5EgBVrjgNbRE91B1RKnYsSqafMl8BKXQXcVxE8wppWYB/wBMwL+11nd0cpLajcej+XRLGdP6px3Rj9TfS/VIJVPFRGMdZtz0NXYzWm0k0ddTK5YG9hNPrbbjwkSm2k8cdaSpKmJUI7wBk21x1GoHNdix4sKKi9zNpdwc5p5QqhN4xT2ZnTodJya+8/TlO92nzWE1Qm9U/qlsbJa2M0lTyGfsDxLCDeMTfOMxGSqomrX9HUmA6G9sHDp2WazVRJ/0OHZXNu/M4g+STIYKnMyRlMyFBtH+I7V2TG81q/czX3L5xDZLklqU5LVzBh48e0YkwVVVmrZLgo80haHpOZRr5EhL5oCI41RGI2IwGcUphAZWTa7oevkeSQDr/23npca2sk3k40e6dsItP9JAuzuJppo1mtLeru64COaUUibgfuBUoBj4Win1qtZ6XeemrH08/mURi15bxwMXjGJ2Yc+o9gmXuf3jg82HnQY7jZxr+oRpxndMN63C8HV3cmvFep1HhW/YihLSiaeOeFVPArVUEstGPYD9nng262zO7G9l45YtxKp6EqhH4UFjsDH9R7xVEoNSmr062Ru8aTN7ScZ1GJdp6E2t0elNrz2KTDI0c/UfKtyz/9mjcgIjg5sNA5MvM++IB+NDCaYi7XvL3KFU1DYFhovxt3WyBrULDNbo9AQ+y0N5ug0tJYv0EBL6fnAwaA4utYsmMw4NTiztnIGbDMWDPxnNfz7bxhPLDgbE548/2PMuNN5vqzTHv3l7jffZWjAX+h2EPrQcLf53PZI2e6HXYrj2iuEcSQDr33feqGzMJhW23Zo58ODXcv9I3024a7s7BB/tJZp86Ujyzq7iuAjmgHHAFq31VgCl1BJgLnDMBnP1TW427a0OzHVZ0+jinAe/4K/nDKcwp3kbhB2+6X12HfD+X9XgZPGr67jptMGBOT9DhZtW6FBYcTLW2EC+2stkYw0nGatwqCYO6Fi+yTqf27b1p4oYSnUiVVEOnAmwy5POJ66WA1bO75HLizujH0D3wQtGEWMzs/A/4bv3h5rQN5X/flsS6J3k16wEKmSZn/8m6M+gL5yYF6hayk+LxWJSON0asymoZK5DqlnDL48mDmjWXido+1RfA3p/SYB/3evfeXvofrm1nP4Z3u/3UM6orZtm8Odzw8wB1DS6mDsiq/kxggLvaG7CoZn64WTgpxX2JDm2eVuvO88exv66JpJirCTFWLllbkEgmJvUN5U/n3Ww48aFE/N5yt90wfdZLv31SYC3feJbaw42eQjer71EOuW7zxvOCQPS+e83xc16XIfzwAWjAr0uAf7fjwZhNhQvflPCpVN6H3Ea/Zef//t55OKxYcedbE1oaUxbwdyUfmk8+kUR0/p7q/cBJvdL4+213lH8s8L07gxlCvptT4kwrlhrwfShlMy1R6lpdxFNMCdt5rqObCA4EigGxndSWpr5aMM+7BZTs+Eo3l+3l0sf9/ZU+m7RDOKsZr7aVs6GPdXc9e5GHvvZODwezVPLt9Pk1gdLhny54EOfbOXFb4rplxHHVSf2DX1LVhRVcN6/vjzElGqyKCdXlXK66QvmmJYFBrncpVN40T2V19yTWK4Hc9OgwXy7NXKP1dZ8sin8yOPRxD6/mN4/ULo4oyCzjZt18wjn3NE5TB+U0WIIioUT8ynZX8/l0/oEloWWWPj/8pee3DJ3aNh3DG4z1xHPgc0CoFMH8MrqXWzZV9Nqqc5/LhrDzx5dwaIzhgSWeYK2z/JNgh5areMKaoPUWslkJJFuRlP7e2+CBz9Tb9u+cN3+g2/Y0VwflpAM+3Ay8OB0/PDn2TjdnmZzBnvTEtTuKiRdAzPjA/NcDsnydirpFTREh7+jyT3zR3DmyGz2+4ZkuWRKHyIJfQBpTaSHiNOG9cRmNvHGdVOZfMeHlByIPEZkaOn/lSd485hLp0ZOI3gD2zFR9J780dBMnltRHPhcTxqYwWmFPQNte5MPY8LyAS3G/mrulCE9WLN4JhaT4hbfcBpnj845GMyFaY/ZmuBr67Vrp7DgoS+pbXLjv2TD/VaC86vgn2y4ALA7lCQdiYFB37fNbOLSKb35dyvT23WHz/N4CebCfVMtfk9KqcuBywF69erVYoeOcPGj3ifO4GmzfvPiwfGTrnvm28CTIhxsY/Ofz7cFhvj42WTv0/Djy4q4bFqfQAmdf1yg+iY3DquJ9buruP7ZVWzYE76TQahsSplq+p5haivjjA30M7ylMfXaytuesbzhnsAWnUWRziT4Iw4ehqC9hLsHPXDBKL4rruR/P/FOeH/9qQMCwVykH+ft8wpZu6sy0NPu4PFVi0AOvOdyW0gJSctqVl/JXBvn0KzNXAfnHT+f3p/dVQ1s2VdDgsNCVYMr7DhRJw/q0WLKttOHZ/HWmj08eMGoQCmk1WQwOi+Zy3w3bLPp4GTV/i4Q0dYEPnDBqLDfz8ZbZwUC5exk780z3LV08+kF3PrGOiwmFXFIkzNHZDWbWQRafubBT+yXTOnNLa+v439/Mjq6k8D7fZqM1ttY/mR8XotldouJZy+fwCBf4BZsQI941iyeGRgbLznWGnZKvWAnDEjn/V9N45S7w4/rGCzSPSs40P3becP5+3ub6BlFadShePqyCVFtd9tZhfzPjIHNguT7LxjFG74x0v5y9rCw+/3+tMEthj2aVZDJtSf3Y0iYz9rPX4oeF3StJdjNnDI4IzAGYaQajv+ZMYC73t3UYnlwe8zCnESSY63UNtW3WjJ3KNWsR1IF3V5G9oo08FDn2vCnWS3ylytP7NtqMCcdILqOYiB4cK4cYFfoRlrrh4CHwDs369FJWuC9cXs0tY3uZj/q4EAOCGRwP5TWBpb953PvRbqzop4Ne6qo8U0A//76vWTE27j8iZX8Yc4QPt64r9VA7oNfTWPDt5+x89OnONn4hgGGt9ddlXaw2tOXp5zT2aqzyBg0iefX1UY8TrghTo5UaIlCSqyV2YU9mV3YMxDMgbdk59PNZWGP0dZNMVqhmW6Sw1tSMDgz/A3jYLuugw3kO6I3ayh/8HbNSf2ob3Jz/rjoHlBmF/Zk2+2zQ0qYFC9eNSnwt7fkoXnVVbj2bcFumVvAvR9sjtiuM7iH3o2zBzM6L7nFuFUACyfls3BSPgCPXjyOV74tadFj8p4FIwMDl/rF2czkpjjY6WuWEJzh/2xKb37WDlWEoX4U4VzH94k81E7cYTwM5bfS6D5YpIec4KYDE/qk8uwVE1s9zsf/c2KLEsn2YjEZZLTScSJ0zK8rpvXhX0u3NhtqRGtYu3gmNnP4HrF+3y+a0aKE9rtFMwDvNX/JlD48uWxHsxkHFk7M4zFfJ6E5w7KwmIwWE9+3NexNuLWRAu3QZh0QXc/ZjvZMlMH50RbuumyrjaGUzHUdXwP9lVK9gRJgAXB+5ybpYBs3gN6/e5MJfVJYtrX1OUdfXb2LW88ayjNf7Qi7ftY9n9I33Zuxf7yxNBAM+kfiDmXCzRMn1dNn9xtkPnwVfRsrcVvMfOEaRO9TruITzwgufbMSULxx3RSG9ExAKcXzEWZwAO+gn8FevGoSZz/Y+qwO6fE2Sqsjz3kY/FN77/ppEZ+U/+/CMVTVt9/Aw+GEZgz5abE8f+VECtsYT8lkKNy+yK6tMbbawy+nDyDRYeHc0TmHnPm31aYvOPM7cWA6G/dWhx3aJNiFE/O5cGJ+VO9vt5iYOyK7ze36psfxqxkDozqm2WTw6W9ODsyOcDw1Im/tZrT65hkMX+ydpq+9HiLy06ILHo+G384axNT+6Uzul0pBVkKgzV80NQThxlYM/m32Tott8RC4eO5QFp1RQFW9i8QYC1ec0JcrTmjenCVi+7dWSvEj7XOsdoDoqGC+IwQHxKcMzqCitvmc0MfC59nRjotgTmvtUkpdC7yDd2iS/2it17axW4e7PmSO07YCOb9/BZVEhRNcahcqFe9k1efkVDJNryC98ntMX1aDLRH6nwL5U2HAbIZZUrA4LJwCnF7yLa+t3kVanC2qhvvBVV82s8GgzJbtVXKSHcRYTZTXNPH+r07AYTUFpnv679WT2LSnmoKsRE7/p3d6quC3DZ377uVrJrPOl4HbLaawmcz6W2a1me5ohXtSbm0k9b+dN5x/vL8Zi0lRVe8tNU08jHY/h8phNXH1if065NjB1Ty/mTWIn07Ma7U05ViSYDdT1eA6rp7GW/tdJjosQds1XxdjNQWqy491r1wzudlcvH6GoZjia2s5qyAzEMx1JOUbyieSSD2BW3umaj5ocPjlfsmdPCPBBeOPTjOk9hIcrP174dgW64+nvCCS4yKYA9Bavwm82dnpCBb6dBCt+z9qPZgDOGd0Dsu/WcmVptfprXZjVS7y1F7SVaV3g1IguTcUzoP+M6D/qWD2VlWZgOAypjvPHsZFk/KajRm1/MbpjP/zwcm0fzzOP4dn88bt714/Lew0MJ/99uQWy7783cmYDYP0eFtgiqvFZxRw86trm01/FWpEbhIjcltvv+FoZSqajjZ3RHaglMlfojg2v+0pvI5lwVVTJkORE2YOzWPVK9dOYfnW8uNu4NSrT+wbmDcyktDAYMXvT2n1t3UsGZ6bFOjd35a2qvw7mv+BLyGkycnBnu8t0xcpoDhrVDb/Wrq12TJ/h6Sko/BQGOyDG06gvsnd6bM6HKq2gjXpzSqOSEe2m7r1zKHc7y5hzvov2aKzadQWPvYMZ4PuxWadzeO/+Qkk5kbVEt9hNTE6r3nJU48EO389Zxi/9k12ffu8YRRmJ3HjS98zMDOeZb+bjkbTM7FlL7B+GeGHKgm3rX8Ylsn90pqN3dVVjeudwivXTGZYTtfKDEN15SfZ3mmx9D6Gqgnby29mDWpzm9A8J3hi++NBjK9q1XEMVAHeM39EoJOA/2M/1KFJHr14LINC2uKe6Rui59PfnHRY7SuPRN/06IeZOpZEKintlRLDjoq6bjEI8/H1Sz/GhKuuO1xKNe9NaLeYmDRmHMNX/R/+Fmc/HpfLxL5pWHdXQdKRF5OfOyY3EMyBd3DUH4/zzs8X2ibsuSsmkpvioLrBRb9DyBBG9Upm9c0zmlUVHYq3fzm1xZRGnS3a0gXRdd1//ijy04690souHIO3cMe8whZTEf50Qh51ja42h0k5GvxTqgXzf/7hSoXbGoJkTF4yL1w1KVCqF25uWRGe/3McFdID98GfjGJtSVXENtjHEwnmOkhdk4sNew6/bYfdYtDgPNibMNywEBP7pfHkJRO46JGvcHk0V53Qj16pMZwxPKvlxu0kUtXVOF+vxJ6HUSB1uIEc0OKpVrSP9pqR4Hh12rDoZmI52o6nquUF43qxIKSHttVs8PPp/TspRW3zBxVtVbP6Z+jxj6W47HfTA/ng8fQdHi1KKV7/+ZRmYzqCd4zGQxmnsSs7/sseO8knG0ujHpcrnDEh1Z6zCzPDbjelfxprFs/k1Wsnt7iQhThc/sLOJZcfm8MTCHEs8ldrhw6vAs1LTf2dUvr6mqRkJto7td3v8WBoduJRGUXgWCUlcx3kcHr+9UmPpdHpobSmkTvO9g5kazObAk95b37vHa383h83H1/LbjExLEeq9kT78Q+xcjy2PROio0zqm8rNpw/h7NE5LdYFN7t54IJRfL6ljLQwA5kfiZW/P4XGMPNyi+OfBHMdxD/IqdlQ3HTaYBa/1vY0sR/ecGLEdf6Bgq0mo0OrUUP95ezCds9wugKlYMHY3LY3PE5N6ZfGS9+WhO2pLIQITym4eHL4wamDh8840k46b143NeysBuFmuRHdgwRzHSQrycG8kdksnJRP7/TYsMHcddP7c69veqq2+Kf5amuIjvY2f+zRG2/omcsmHPZwLu1t2+3tM5tEV3XH2YVcN71/2EFXhRDhtTYMTHv2wPXP+yuEnwRzHcRkKO6ePwKABqc77Da/mN4fm9ngr+9sbPN4FpPBS1dPCrSxOB5N7Bt5CiRxdNnMJqliFeIQtTb+nVKKW+YWdOt2XaLjSAeIo8A/yO7Fk/ObLTcZimtOin4E/5G9kiUjEIE5WYUQx4ZoB2a+cGJ+2CFNhDhSclc4CkyGYuOts7AYBvuqGluMnSREtL66aXqzCeuFEJ2vs2ekEEJK5o4Sm9mEYSjuv2AUQNj5TIVoS0a8/YjG5RNCCHH8kZK5TvDmdVPJTjo4tdV/LhpDSZgJpoUQQhz7BmTEs7OiHvsxMM2Y6J4kmOsEoT2RTh7Uo5NSIoQQ4kjds2AEq3YeoMdhjC8qRHuQalYhhBDiCMTbLUztn97ZyRDdmARzQgjRxaXHy2CxQnRnUs0qhBBd3HvXT6Oq3tXZyRBCdBIJ5oQ4zpw8KIOymsbOToY4ipJirGEndxdCdA8SzAlxnPnPRWM7OwlCCCGOImkzJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhUkwJ4QQQgjRhXVKMKeUOlcptVYp5VFKjQlZ9zul1Bal1Eal1Myg5aOVUt/71t2rlFK+5Tal1LO+5cuVUvlH92yEEEIIITpPZ5XMrQHmAUuDFyqlhgALgAJgFvCAUsrkW/0gcDnQ3/dvlm/5JcB+rXU/4O/AXzo89UIIIYQQx4hOCea01uu11hvDrJoLLNFaN2qttwFbgHFKqZ5Agtb6S621Bh4Hzgza5zHf6xeA6f5SOyGEEEKI492x1mYuG9gZ9Hexb1m273Xo8mb7aK1dQCWQ2uEpFUIIIYQ4Bpij3VAp5QB6RShRC7f9+0BmmFU3aa1fibRbmGW6leWt7RMuTZfjraqlV69eEZIghBBCCNF1RBXMKaVOB+4CrEBvpdQI4Bat9RmR9tFan3IY6SkGcoP+zgF2+ZbnhFkevE+xUsoMJAIVEdL0EPAQwJgxY8IGfEIIIYQQXUm01ayLgHHAAQCt9SogvwPS8yqwwNdDtTfejg5faa13A9VKqQm+9nAXAq8E7bPQ9/oc4ENfuzohhBBCiONetNWsLq11ZXv1K1BKnQXcB6QDbyilVmmtZ2qt1yqlngPWAS7gGq2127fbVcCjgAN4y/cP4GHgCaXUFrwlcgvaJZFCCCGEEF1AtMHcGqXU+YBJKdUfuA744nDfVGv9EvBShHW3AbeFWb4CGBpmeQNw7uGmRQghhBCiK4u2mvXneMd+awSexttj9JcdlSghhBBCCBGdNkvmfIP2vurr0HBTxydJCCGEEEJEq82SOV+btTqlVOJRSI8QQgghhDgE0baZawC+V0q9B9T6F2qtr+uQVAkhhBBCiKhEG8y94fsnhBBCCCGOIVEFc1rrx5RSVmCAb9FGrbWz45IlhBBCCCGiEe0MECfincy+CO/0WblKqYVa66Udl19qiZEAABsUSURBVDQhhBBCCNGWaKtZ/wbM8M/LqpQaADwDjO6ohAkhhBBCiLZFO86cxR/IAWitNwGWjkmSEEIIIYSIVrQlcyuUUg8DT/j+vgBY2TFJEkIIIYQQ0Yo2mLsKuAbvNF4KWAo80FGJEkIIIYQQ0Yk2mDMD/9Ba3w2BWSFsHZYqIYQQQggRlWjbzH0AOIL+dgDvt39yhBBCCCHEoYg2mLNrrWv8f/hex3RMkoQQQgghRLSiDeZqlVKj/H8opcYA9R2TJCGEEEIIEa1o28z9EnheKbUL0EAWML/DUiWEEEIIIaLSasmcUmqsUipTa/01MAh4FnABbwPbjkL6hBBCCCFEK9qqZv0X0OR7PRG4Ebgf2A881IHpEkIIIYQQUWirmtWkta7wvZ4PPKS1fhF4USm1qmOTJoQQQggh2tJWyZxJKeUP+KYDHwati7a9nRBCCCGE6CBtBWTPAJ8opcrw9l79FEAp1Q+o7OC0CSGEEEKINrQazGmtb1NKfQD0BN7VWmvfKgP4eUcnTgghhBBCtK7NqlKt9bIwyzZ1THKEEEIIIcShiHbQYCGEEEIIcQySYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQoguTYE4IIYQQogvrlGBOKfVXpdQGpdR3SqmXlFJJQet+p5TaopTaqJSaGbR8tFLqe9+6e5VSyrfcppR61rd8uVIq/+ifkRBCCCFE5+iskrn3gKFa62HAJuB3AEqpIcACoACYBTyglDL59nkQuBzo7/s3y7f8EmC/1rof8HfgL0frJIQQQgghOlunBHNa63e11i7fn8uAHN/rucASrXWj1nobsAUYp5TqCSRorb/UWmvgceDMoH0e871+AZjuL7UTQgghhDjeHQtt5n4GvOV7nQ3sDFpX7FuW7XsdurzZPr4AsRJIDfdGSqnLlVIrlFIrSktL2+0EhBBCCCE6i7mjDqyUeh/IDLPqJq31K75tbgJcwFP+3cJsr1tZ3to+LRdq/RDwEMCYMWPCbiOEEEII0ZV0WDCntT6ltfVKqYXAHGC6r+oUvCVuuUGb5QC7fMtzwiwP3qdYKWUGEoGKIz4BIYQQQoguoLN6s84CfgucobWuC1r1KrDA10O1N96ODl9prXcD1UqpCb72cBcCrwTts9D3+hzgw6DgUAghhBDiuNZhJXNt+CdgA97z9VVYprW+Umu9Vin1HLAOb/XrNVprt2+fq4BHAQfeNnb+dnYPA08opbbgLZFbcNTOQgghhBCik6nuWog1ZswYvWLFis5OhhBCCCFEm5RSK7XWY8Kt66ySuWOS0+mkuLiYhoaGzk6KOEbY7XZycnKwWCydnRQhhBAiLAnmghQXFxMfH09+fj4yVJ3QWlNeXk5xcTG9e/fu7OQIIYQQYR0L48wdMxoaGkhNTZVATgCglCI1NVVKaoUQQhzTJJgLIYGcCCbXgxBCiGOdBHPHGJPJxIgRIygoKGD48OHcfffdeDyewz5eXFxc2OUXXXQRL7zwQtTHWbRoEdnZ2YwYMYL+/fszb9481q1bF1jf1NTEL3/5S/r27Uu/fv2YM2cOO3bsCKxXSnHDDTcE/r7rrrtYtGhRi/fZu3cvc+bMYfjw4QwZMoTZs2dHnUYhhBCiO5Jg7hjjcDhYtWoVa9eu5b333uPNN99k8eLFnZ0sAK6//npWrVrF5s2bmT9/PieffDL+adFuvPFGqqur2bRpE1u2bOHss89m7ty5gUDUZrPx3//+l7Kyslbf449//COnnnoqq1evZt26ddxxxx1HnG6Xy9X2RkIIIUQXJcHcMSwjI4OHHnqIf/7zn2itaWho4OKLL6awsJCRI0fy0UcfAfDoo49y7bXXBvabM2cOH3/8ceDvG264gVGjRjF9+nTCzUm7cuVKTjjhBEaPHs3MmTPZvXt3m2mbP38+M2bM4Omnn6auro5HHvn/7d15dBRVvsDx748ECAQIRONThzXPEYEkhpCwiBo8SlCeOIBoADExT2HyWBzGGZSRGQTEAZlxUJbDqIcdTHAZ0SfiYwBH1APKYkYIOxjcUDCQyKoh+b0/uhI60J0FAp3u/n3O6ZPKrarb91dVnb65t+re+UyfPp2QkBAAMjIyaNSoEatXrwYgNDSUYcOGMX369ArzPXjwIM2bn53sIy4urmx52rRpxMbGcuONNzJ27FgAcnJy6Nq1K3FxcfTr14+jR48C0KNHD5588kmSk5N54YUXvMY4Y8YM2rdvT1xcHAMH2hCFxhhj/I89zerFxP/NZfu3P9Zonu2vbcJTfTpUa5/o6GhKSko4dOgQS5YsAWDr1q3s3LmTlJQUdu/eXeH+J06cICEhgeeee45JkyYxceJEZs2aVba+qKiIUaNG8dZbbxEVFcWyZcsYN24c8+bNq7RsCQkJ7Ny5k71799KyZUuaNGlSbn1iYiLbt28nJSUFgBEjRhAXF8fjjz/uNc8RI0aQmprKrFmzuOOOO8jIyODaa69l5cqVLF++nE8++YSGDRty5Ihrxra0tDRmzpxJcnIy48ePZ+LEiTz//PMAFBQU8MEHH1BUVERycrLHGKdOncoXX3xB/fr1KSgoqDRmY4wxpraxypwfKB3Y+aOPPmLUqFEA3HDDDbRq1arSylydOnVITU0FYMiQIfTv37/c+l27drFt2zZ69uwJQHFxMddcc021yqWqHh8UOHdA6iZNmpCWlsaMGTNo0KCBxzx79erF/v37ee+991i5ciUdO3Zk27ZtrF69moyMDBo2bAhAZGQkhYWFFBQUkJycDEB6ejr33XdfWV6lcVcUY1xcHA888AB9+/alb9++VYrbGGOMqU2sMudFdVvQLpX9+/cTEhLCVVdddV7lqFRoaGi5hyQqGkrj3EqXqtKhQwfWr19f7bJ99tlnJCYmct1113HgwAGOHTtG48aNy9Zv2bKFAQMGlNtn9OjRJCQkkJGR4TXfyMhIBg8ezODBg7n77rtZt26d1wpjRcLDw4GKY1yxYgXr1q3j7bff5umnnyY3N5fQUPtYGGOM8R92z1wtdvjwYTIzMxk5ciQiwq233srSpUsB2L17N19++SVt27aldevW5OTkUFJSwldffcWnn35alkdJSUnZU6uvvPIKN998c7n3aNu2LYcPHy6r6BQVFZGbm1tp2d544w1WrVrFoEGDCA8PJz09nccee4ziYtdUuosWLSIsLIzu3buX2y8yMpL777+fuXPnesx37dq1nDx5EoBjx46xb98+WrZsSUpKCvPmzStbd+TIESIiImjWrBkffvghAIsXLy5rpatKjKXH67bbbmPatGkUFBRw/PjxSmM3xhhjahNrgqhlTp06RXx8PEVFRYSGhvLggw/y2GOPATB8+HAyMzOJjY0lNDSUBQsWUL9+fbp3706bNm2IjY0lJiaGhISEsvzCw8PJzc2lU6dOREREsGzZsnLvV69ePV5//XUeffRRCgsLOXPmDKNHj6ZDh/NbJqdPn86SJUs4ceIEMTExrF27lqioKACmTJnCmDFjaNu2LadOnSIqKor169d7bE373e9+V+6+PXebN29m5MiRZa2NjzzyCElJSYDrYYfExETq1atH7969+fOf/8zChQvJzMzk5MmTREdHM3/+/PPy9Bbj9ddfz5AhQygsLERV+e1vf0vTpk2reKaMMcaY2kG8dd0FusTERN20aVO5tB07dtCuXTsflShwfPfdd9x5550MHz6cYcOG+bo4F82uC2OMMb4mIptVNdHTOmuZMzXu6quvJicnx9fFMMYYY4KC3TNnjDHGGOPHrDJnjDHGGOPHrDJnjDHGGOPHrDJnjDHGGOPHrDJnjDHGGOPHrDJXy4SEhBAfH09MTAx9+vSpdL7Qhx56qGxQ4B49elA63Erv3r1rdK7R6dOnExYWRmFhYY3laYwxxpiLZ5W5WqZBgwbk5OSwbds2IiMjmT179gXl8+6779boALhZWVkkJSXx5ptv1kh+pTNFGGOMMebiWGWuFuvWrRvffPMN4Jr9oGvXrsTFxdGvXz+OHj1a4b6tW7fmhx9+IC8vj3bt2jF06FA6dOhASkoKp06dAmDjxo3ExcXRrVs3xowZQ0xMjMe89u3bx/Hjx5k8eTJZWVkAzJkzh8cff7xsmwULFjBq1CgAlixZQufOnYmPj+fXv/51WcWtUaNGjB8/ni5durB+/XomTZpEUlISMTExDBs2rGzuWW/lKi4uZsyYMSQlJREXF8eLL754oYfWGGOMCRg2aLA3K8fCd1trNs+rY+GuqVXatLi4mDVr1vDwww8DkJaWxsyZM0lOTmb8+PFMnDiR559/vkp57dmzh6ysLF5++WXuv/9+3njjDYYMGUJGRgYvvfQSN910E2PHjvW6f1ZWFoMGDeKWW25h165dHDp0iAEDBtCtWzemTZsGwLJlyxg3bhw7duxg2bJlfPzxx9StW5fhw4ezdOlS0tLSyqYBmzRpEgDt27dn/PjxADz44IO888479OnTx2u55s6dS0REBBs3buSnn36ie/fupKSk0KZNmyodB2OMMSYQWctcLVM6N+sVV1zBkSNH6NmzJ4WFhRQUFJRNIp+ens66deuqnGebNm2Ij48HoFOnTuTl5VFQUMCxY8e46aabABg8eLDX/bOzsxk4cCB16tShf//+vPbaa0RFRREdHc2GDRvIz89n165ddO/enTVr1rB582aSkpKIj49nzZo17N+/H3DdD3jvvfeW5fv+++/TpUsXYmNjWbt2Lbm5uRWWa9WqVSxatIj4+Hi6dOlCfn4+e/bsqfJxMMYYYwKRtcx5U8UWtJpWes9cYWEhd999N7NnzyY9Pf2i8qxfv37ZckhICKdOnaKqc/J+/vnn7Nmzh549ewLw888/Ex0dzYgRI0hNTeXVV1/lhhtuoF+/fogIqkp6ejpTpkw5L6+wsDBCQkIAOH36NMOHD2fTpk20aNGCCRMmcPr06QrLparMnDmTXr16VSd8Y4wxJqBZy1wtFRERwYwZM/jrX/9Kw4YNadasGR9++CEAixcvLmulu1DNmjWjcePGbNiwAXC1vnmSlZXFhAkTyMvLIy8vj2+//ZZvvvmGAwcO0L9/f5YvX05WVhapqakA3H777bz++uscOnQIgCNHjnDgwIHz8j19+jQAV155JcePHy97IreicvXq1Ys5c+ZQVFQEwO7duzlx4sRFHQdjjDHG31nLXC3WsWNHbrzxRrKzs1m4cCGZmZmcPHmS6Oho5s+ff9H5z507l6FDhxIeHk6PHj2IiIg4b5vs7GxWrlxZLq1fv35kZ2fzxBNP0L59e7Zv307nzp0B131wkydPJiUlhZKSEurWrcvs2bNp1apVuTyaNm3K0KFDiY2NpXXr1iQlJVVarkceeYS8vDwSEhJQVaKioli+fPlFHwdjjDHGn0lVu9sCTWJiopaOyVZqx44dtGvXzkcluvyOHz9Oo0aNAJg6dSoHDx7khRde8HGpal+5gu26MMYYU/uIyGZVTfS0zlrmgtiKFSuYMmUKZ86coVWrVixYsMDXRQJqb7mMMcaY2sha5txYC4zxxK4LY4wxvlZRy5w9AGGMMcYY48esMneOYG2pNJ7Z9WCMMaa2s8qcm7CwMPLz8+0L3ACuilx+fj5hYWG+LooxxhjjlU8egBCRp4FfASXAIeAhVf3WWfcH4GGgGHhUVf/PSe8ELAAaAO8Cv1FVFZH6wCKgE5APpKpq3oWUq3nz5nz99dccPnz4IqIzgSQsLIzmzZv7uhjGGGOMV756mvUvqvonABF5FBgPZIpIe2Ag0AG4FlgtIterajEwBxgGbMBVmbsTWImr4ndUVa8TkYHAs0DqhRSqbt26Ns+nMcYYY/yKT7pZVfVHt1/DgdJ+zV8B2ar6k6p+AewFOovINUATVV2vrj7QRUBft30WOsuvA7eLiFzyIIwxxhhjagGfjTMnIs8AaUAhcJuT/AtcLW+lvnbSipzlc9NL9/kKQFXPiEghcAXwg4f3HIardY+WLVvWVCjGGGOMMT5zyVrmRGS1iGzz8PoVgKqOU9UWwFJgZOluHrLSCtIr2uf8RNWXVDVRVROjoqKqF5AxxhhjTC10yVrmVPWOKm76CrACeApXi1sLt3XNgW+d9OYe0nHb52sRCQUigCOVvenmzZt/EJHzZ4CvWVfioYUwiARz/MEcOwR3/MEcOwR3/MEcOwR3/Jcj9lbeVvjqadZfquoe59d7gJ3O8tvAKyLyN1wPQPwS+FRVi0XkmIh0BT7B1T07022fdGA9MABYq1UYW0RVL3nTnIhs8jZaczAI5viDOXYI7viDOXYI7viDOXYI7vh9Hbuv7pmbKiJtcQ1NcgDIBFDVXBF5FdgOnAFGOE+yAvwPZ4cmWem8AOYCi0VkL64WuYGXKwhjjDHGGF/zSWVOVe+tYN0zwDMe0jcBMR7STwP31WgBjTHGGGP8hM0AcWm95OsC+Fgwxx/MsUNwxx/MsUNwxx/MsUNwx+/T2MWmrjLGGGOM8V/WMmeMMcYY48esMneJiMidIrJLRPaKyFhfl6emiUgLEXlfRHaISK6I/MZJnyAi34hIjvPq7bbPH5zjsUtEevmu9DVDRPJEZKsT5yYnLVJE/ikie5yfzdy2D4j4RaSt2/nNEZEfRWR0IJ97EZknIodEZJtbWrXPtYh0cq6ZvSIywx9mq/ES+19EZKeIfC4ib4pIUye9tYiccrsG/u62T6DEXu3r3B9jB6/xL3OLPU9Ecpz0QDv33r7jaufnXlXtVcMvIATYB0QD9YB/A+19Xa4ajvEaIMFZbgzsBtoDE4Dfe9i+vXMc6gNtnOMT4us4LvIY5AFXnpM2DRjrLI8Fng3U+J24QoDvcI1/FLDnHrgVSAC2Xcy5Bj4FuuEa7HwlcJevY7vA2FOAUGf5WbfYW7tvd04+gRJ7ta9zf4zdW/znrH8OGB+g597bd1yt/Nxby9yl0RnYq6r7VfVnIBvXHLIBQ1UPquoWZ/kYsIOzU6x54nHe3Utf0svOfa7ghZSfQzgQ478d2KeqFQ3A7fexq+o6zh+MvFrnWiqeY7rW8hS7qq5S1TPOrxsoP6j7eQIp9goE1HmHiuN3WpfuB7IqysNf46/gO65Wfu6tMndplM0X63CfSzbgiEhroCOuAZ0BRjrdL/PcmqAD8ZgosEpENotr3l+A/1DVg+D6YwBc5aQHYvzgGtfR/Y95sJx7qP65/gXe55j2Z//N2XE/AdqIyGci8oGI3OKkBVrs1bnOAy32UrcA3+vZCQAgQM/9Od9xtfJzb5W5S6PK88X6OxFpBLwBjFbVH4E5wH8C8cBBXM3wEJjHpLuqJgB3ASNE5NYKtg24+EWkHq4ZXF5zkoLp3FfkQuaY9ksiMg7XAO9LnaSDQEtV7Qg8hmtGnyYEVuzVvc4DKXZ3gyj/j1xAnnsP33FeN/WQdtnOv1XmLg1vc8wGFBGpi+siX6qq/wBQ1e9VtVhVS4CXOdudFnDHRFW/dX4eAt7EFev3TrN6affCIWfzgIsfVyV2i6p+D8F17h3VPdcVzTHtd0QkHbgbeMDpPsLpYsp3ljfjum/oegIo9gu4zgMm9lLimge9P7CsNC0Qz72n7zhq6efeKnOXxkbglyLSxmm9GIhrDtmA4dwvMRfYoap/c0u/xm2zfkDpU1BvAwNFpL6ItMGZd/dylbemiUi4iDQuXcZ1Q/g2zs4VjPPzLWc5oOJ3lPvPPFjOvZtqnWunS+aYiHR1Pj9pbvv4FRG5E3gCuEdVT7qlR4lIiLMcjSv2/QEWe7Wu80CK3c0dwE5VLes+DLRz7+07jtr6ua/pJyrsVfYkTG9cT7/sA8b5ujyXIL6bcTUVfw7kOK/ewGJgq5P+NnCN2z7jnOOxCz94mqmS+KNxPbn0byC39BwDVwBrgD3Oz8gAjb8hkA9EuKUF7LnHVWk9CBTh+k/74Qs510Airi//fcAsnIHba/PLS+x7cd0fVPrZ/7uz7b3O5+HfwBagTwDGXu3r3B9j9xa/k74AyDxn20A7996+42rl595mgDDGGGOM8WPWzWqMMcYY48esMmeMMcYY48esMmeMMcYY48esMmeMMcYY48esMmeMMcYY48esMmeM8SsiUiwiOW6vsZVsnykiaTXwvnkicmU1tv+XiGxy+z1RRP51seVw8npIRGbVRF7GGP8X6usCGGNMNZ1S1fiqbqyqf7+UhanEVSJyl6qurHzTy0dEQlS12NflMMbUDGuZM8YEBKfl7FkR+dR5XeekTxCR3zvLj4rIdmeS9GwnLVJEljtpG0Qkzkm/QkRWOROHv4jbHIsiMsR5jxwRebF05HsP/gL80UNZy7Wsicg7ItLDWT7uxLFZRFaLSGenlW+/iNzjlk0LEXlPRHaJyFOVlc3Jd5KIfAJ0u5BjbIypnawyZ4zxNw3O6WZNdVv3o6p2xjXK+vMe9h0LdFTVOCDTSZsIfOakPQksctKfAj5S18ThbwMtAUSkHZAKdHdaCIuBB7yUdT3wk4jcVo34woF/qWon4BgwGeiJa+qoSW7bdXbeNx64z+nGrahs4cA2Ve2iqh9VozzGmFrOulmNMf6mom7WLLef0z2s/xxYKiLLgeVO2s24piJCVdc6LXIRwK24JhNHVVeIyFFn+9uBTsBG11SLNODsZNueTMbVOvdEFWID+Bl4z1neCvykqkUishVo7bbdP9WZ2FxE/uHEcaaCshXjmjTcGBNgrDJnjAkk6mW51H/hqqTdA/xJRDrg1n3qYV9PeQiwUFX/UKUCuSqITwNd3ZLPUL5nJMxtuUjPzrNYAvzk5FMiIu5/s88tm1ZSttN2n5wxgcm6WY0xgSTV7ed69xUiUgdooarvA48DTYFGwDqcrkjnvrUfVPXHc9LvApo5Wa0BBojIVc66SBFpVUm5nnHes1QeEC8idUSkBa4u0+rq6bx3A6Av8PEFls0Y4+esZc4Y428aiEiO2+/vqWrp8CT1nRv86wCDztkvBFjidKEKMF1VC0RkAjBfRD4HTgLpzvYTgSwR2QJ8AHwJoKrbReSPwCqnglgEjAAOeCuwqr4rIofdkj4GvsDVjboN2FKtI+DyEbAYuA54RVU3AVS3bMYY/ydnW/ONMcZ/iUgekKiqP/i6LMYYczlZN6sxxhhjjB+zljljjDHGGD9mLXPGGGOMMX7MKnPGGGOMMX7MKnPGGGOMMX7MKnPGGGOMMX7MKnPGGGOMMX7MKnPGGGOMMX7s/wHjXhz3/Et7aQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True, sharey=True)\n",
    "_ = uniform_sampling_scores.plot(ax=axes[0], label=\"Uniform Sampling\")\n",
    "_ = (uniform_sampling_scores.rolling(window=100)\n",
    "               .mean()\n",
    "               .rename(\"Rolling Average\")\n",
    "               .plot(ax=axes[0]))\n",
    "_ = axes[0].legend()\n",
    "_ = axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "_ = prioritized_sampling_scores.plot(ax=axes[1], label=\"Double DQN Scores\")\n",
    "_ = (prioritized_sampling_scores.rolling(window=100)\n",
    "                      .mean()\n",
    "                      .rename(\"Rolling Average\")\n",
    "                      .plot(ax=axes[1]))\n",
    "_ = axes[1].legend()\n",
    "_ = axes[1].set_ylabel(\"Score\")\n",
    "_ = axes[1].set_xlabel(\"Episode Number\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel density plot of the scores\n",
    "\n",
    "In general, the kernel density plot will be bimodal with one mode less than -100 and a second mode \n",
    "greater than 200. The negative mode corresponds to those training episodes where the agent crash \n",
    "landed and thus scored at most -100; the positive mode corresponds to those training episodes \n",
    "where the agent \"solved\" the task. The kernel density or scores typically exhibits negative \n",
    "skewness (i.e., a fat left tail): there are lots of ways in which landing the lander can go \n",
    "horribly wrong (resulting in the agent getting a very low score) and only relatively few paths to \n",
    "a gentle landing (and a high score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "_ = uniform_sampling_scores.plot(kind=\"kde\", ax=ax, label=\"Uniform Sampling\")\n",
    "_ = prioritized_sampling_scores.plot(kind=\"kde\", ax=ax, label=\"Priority Sampling\")\n",
    "_ = ax.set_xlabel(\"Score\")\n",
    "_ = ax.set_xscale(\"symlog\")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go from here?\n",
    "\n",
    "Up next in this series will be [*Dueling Network Architectures for Deep Reinforcement Learning*](https://arxiv.org/abs/1511.06581). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
